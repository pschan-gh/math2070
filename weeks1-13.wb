@course{Math 2070}
@week{1}
@topic{Groups}
@section{Overview}
<hr/>
@itemize
@item
<h5 style="">Groups</h5>
@ul
@li
How many ways are there to color a cube, such that each face is either black or white?

@newcol
<strong style="">Answer:</strong> 10. Why?

@endcol
@li
How many ways are there to form a triangle with three sticks of equal lengths, colored
red, green and blue, respectively?

@li
What are the symmetries of an equilateral triangle?

@newcol
@keyword{Dihedral Group $D_3$}
<br/><br/><a href="https://commons.wikimedia.org/wiki/File:Labeled_Triangle_Reflections.svg#/media/File:Labeled_Triangle_Reflections.svg" style="">
<img alt="Labeled Triangle Reflections.svg" class="lazy" style="background: none;" rendered="0" width="450" src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Labeled_Triangle_Reflections.svg/1200px-Labeled_Triangle_Reflections.svg.png"/></a>
@endcol
@endul
@item
<h5 style="">Rings</h5>
@ul
@li
Euclidean Algorithm.
@li
Chinese Remainder Theorem.
@li
Partial Fraction Decomposition.
@li
Algebraic Extension of Fields.
@endul
@enditemize
@section{Groups}
@defn
A group $G$ is a set equipped with a binary operation $*: G \times G \longrightarrow G$ (typically called @keyword{group operation} or "@keyword{multiplication}"), such that:
@ul
@li
<u style="">
@keyword{Associativity}</u>
\[(a* b)* c = a * (b * c),\]
for all $a, b, c \in G$. In other words, the group operation is @keyword{associative} .
@li
<u style="">
@keyword{Existence of an Identity Element}</u>

There is an element $e \in G$, called an @keyword{identity element} , such that:
\[g* e = e * g = g,\]
for all $g \in G$.
@li
<u style="">
@keyword{Invertibility}</u>

Each element $g \in G$ has an @keyword{inverse} $g^{-1} \in G$, such that:
\[g^{-1}* g = g* g^{-1} = e.\]
@endul
@end
@newcol
<ul style="">
<li style=""> Note that we do not require that $a* b = b * a$. </li>

<li style=""> We often write $ab$ to denote $a* b$. </li></ul>
@endcol
@slide
@defn
If $ab = ba$ for all $a, b \in G$. We say that the group operation is @keyword{commutative}, and that $G$ is an @keyword{abelian group}.
@end
@eg
The following sets are groups, with respect to the specified group operations:
@ul
@li
$G = \mathbb{Q} \backslash \{0\}$, where the group operation is the usual multiplication for rational numbers.
The identity is $e = 1$, and the inverse of $a \in \mathbb{Q}\backslash\{0\}$ is $a^{-1} = \frac{1}{a}$.
The group $G$ is abelian.
@li
$G = \mathbb{Q}$, where the group operation is the usual addition $+$ for rational numbers. The identity is $e = 0$.
The inverse of $a \in \mathbb{Q}$ with respect to $+$ is $-a$.
Note that $\mathbb{Q}$ is <em>NOT</em> a group with respect to multiplication. For in that case, we have $e = 1$, but $0 \in \mathbb{Q}$ has no inverse
$0^{-1} \in \mathbb{Q}$ such that $0\cdot 0^{-1} = 1$.
@endul
@end
@slide
@ex
Verify that the following sets are groups under the specified binary operation:
@ul
@li
$(\mathbb{Z}, +)$
@li
$(\mathbb{R}, +)$
@li
$(\mathbb{R}^\times, \cdot)$
@li
$(U_m, \cdot)$, where $m \in \mathbb{N}$,
\[U_m = \{1, \xi_m, \xi_m^2, \ldots, \xi_m^{m - 1}\},\]
and
$\xi_m = e^{2\pi i/m} = \cos(2\pi/m) + i\sin(2\pi/m) \in \mathbb{C}$.
@li
The set of bijective functions $f: \mathbb{R} \ra \mathbb{R}$,
where $f * g:= f \circ g$ (i.e. composition of functions).
@endul
@end
@subsection{Cayley Table}
<div class="image">
<a href="https://en.wikipedia.org/wiki/Cayley_table" target="_blank">
<table class="table table-bordered" border="2" cellpadding="5" align="center" style="text-align: center;">
<tbody>
<tr>
<th style="background:#efefef;text-align:center">$\large\ast$</th><th style="background:#efefef;text-align:center">$a$</th><th style="background:#efefef;text-align:center">$b$</th><th style="background:#efefef;text-align:center">$c$</th></tr><tr>
<th style="background:#efefef;text-align:center">$a$</th><td>$a^2$</td><td>$ab$</td><td>$ac$</td></tr><tr>
<th style="background:#efefef;text-align:center">$b$</th><td>$ba$</td><td>$b^2$</td><td>$bc$</td></tr><tr>
<th style="background:#efefef;text-align:center">$c$</th><td>$ca$</td><td>$cb$</td><td>$c^2$</td></tr></tbody></table></a></div>
<hr/>

@newcol
<h5>Cayley Table for $D_3$</h5><div class="image">
<a href="https://en.wikipedia.org/wiki/Dihedral_group" target="_blank">
<table class="table table-bordered" width="200" style="text-align: center;">
<tbody>
<tr>
<th style="text-align: center;">$\large\ast$</th><th style="background:#efefef;text-align:center">$r_0$</th><th style="background:#efefef;text-align:center">$r_1$</th><th style="background:#efefef;text-align:center">$r_2$</th><th style="background:#efefef;text-align:center">$s_0$</th><th style="background:#efefef;text-align:center">$s_1$</th><th style="background:#efefef;text-align:center">$s_2$</th></tr><tr>
<th style="background:#efefef;text-align:center">$r_0$</th><td>$r_0$</td><td>$r_1$</td><td>$r_2$</td><td>$s_0$</td><td>$s_1$</td><td>$s_2$</td></tr><tr>
<th style="background:#efefef;text-align:center">$r_1$</th><td>$r_1$</td><td>$r_2$</td><td>$r_0$</td><td>$s_1$</td><td>$s_2$</td><td>$s_0$</td></tr><tr>
<th style="background:#efefef;text-align:center">$r_2$</th><td>$r_2$</td><td>$r_0$</td><td>$r_1$</td><td>$s_2$</td><td>$s_0$</td><td>$s_1$</td></tr><tr>
<th style="background:#efefef;text-align:center">$s_0$</th><td>$s_0$</td><td>$s_2$</td><td>$s_1$</td><td>$r_0$</td><td>$r_2$</td><td>$r_1$</td></tr><tr>
<th style="background:#efefef;text-align:center">$s_1$</th><td>$s_1$</td><td>$s_0$</td><td>$s_2$</td><td>$r_1$</td><td>$r_0$</td><td>$r_2$</td></tr><tr>
<th style="background:#efefef;text-align:center">$s_2$</th><td>$s_2$</td><td>$s_1$</td><td>$s_0$</td><td>$r_2$</td><td>$r_1$</td><td>$r_0$</td></tr></tbody></table></a></div>
@endcol
@subsection{WeBWorK}
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Groups/Groups1.pg}
<br/>
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Groups/Groups3.pg}
<br/>
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Groups/Groups4.pg}
<br/>
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Groups/Groups5.pg}
<br/>
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Groups/Groups6.pg}
<br/>
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Groups/Groups7.pg}
<br/>
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Groups/Groups10.pg}
<br/>
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Groups/Groups11.pg}
<br/>
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Groups/Groups12.pg}
<br/>
@endenumerate
@subsection{Matrix Groups}
@eg
The set $G = {\rm GL}(2, \mathbb{R})$
of real $2 \times 2$ matrices with nonzero determinants is a group
under matrix multiplication, with identity element:

@newcol
\[e = \left(\begin{matrix} 1 & 0\\0& 1\end{matrix}\right).\]
In the group $G$, we have:
\[\left(\begin{matrix} a & b \\ c & d\end{matrix}\right)^{-1}
=
\frac{1}{ad - bc}\left(\begin{matrix}d & -b \\-c & a\end{matrix}\right)\]
@col
Note that there are matrices $A, B \in {\rm GL}(2, \mathbb{R})$
such that $AB \neq BA$. Hence ${\rm GL}(2, \mathbb{R})$ is not abelian.

@col
The group ${\rm GL}(2, \mathbb{R})$ is called a @keyword{General Linear Group}.
<hr/>
@endcol
@end
@ex
@newcol
The set ${\rm SL}(2, \mathbb{R})$
of real $2 \times 2$ matrices with determinant $1$ is a group under matrix multiplication.

It is called a @keyword{Special Linear Group}.
@endcol
@end
@subsection{Basic Properties}
@claim
The identity element $e$ of a group $G$ is unique.
@end
@proof
@newcol
Suppose there is an element $e' \in G$ such that $e' g = ge' = g$ for all $g \in G$.
Then, in particular, we have:
\[e'e = e\]
But since $e$ is an identity element, we also have $e'e = e'$. Hence, $e' = e$.
@endcol
@end
@claim
Let $G$ be a group.
For all $g \in G$, its inverse $g^{-1}$ is unique.
@end
@proof
@newcol
Suppose there exists $g' \in G$ such that $g'g = gg' = e$.
By the associativity of the group operation, we have:
\[g' = g'e = g'(g g^{-1}) = (g'g)g^{-1} = e g^{-1} = g^{-1}.\]
Hence, $g^{-1}$ is unique.
@endcol
@end
@slide
Let $G$ be a group with identity element $e$.
For $g \in G$, $n \in \mathbb{N}$,
let:
\[\begin{split}
g^n &:= \underbrace{g \cdot g \cdots g}_{n\text{ times}}.\\
g^{-n} &:= \underbrace{g^{-1} \cdot g^{-1} \cdots g^{-1}}_{n\text{ times}}\\
g^0 &:= e.
\end{split}\]
@claim
@newcol
Let $G$ be a group. <ol>
<li> For all $g \in G$,
we have:
\[(g^{-1})^{-1} = g.\] </li>

<li> For all $a, b \in G$,
we have:
\[(ab)^{-1} = b^{-1}a^{-1}.\] </li>

<li> For all $g \in G$, $n, m \in \mathbb{Z}$, we have:
\[g^n\cdot g^m = g^{n + m}.\] </li></ol>
@endcol
@end
@proof
@newcol
@keyword{Exercise.}
@endcol
@end
@slide
@defn
Let $G$ be a group, with identity element $e$.
The @keyword{order} of $G$ is the number of elements in $G$.
The @keyword{order} $\ord g$ of an  $g \in G$
is the smallest $n \in \mathbb{N}$ such that $g^n = e$.
If no such $n$ exists, we say that $g$ has @keyword{infinite order}.
@end
@thm
@newcol
Let $G$ be a group with identity element $e$.
Let $g$ be an element of $G$. If $g^n = e$ for some $n \in \mathbb{N}$,
then $g$ has finite order, andÂ $\ord g$ divides $n$.
@endcol
@end
@proof
@newcol
Shown in class.
@endcol
@end@course{Math 2070}
@week{2}
@topic{Groups}
@slide
@defn
Let $G$ be a group, with identity element $e$.

The @keyword{order} of $G$ is the number of elements in $G$.

The @keyword{order} $\ord g$ of an <i> element</i> $g \in G$
is the smallest $n \in \mathbb{N}$ such that $g^n = e$.
If no such $n$ exists, we say that $g$ has @keyword{infinite order}.
@end

<hr/>
@thm
@label{thm:orderdividesn}
@newcol
Let $G$ be a group with identity element $e$.
Let $g$ be an element of $G$.  If $g^n = e$ for some $n \in \mathbb{N}$,
then $\ord g$ is finite, and moreover $\ord g$ divides $n$.
@endcol
@end
@proof
Shown in class.
@end
<hr/>

@ex
@newcol
If $G$ has finite order, then every element of $G$ has finite order.
@endcol
@end

@slide
@defn
A group $G$ is @keyword{cyclic} if there exists $g \in G$ such that every element of $G$ is equal to $g^n$
for some integer $n$.
In which case, we write: $G = \langle g \rangle$, and say that $g$ is a @keyword{generator} of $G$.

@newcol
Note: The generator of of a cyclic group might not be unique.
@endcol
@end
@eg
@newcol
$(U_m, \cdot)$ is cyclic.
@endcol
@end
@ex
@newcol
A finite cyclic group $G$ has order (i.e. size) $n$
if and only if each of its generators has order $n$.
@endcol
@end
@ex
@newcol
$(\mathbb{Q}, +)$ is not cyclic.
@endcol
@end
@section{Permutations}
@defn
Let $X$ be a set.  A @keyword{permutation} of $X$ is a bijective map $\sigma : X \ra X$.
@end
@claim
@newcol
The set $S_X$ of permutations of a set $X$
is a group with respect to $\circ$, the composition of maps.
@endcol
@end
@proof
@newcol
@ul
@li
Let $\sigma, \gamma$ be permutations of $X$.
By definition, they are bijective maps from $X$ to itself.
It is clear that $\sigma\circ\gamma$ is a bijective map from $X$ to itself,
hence $\sigma\circ\gamma$ is a permutation of $X$.  So $\circ$ is a well-defined
binary operation on $S_X$.
@li
For $\alpha, \beta, \gamma \in S_X$, it is clear that
$\alpha\circ(\beta\circ \gamma) = (\alpha\circ\beta)\circ\gamma$.
@li
Define a map $e : X \ra X$ as follows:
\[
e(x) = x,\quad \text{ for all } x \in X.
\]
It is clear that $e \in S_X$, and that $e \circ \sigma = \sigma\circ e = \sigma$
for all $\sigma \in S_X$.  Hence, $e$ is an identity element in $S_X$.
@li
Let $\sigma$ be any element of $S_X$.  Since $\sigma : X \ra X$ is by assumption bijective,
there exists a bijective map $\sigma^{-1} : X \ra X$
such that $\sigma\circ\sigma^{-1} = \sigma^{-1}\circ \sigma = e$.
So $\sigma^{-1}$
is an inverse of $\sigma$ with respect to the operation $\circ$.
@endul
@qed
@endcol
@end

@slide
<strong>Terminology:</strong> We call $S_X$ the @keyword{Symmetric Group} on $X$.

<strong>Notation:</strong> If $X = \{1, 2, \ldots, n\}$, where $n \in \mathbb{N}$,
we denote $S_X$ by $S_n$.

For $n \in \mathbb{N}$, the group $S_n$ has $n!$ elements.

For $n \in \mathbb{N}$,
by definition an element of $S_n$ is a bijective map $\sigma : X \ra X$,
where $X = \{1, 2, \ldots, n\}$.
We often describe $\sigma$ using the following notation:
\[
\sigma = \left(\begin{matrix}
1 & 2 & \cdots & n\\
\sigma(1) & \sigma(2) & \ldots & \sigma(n)
\end{matrix}
\right)
\]
@slide
@eg
In $S_3$,
\[
\sigma = \left(
\begin{matrix}
1 & 2 & 3\\
3 & 2 & 1
\end{matrix}
\right)
\]
is the permutation on $\{1, 2, 3\}$
which sends $1$ to $3$, $2$ to itself, and $3$ to $1$,
i.e. $\sigma(1) = 3, \sigma(2) = 2, \sigma(3) = 1$.

@newcol
For $\alpha, \beta \in S_3$ given by:
\[
\alpha =
\left(
\begin{matrix}
1 & 2 & 3\\
2 & 3 & 1
\end{matrix}\right),
\quad
\beta =
\left(\begin{matrix}
1 & 2 & 3\\
2 & 1 & 3
\end{matrix}\right),
\]
we have:

@col
\[
\alpha\beta = \alpha\circ\beta
=
\left(\begin{matrix}
1 & 2 & 3\\
2 & 3 & 1
\end{matrix}\right) \circ
\left(\begin{matrix}
1 & 2 & 3\\
2 & 1 & 3
\end{matrix}\right)
=\left(\begin{matrix}
1 & 2 & 3\\
3 & 2 & 1
\end{matrix}\right)
\]
(since, for example, $\alpha\circ\beta: 1 \xmapsto{\beta} 2 \xmapsto{\alpha} 3$.).

We also have:

@col
\[
\beta\alpha = \beta\circ\alpha
= \left(\begin{matrix}
1 & 2 & 3\\
2 & 1 & 3
\end{matrix}\right) \circ
\left(\begin{matrix}
1 & 2 & 3\\
2 & 3 & 1
\end{matrix}\right)
=
\left(\begin{matrix}
1 & 2 & 3\\
1 & 3 & 2
\end{matrix}\right)
\]
@col
Since $\alpha\beta \neq \beta\alpha$, the group $S_3$ is non-abelian.

@col
In general, for $n > 2$, the group $S_n$ is non-abelian ( @keyword{Exercise:} Why?).

@col
For the same $\alpha \in S_3$ defined above, we have:
\[
\alpha^2 = \alpha\circ\alpha =
\left(\begin{matrix}
1 & 2 & 3\\
2 & 3 & 1
\end{matrix}\right)\circ
\left(\begin{matrix}
1 & 2 & 3\\
2 & 3 & 1
\end{matrix}\right) =
\left(\begin{matrix}
1 & 2 & 3\\
3 & 1 & 2
\end{matrix}\right)
\]
and:

@col
\[
\alpha^3 = \alpha\cdot\alpha^2
= \left(\begin{matrix}
1 & 2 & 3\\
2 & 3 & 1
\end{matrix}\right)
\circ
\left(\begin{matrix}
1 & 2 & 3\\
3 & 1 & 2
\end{matrix}\right)
=
\left(\begin{matrix}
1 & 2 & 3\\
1 & 2 & 3
\end{matrix}\right) = e
\]
@col
Hence, the order of $\alpha$ is $3$.
@endcol
@end
@section{Dihedral Group}
Consider the subset $\mathcal{T}$ of transformations of $\mathbb{R}^2$,
consisting of all rotations by fixed angles about the origin, and all reflections over lines through the origin.

@newcol
Consider a regular polygon $P$ with $n$ sides in $\mathbb{R}^2$, centered at the origin.
Identify the polygon with its $n$ vertices, which form a subset $P = \{x_1, x_2, \ldots, x_n\}$
of $\mathbb{R}^2$.  If $\tau(P) = P$ for some $\tau \in \mathcal{T}$, we say that $P$ is @keyword{symmetric} with respect to $\tau$.

@col
Intuitively, it is clear that $P$ is symmetric with respect to $n$ rotations $\{r_0, r_1,\ldots, r_{n - 1}\}$,
and $n$ reflections $\{s_1, s_2,\ldots, s_n\}$ in $\mathcal{T}$. <br/><br/><div class="image" style="width: 450px;">
<a href="https://commons.wikimedia.org/wiki/File:Labeled_Triangle_Reflections.svg#/media/File:Labeled_Triangle_Reflections.svg">
<img alt="Labeled Triangle Reflections.svg" class="lazy" style="background: none;" rendered="0" width="450" src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Labeled_Triangle_Reflections.svg/1200px-Labeled_Triangle_Reflections.svg.png"/></a><center>
@newcol
By <a href="//commons.wikimedia.org/w/index.php?title=User:Jim.belk&action=edit&redlink=1" class="new" title="User:Jim.belk (page does not exist)">Jim.belk</a>
- <span class="int-own-work" lang="en" xml:lang="en">Own work</span>
, Public Domain, <a href="https://commons.wikimedia.org/w/index.php?curid=2803388">Link</a>
@endcol</center></div>

@endcol
@thm
@newcol
The set $D_n := \{r_0, r_1,\ldots, r_{n - 1}, s_1, s_2,\ldots, s_n\}$ is a group,
with respect to the group operation defined by $\tau*\gamma = \tau\circ\gamma$
(composition of transformations).
@endcol
@end@keyword{Terminology:}
@newcol
$D_n$ is called a @keyword{dihedral group} .
@endcol

@section{More on $S_n$}
Consider the following element in $S_6$:
\[
\sigma = \left(
\begin{matrix}
1&2&3&4&5&6\\
5&4&3&6&1&2
\end{matrix}
\right)
\]
@newcol
We may describe the action of $\sigma : \{1, 2, \ldots, 6\} \ra \{1, 2, \ldots, 6\}$
using the notation:
\[
\sigma = (15)(246),
\]
@col
where $(n_1 n_2\cdots n_k)$ represents the permutation:
\[
n_1 \mapsto n_2 \dots n_i \mapsto n_{i + 1} \dots \mapsto n_k \mapsto n_1
\]
@col
Viewing permutations as bijective maps,
the "multiplication" $(15)(246)$ is by definition the composition $(15)\circ(246)$.

@col
We call $(n_1n_2\cdots n_k)$ a @keyword{$k$-cycle} .
Note that $3$ is missing from $(15)(246)$.
This corresponds to the fact that $3$ is fixed by $\sigma$.

@endcol

@ex
@newcol
In $S_n$, for any positive integer $k \leq n$, every $k$-cycle has order $k$.
@endcol
@end
@slide

@claim
Every non-identity permutation in $S_n$ is either a cycle or a product of disjoint cycles.
@end
@proof
Discussed in class.
@end

<hr/>
@ex
@newcol
Disjoint cycles commute with each other.
@endcol
@end

@slide
A 2-cycle is often called a @keyword{transposition},
for it switches two elements with each other.

@claim
Each element of $S_n$ is a product of (not necessarily disjoint) transpositions.
@end

Sketch of proof:

@newcol
Show that each permutation not equal to the identity is a product of cycles,
and that each cycle is a product of transpositions:
\[
(a_1a_2\ldots a_k) = (a_1 a_k) (a_1 a_{k - 1})\cdots(a_1 a_3)(a_1 a_2)
\]
@endcol
@eg
@newcol
@steps
\[
\begin{split}
\left(
\begin{matrix}
1&2&3&4&5&6\\
5&4&3&6&1&2
\end{matrix}
\right) &=
@nstep{(15)(246)}
\\&
@nstep{= (15)(26)(24)}
\\&
@nstep{= (15)(46)(26)}
\end{split}
\]
@endsteps
@endcol
@end

@slide
Note that a given element $\sigma$ of $S_n$
may be expressed as a product of transpositions in different ways,
but:
@claim
In every factorization of $\sigma$ as a product of transpositions,
the number of factors is either always even or always odd.
@end

@proof
@newcol
@keyword{Exercise.} One approach: Show that there is a unique $n \times n$ matrix, with either $0$ or $1$ as its coefficients,
which sends each standard basis vector $\vec{e}_i$ in $\mathbb{R}^n$ to $\vec{e}_{\sigma(i)}$.
Then, use the fact that the determinant of the matrix corresponding to a transposition is $-1$,
and that the determinant function of matrices is multiplicative.
@endcol
@end
@section{WeBWorK}
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Permutations/Permutations4.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Permutations/Permutations3.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Permutations/Permutations1.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Permutations/Permutations2.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Subgroups/Subgroups7.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Subgroups/Subgroups8.pg}
@endenumerate@course{Math 2070}
@week{3}
@topic{$\mathbb{Z}_n$}
@topic{Subgroups}
@topic{Left Cosets}
@topic{Index}
@section{The Cyclic Group $\mathbb{Z}_n$}
@defn
@label{def:cycliczn}
Fix an integer $n > 0$.

For any $k \in \mathbb{Z}$, let $\ol{k}$ denote the remainder of the division of $k$
by $n$.

Let $\mathbb{Z}_n = \{0, 1, 2, \ldots, n - 1\}$.
We define a binary operation $+_{\mathbb{Z}_n}$
on $\mathbb{Z}_n$ as follows:
\[k +_{\mathbb{Z}_n} l = \ol{k + l}.\]
@end
@ex
@label{ex:cycliczn}
@newcol
$\mathbb{Z}_n = (\mathbb{Z}_n, +_{\mathbb{Z}_n})$
is a @keyword{cyclic} group, with identity element $0$, and $j^{-1} = n - j$ for any nonzeroÂ $j \in \mathbb{Z}_n$.
@endcol
@end
@subsection{WeBWorK}
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Subgroups/Subgroups9.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Subgroups/Subgroups8.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-CyclicGroups/CyclicGroups1.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-CyclicGroups/CyclicGroups2.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-CyclicGroups/CyclicGroups3.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-CyclicGroups/CyclicGroups4.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-CyclicGroups/CyclicGroups5.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-CyclicGroups/CyclicGroups6.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-CyclicGroups/CyclicGroups7.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-CyclicGroups/CyclicGroups8.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-CyclicGroups/CyclicGroups9.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-CyclicGroups/CyclicGroups10.pg}
@endenumerate
@section{Subgroups}
@defn
Let $G$ be a group.
A subset $H$ of $G$ is a @keyword{subgroup} of $G$ if it satisfies the following properties:

@newcol
@ul
@li
@keyword{Closure} If $a, b \in H$, then $ab \in H$.
@li
@keyword{Identity} The identity element of $G$ lies in $H$.
@li
@keyword{Inverses} If $a \in H$, then $a^{-1} \in H$.
@endul
@endcol
@end
@newcol
In particular, a subgroup $H$ is a group with respect to the group operation on $G$,
and the identity element of $H$ is the identity element of $G$.
@endcol

@slide
@eg
@label{eg:subgroups}
@ul
@li
For any $n \in \mathbb{Z}$,
$n\mathbb{Z}$ is a subgroup of $(\mathbb{Z}, +)$.
@li
$\mathbb{Q}\bs\{0\}$ is a subgroup of $(\mathbb{R}\bs\{0\}, \cdot)$.
@li
${\rm SL}(2, \mathbb{R})$ is a subgroup of ${\rm GL}(2, \mathbb{R})$.
@li
The set of all rotations (including the trivial rotation) in a dihedral group $D_n$
is a subgroup of $D_n$.
@li
Let $n \in \mathbb{N}$, $n \geq 2$.
We say that $\sigma \in S_n$ is an @keyword{even permutation} if it is equal to the product of an even number of transpositions.
The subset $A_n$ of $S_n$ consisting of even permutations is a subgroup of $S_n$.
$A_n$ is called an @keyword{alternating group}.
@endul
@end
@slide
@claim
A subset $H$ of a group $G$ is a subgroup of $G$ if and only if $H$ is nonempty
and, for all $x, y \in H$, we have $xy^{-1} \in H$.
@end
@proof
@newcol
Suppose $H \subseteq G$ is a subgroup.
Then, $H$ is nonempty since $e_G \in H$.
For all $x, y \in H$, we have $y^{-1} \in H$;
hence, $xy^{-1} \in H$.

Conversely, suppose $H$ is a nonempty subset of $G$,
and $xy^{-1} \in H$ for all $x, y \in H$.

@col
@ul
@li
@keyword{Identity} Let $e$ be the identity element of $G$.
Since $H$ is nonempty, it contains at least one element $h$.
Since $e = h \cdot h^{-1}$, and by hypothesis $h\cdot h^{-1} \in H$, the set $H$ contains $e$.
@li
@keyword{Inverses} Since $e \in H$, for all $a \in H$ we have $a^{-1} = e\cdot a^{-1} \in H$.
@li
@keyword{Closure} For all $a, b \in H$, we know that $b^{-1} \in H$.  Hence,
$ab = a\cdot(b^{-1})^{-1} \in H$.
@endul
@col
Hence, $H$ is a subgroup of $G$.
@qed
@endcol
@end
@slide
@claim
The intersection of two subgroups of a group $G$ is a subgroup of $G$.
@end
@proof
Exercise.
@end
@slide
@thm
Every subgroup of $(\mathbb{Z}, +)$ is cyclic.
@end
@proof
@newcol
Let $H$ be a subgroup of $G = (\mathbb{Z}, +)$.
If $H = \{0\}$, then it is clearly cyclic.

@col
Suppose $\abs{H} > 1$.  Consider the subset:
\[
S = \{h \in H \,:\, h > 0\} \subseteq H
\]
Since a subgroup is closed under inverse,
and the inverse of any $z \in \mathbb{Z}$
with respect to $+$ is $-z$, the subgroup $H$ must contain at least one positive
element.  Hence, $S$ is a non-empty subset of $\mathbb{Z}$ bounded from below.

@col
It then follows from the <a target="_blank" href="https://planetmath.org/wellorderingprinciplefornaturalnumbers">Least Integer Axiom</a>
that exists a minimum element $h_0$ in $S$.
That is $h_0 \leq h$ for any $h \in S$.

@col
<strong>Exercise.</strong>  Show that $H = \langle h_0 \rangle$.

(<em>Hint</em> : The <a target="_blank" href="https://planetmath.org/divisionalgorithmforintegers">Division Theorem for Integers</a>  could be useful here.)
@endcol
@end
@ex
Every subgroup of a cyclic group is cyclic.
@end
@section{Lagrange's Theorem}
Let $G$ be a group, $H$ a subgroup of $G$.
We are interested in knowing how large $H$ is relative to $G$.

We define a relation $\equiv$ on $G$ as follows:
\[
a \equiv b \text{ if } b = ah \text{ for some } h \in H,
\]
or equivalently:
\[
a \equiv b \text{ if } a^{-1}b \in H.
\] @keyword{Exercise:} $\equiv$ is an <a target="_blank" href="https://planetmath.org/equivalencerelation">
@keyword{equivalence relation}</a>.

We may therefore partition $G$
into disjoint equivalence classes with respect to $\equiv$.
We call these equivalence classes the @keyword{left cosets} of $H$.

Each left coset of $H$ has the form $aH = \{ah \,|\, h \in H\}$.

@newcol
We could likewise define <i> right</i>  cosets.  These sets are of the form $Hb$, $b \in G$.
In general,
the number of left cosets and right cosets, if finite, are equal to each other
@endcol
@slide
@eg
Let $G = (\mathbb{Z}, +)$.
Let:
\[
H = 3\mathbb{Z} =
\{\ldots, -9, -6, -3, 0, 3, 6, 9, \ldots\}
\]
The set $H$ is a subgroup of $G$.
The left cosets of $H$ in $G$ are as follows:
\[
3\mathbb{Z}, 1 + 3\mathbb{Z}, 2 + 3\mathbb{Z},
\]
where $i + 3\mathbb{Z} := \{i + 3k : k \in \mathbb{Z}\}$.

In general, for $n \in \mathbb{Z}$,
the left cosets of $n\mathbb{Z}$ in $\mathbb{Z}$ are:
\[
i + n\mathbb{Z}, \quad i = 0, 1, 2, \ldots, n - 1.
\]
@end
@slide
@defn
The number of left cosets of a subgroup $H$ of $G$ is called the @keyword{index} of $H$ in $G$.
It is denoted by:
\[
[G : H]
\]
@end
@eg
Let $n \in \mathbb{N}$,
$G = (\mathbb{Z}, +)$, $H = (n\mathbb{Z}, +)$.
Then,
\[
[G:H] = n.
\]
@end
@slide
@eg
Let $G = {\rm GL}(2, \mathbb{R})$.  Let:
\[
H = {\rm GL}^+(2, \mathbb{R}) := \left\{ h \in G : \det h > 0\right\}.
\]
(@keyword{Exercise:} $H$ is a subgroup of $G$.)

Let:
\[
s = \left(
\begin{matrix}
-1 & 0 \\
 0 & 1 
\end{matrix}
\right) \in G
\]
Note that $\det s = \det s^{-1} = -1$.

For any $g \in G$, either $\det g > 0$ or $\det g < 0$.
If $\det g > 0$, then $g \in H$.
If $\det g < 0$, we write:
\[
g = (ss^{-1}) g = s(s^{-1} g).
\]
Since $\det s^{-1}g = (\det s^{-1})(\det g) > 0$, we have $s^{-1}g \in H$.
So, $G = H \sqcup s H$, and $[G : H] = 2$.
Notice that both $G$ and $H$ are infinite groups, but the index of $H$ in $G$ is finite.
@end

@eg
Let $G = {\rm GL}(2, \mathbb{R})$, $H = {\rm SL}(2, \mathbb{R})$.
For each $x \in \mathbb{R}^\times$, let:
\[
s_x = \left(
\begin{matrix}
x & 0\\
0 & 1 
\end{matrix}
\right) \in G
\]
Note that $\det s_x = x$.

For each $g \in G$, we have:
\[
g = s_{\det g}{(s_{\det g}^{-1} g)} \in s_{\det g}H
%% g = s_{\det g}\underbrace{(s_{\det g}^{-1} g)}_{\in H}
\]
Moreover, for distinct $x, y \in \mathbb{R}^\times$, we have:
\[
\det (s_x^{-1}s_y) = y/x \neq 1.
\]
This implies that $s_x^{-1} s_y \notin H$, hence $s_yH$ and $s_xH$ are disjoint cosets.
We have therefore:
\[
G = \bigsqcup_{x \in \mathbb{R}^\times} s_x H.
\]
The index $[G: H]$ in this case is infinite.
@end

@course{Math 2070}
@week{4}
@topic{Lagrange's Theorem}
@topic{Generators}
@topic{Group Homomorphisms}
@section{Lagrange's Theorem}
@thm
@title{Lagrange's Theorem}
@label{lagrangethm}
Let $G$ be a finite group. Let $H$ be subgroup of $G$, then $\abs{H}$ divides $\abs{G}$.
More precisely, $\abs{G} = [G: H]\cdot\abs{H}$.
@end
@proof
@newcol
We already know that the left cosets of $H$ partition $G$.
That is:
\[G = a_1 H \sqcup a_2 H \sqcup \ldots \sqcup a_{[G:H]}H,\]
where $a_i H \cap a_j H = \emptyset$ if $i \neq j$.
Hence, $\abs{G} = \sum_{i = 1}^{[G:H]} \abs{a_i H}$.

@col
The theorem follows if we show that the size of each left coset of $H$ is equal to $\abs{H}$.

@col
For each left coset $S$ of $H$, pick an element $a \in S$, and define a map
$\psi: H \ra S$ as follows:
\[\psi(h) = ah.\]
@col
We want to show that $\psi$ is bijective.

@col
For any $s \in S$,
by definition of a left coset (as an equivalence class) we have $s = ah$ for some $h \in H$.
Hence, $\psi$ is surjective.

@col
If $\psi(h') = ah' = ah = \psi(h)$ for some $h', h \in H$,
then $h' = a^{-1}ah' = a^{-1}ah = h$. Hence, $\psi$ is one-to-one.

@col
So we have a bijection between two finite sets. Hence, $\abs{S} = \abs{H}$.
@qed
@endcol
@end
@slide
@cor
Let $G$ be a finite group.
The order of every element of $G$ divides the order of $G$.
@end
Since $G$ is finite, any element of $g \in G$ has finite order $\ord g$.
Since the order of the subgroup:
\[H = \langle g \rangle
= \{e, g, g^2, \ldots, g^{(\ord g) - 1}\}\]
is equal to $\ord g$,
it follows from Lagrange's Theorem that $\ord g = \abs{H}$ divides $\abs{G}$.
@cor
@newcol
If the order of a group $G$ is prime, then $G$ is a cyclic group.
<!-- @ref{pf:primecyclic} -->
@endcol
@end
@cor
@newcol
If a group $G$ is finite, then for all $g \in G$ we have:
\[
g^{\abs{G}} = e.
\] 
<!-- @ref{pf:ghatordGeqe} -->
@endcol
@end
@slide
@cor
Let $G$ be a <i>finite</i> group. Then a nonempty subset $H$ of $G$
is a subgroup of $G$ if and only if it is closed under the group operation of $G$
(i.e. $ab \in H$ for all $a, b \in H$).
@end
@proof
@newcol
It is easy to see that if $H$ is a subgroup,
then it is closed under the group operation.
The other direction is left as an @keyword{Exercise} .
@endcol
@end
@slide
@eg
Let $n$ be an integer greater than $1$. The group $A_n$ of even permutations
on a set of $n$ elements (see @ref{eg:subgroups}) has order $\displaystyle \frac{n!}{2}$.
@end
@proof
@newcol
View $A_n$ as a subgroup of $S_n$, which has order $n!$.

@keyword{Exercise} : Show that $S_n = A_n\, \sqcup\, (12)A_n$.

@col
Hence, we have $[S_n: A_n] = 2$.

@col
It now follows from @ref{lagrangethm} that:
\[\abs{A_n} = \frac{\abs{S_n}}{[S_n: A_n]} = \frac{n!}{2}.\]
@endcol
@end
@subsection{WeBWorK}
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Cosets/Cosets1.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Cosets/Cosets5.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Cosets/Cosets13.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Cosets/Cosets14.pg}
@endenumerate
@section{Generators}
Let $G$ be a group, $X$ a nonempty subset of $G$.
The subset of $G$ consisting of elements of the form:
\[g_1^{m_1}g_2^{m_2}\cdots g_n^{m_n},
\quad\text{where}\quad
n \in \mathbb{N}, g_i \in X, m_i \in \mathbb{Z},\]
is a subgroup of $G$.
We say that it is the subgroup of $G$ @keyword{generated} by $X$.
If $X = \{x_1, x_2, \ldots, x_l\}$, $l \in \mathbb{N}$.
We often write:
\[\langle x_1, x_2, \ldots, x_l\rangle\]
to denote the subgroup generated by $X$.
@eg
@newcol
In $D_n$, $\{ r_0, r_1, \ldots, r_{n - 1}\} = \langle r_1 \rangle$.
@endcol
@end
@newcol
If there exists a finite number of elements $x_1, x_2, \ldots, x_l \in G$
such that $G = \langle x_1, x_2, \ldots, x_l\rangle$,
we say that $G$ is @keyword{finitely generated} .

@col
For example, every cyclic group is finitely generated, for it is generated by one
element.

@col
Every finite group is finitely generated, since we may take the finite generating set
$X$ to be $G$ itself.
@endcol
@slide
@eg
Consider $G = D_3$, and its subgroup $H = \{r_0, r_1, r_2\}$ consisting of its rotations.
(We use the convention that $r_k$ is the anticlockwise rotation by an angle of $2\pi k/3$).

@newcol
By Lagrange's Theorem, the index of $H$ in $G$ is $[G: H] = \abs{G}/\abs{H} = 2$.
This implies that $G = H \sqcup gH$ for some $g \in G$.
Since $gH = H$ if $g \in H$, we may conclude that $g \notin H$. So, $g$ is a reflection.

@col
Conversely, for any reflection $s \in D_3$, the left coset $sH$ is disjoint from $H$.
We have therefore $G = H {\sqcup} s_1H = H {\sqcup} s_2H = H {\sqcup} s_3H$,
which implies that $s_1 H = s_2 H = s_3 H$.

@col
In particular, for a fixed $s = s_i$,
any element in $G$ is either a rotation or equal to $s r_i$ for some rotation $r_i$.
Since $H$ is a cyclic group, generated by the rotation $r_1$, we have $D_3 = \langle r_1, s \rangle$,
where $s$ is any reflection in $D_3$.
@endcol
@end
@section{Group Homomorphisms}
@defn
Let $G = (G, *)$, $G' = (G', *')$ be groups.
A @keyword{group homomorphism} $\phi$ from $G$ to $G'$
is a map $\phi: G \ra G'$ which satisfies:
\[\phi(a * b) = \phi(a)*'\phi(b),\]
for all $a, b \in G$.
@end
@claim
@newcol
If $\phi: G \ra G'$ is a group homomorphism, then: <ol>
<li> $\phi(e_G) = e_{G'}$. </li>
<li> $\phi(g^{-1}) = \phi(g)^{-1}$, for all $g \in G$. </li>
<li> $\phi(g^n) = \phi(g)^n$, for all $g \in G$, $n \in \mathbb{Z}$. </li></ol>
@endcol
@end
@proof
@newcol
We prove the first claim, and leave the rest as an exercise.
Since $e_G$ is the identity element of $G$, we have $e_G*e_G = e_G$.
On the other hand, since $\phi$ is a group homomorphism, we have:
\[\phi(e_G) =
\phi(e_G*e_G) = \phi(e_G)*'\phi(e_G).\]
Since $G'$ is a group, $\phi(e_G)^{-1}$ exists in $G'$, hence:
\[\phi(e_G)^{-1}*'\phi(e_G) = \phi(e_G)^{-1}*'(\phi(e_G)*'\phi(e_G))\]
The left-hand side is equal to $e_{G'}$, while by the associativity of $*'$
the right-hand side is equal to $\phi(e_G)$.
@endcol
@end
@slide
Let $\phi: G \ra G'$ be a homomorphism of groups.
The __image__ of $\phi$ is defined as:
\[\im \phi:= \phi(G):= \{g' \in G' : g' = \phi(g) \;\text{ for some }\; g \in G\} \subseteq G'\]
The __kernel__ of $\phi$ is defined as:
\[\ker \phi = \{g \in G: \phi(g) = e_{G'}\} \subseteq G.\]
@claim
@newcol
The image of $\phi$ is a subgroup of $G'$.
The kernel of $\phi$ is a subgroup of $G$.
@endcol
@end
@claim
@newcol
A group homomorphism $\phi: G \ra G'$ is one-to-one if and only if $\ker \phi = \{e_G\}$.
<!-- @ref{pf:kernelonetoone} -->
@endcol
@end
@slide
@eg
@title{Examples of Group Homomorphisms}
@label{eg:grouphomomorphisms}
@ul
@li
$\phi: S_n \longrightarrow (\{\pm 1\}, \cdot)$,
\[\phi(\sigma) = \begin{cases} 1, & \sigma \text{ is an even permutation.}\\
-1, & \sigma \text{ is an odd permutation.}
\end{cases}\]
@newcol
$\ker \phi = A_n$.
@endcol
@li
$\det: \GL(n, \mathbb{R}) \longrightarrow (\mathbb{R}^\times, \cdot)$ <br/>
@newcol
$\ker \det = \SL(n, \mathbb{R})$.
@endcol
@li
Let $G$ be the (additive) group of all real-valued continuous functions on $[0, 1]$.
\[\phi: G \longrightarrow (\mathbb{R}, +)\]
\[\phi(f) = \int_0^1 f(x)\,dx.\]
@li
$\phi: (\mathbb{R}, +) \longrightarrow (\mathbb{R}^\times, \cdot)$.
\[\phi(x) = e^x.\]
@endul
@end
@slide
@defn
Let $G$, $G'$ be groups. A map $\phi: G \ra G'$ is a group @keyword{isomorphism} if it is a bijective
group homomorphism.
@end
@newcol
Note that if a homomorphism $\phi$ is bijective, then $\phi^{-1}: G' \ra G$ is also a homomorphism,
and consequently, $\phi^{-1}$ is an isomorphism.
If there exists an isomorphism between two groups $G$ and $G'$,
we say that the groups $G$ and $G'$ are @keyword{isomorphic} .
@endcol
@slide
@eg
@label{eg:cycliczn}
Recall @ref{def:cycliczn} and @ref{ex:cycliczn}.

Let $n > 2$.
Let $H = \{r_0, r_1, r_2, \ldots, r_{n - 1}\}$
be the subgroup of $D_n$ consisting of all rotations,
where $r_1$ denotes the anticlockwise rotation by the angle $2\pi/n$,
and $r_k = r_1^k$.
Then, $H$ is isomorphic to $\mathbb{Z}_n = (\mathbb{Z}_n, +_{\mathbb{Z}_n})$.
@end
@proof
@newcol
Define $\phi: H \ra \mathbb{Z}_n$ as follows:
\[\phi(r_k) = k, \quad k \in \{0, 1, 2, \ldots, n - 1\}.\]
@col
For any $k \in \mathbb{Z}$,
let $\ol{k} \in \{0, 1, 2, \ldots, n - 1\}$
denote the remainder of the division of $k$ by $n$.
By the Division Theorem for Integers, we have:
\[
k = nq + \ol{k}
\]
for some integer $q \in \mathbb{Z}$.

@col
It now follows from $\ord r_1 = n$ that,
for all $r_i, r_j \in H$, we have:
@steps
\[\begin{split}
r_i r_j &= r_1^i r_1^j = r_1^{i + j}
\\&
@nstep{= r_1^{nq + \ol{i + j}}}
\\
&
@nstep{= \left(r_1^n\right)^q r_1^{\ol{i + j}}}
\\
&
@nstep{= r_{\ol{i + j}}.}
\end{split}\]
@endsteps

@col
Hence,
@steps
\[\begin{split}
\phi(r_i r_j) &= \phi(r_{\ol{i + j}})
\\&
@nstep{= \ol{i + j}}
\\&
@nstep{= i +_{\mathbb{Z}_n} j}
\\&
@nstep{=\phi(r_i) +_{\mathbb{Z}_n} \phi(r_j).}
\end{split}\]
@endsteps
@col
This shows that $\phi$ is a homomorphism.
It is clear that $\phi$ is surjective, which then implies that
$\phi$ is one-to-one, for the two groups have the same size.
Hence, $\phi$ is a bijective homomorphism, i.e. an isomorphism.
@qed
@endcol
@end@course{Math 2070}
@week{5}
@topic{Group Homomorphisms}
@topic{Rings}
@slide
@keyword*{isomorphic}
@claim
 Any cyclic group of finite order $n$ is isomorphic to $\mathbb{Z}_n$.
@end
@proof
@newcol
 Sketch of Proof:

By definition, a cyclic group $G$ is equal to $\langle g\rangle$ for some $g \in G$.
Moreover, $\ord g = \ord G$.

Define a map $ \phi : \mathbb{Z}_n \longrightarrow G $ as follows:
\[
\phi(k) = g^k, \quad k \in \{0, 1, 2, \ldots, n - 1\}.
\]
Show that $\phi$ is a group isomorphism.

(For reference, see the discussion of @ref{eg:cycliczn}.)
@endcol
@end

@cor
@newcol
 If $G$ and $G'$ are two finite cyclic groups of the same order, then $G$ is isomorphic to $G'$.
@endcol
@end

@ex
@newcol
 An infinite cyclic group is isomorphic to $(\mathbb{Z}, +)$.
@endcol
@end

@ex
@newcol
 Let $G$ be a cyclic group, then any group which is isomorphic to $G$ is also cyclic.
@endcol
@end

@section{Product Group}
<b style="display:none">Product Group</b>

Let $(A, \ast_A), (B, \ast_B)$ be groups.  The direct product:
\[
A \times B := \{(a, b)\;|\; a\in A, b \in B\}
\]
has a natural group structure
where the group operation $\ast$ is defined as follows:
\[
(a, b)\ast(a', b') = (a\ast_A a', b\ast_B b'), \quad (a, b), (a', b') \in A\times B.
\]
@newcol
 The identity element of $A \times B$ is $e = (e_A, e_B)$, where $e_A, e_B$
are the identity elements of $A$ and $B$, respectively.

@col
 For any $(a, b) \in A \times B$, we have $(a, b)^{-1} = (a^{-1}, b^{-1})$,
where $a^{-1}$, $b^{-1}$ are the inverses of $a$, $b$ in the groups $A$, $B$,
respectively.

@col
 For any collection of groups $A_1, A_2, \ldots, A_n$,
we may similarly define a group operation $\ast$ on:
\[
A_1 \times A_2 \times \cdots \times A_n
:= \{(a_1, a_2, \ldots, a_n)\;|\;a_i \in A_i, i = 1, 2, \ldots n\}.
\]
That is:
\[
(a_1, a_2, \ldots, a_n)\ast (a_1', a_2', \ldots, a_n')
=
(a_1\ast_{A_1} a_1', a_2\ast_{A_2} a_2', \ldots, a_n \ast_{A_n} a_n')
\]
The identity element of $A_1 \times A_2 \times \cdots \times A_n$ is:
\[
e = (e_{A_1}, e_{A_2}, \ldots, e_{A_n}).
\]
For any $(a_1, a_2, \ldots, a_n) \in A_1 \times A_2 \times \cdots \times A_n$,
its inverse is:
\[
(a_1, a_2, \ldots, a_n)^{-1} = (a_1^{-1}, a_2^{-1}, \ldots, a_n^{-1}).
\]
@endcol
@slide
@keyword*{isomorphic}
@ex
 $\mathbb{Z}_6$ is isomorphic to $\mathbb{Z}_2\times\mathbb{Z}_3$.
@end
@proof
@newcol
<strong>Hint:</strong>

Show that $\mathbb{Z}_2\times\mathbb{Z}_3$ is a cyclic group generated by $(1, 1)$.
@endcol
@end
@eg
@newcol
 The cyclic group $\mathbb{Z}_4$ is not isomorphic to $\mathbb{Z}_2 \times \mathbb{Z}_2$.
@endcol
@end
@proof
@newcol
 Each element of $G = \mathbb{Z}_2\times\mathbb{Z}_2$ is of order at most $2$.
Since $\abs{G} = 4$, $G$ cannot be generated by a single element.
Hence, $G$ is not cyclic,
so it cannot be isomorphic to the cyclic group $\mathbb{Z}_4$.
@qed
@endcol
@end

@slide
@ex
 Let $G$ be an abelian group, then any group which is isomorphic to $G$ is abelian.
@end
@eg
@newcol
 The group $D_6$ has $12$ elements.  We have seen that $D_6 = \langle r_1, s\rangle$, where $r_1$ is a rotation of order $6$,
and $s$ is a reflection, which has order $2$.  So, it is reasonable to ask if $D_6$ is isomorphic to $\mathbb{Z}_6 \times \mathbb{Z}_2$.  The answer is no.
For $\mathbb{Z}_6 \times \mathbb{Z}_2$ is abelian, but $D_6$ is not.
@endcol
@end

@slide
@claim
 The dihedral group $D_3$ is isomorphic to the symmetric group $S_3$.
@end
@proof
@newcol
 We have seen that $D_3 = \langle r, s\rangle$, where $r = r_1$ and
$s$ is any fixed reflection,
with:
\[
\ord r = 3,\quad \ord s = 2,\quad srs = r^{-1}.
\]
In particular , any element in $D_3$ may be expressed as $r^is^j$,
with $i \in \{0, 1, 2\}$, $j \in \{0, 1\}$.

@col
 We have also seen that $S_3 = \langle a, b \rangle$,
where:
\[
a = (123),\quad b = (12),\quad \ord a = 3,\quad \ord b = 2, \quad bab = a^{-1}.
\]
Hence, any element in $S_3$ may be expressed as $a^ib^j$,
with $i \in \{0, 1, 2\}$, $j \in \{0, 1\}$.

@col
 Define map $\phi: D_3 \longrightarrow S_3$ as follows:
\[
\phi(r^is^j) = a^ib^j, \quad i, j \in \mathbb{Z}
\]

@col
 We first show that $\phi$ is well-defined:
That is, whenever $r^i s^j = r^{i'}s^{j'}$,
we want to show that:
\[
\phi(r^i s^j) = \phi(r^{i'}s^{j'}).
\]
@col
 The condition $r^i s^j = r^{i'}s^{j'}$ implies that:
\[
r^{i - i'} = s^{j' - j}
\]
@col
 This holds only if  $r^{i - i'} = s^{j' - j} = e$,
since no rotation is a reflection.

@col
 Since $\ord r = 3$ and $\ord s = 2$, we have:
\[
3 | (i - i'), \quad 2 | (j' - j),
\]
by @ref{thm:orderdividesn}.

@col
 Hence,
@steps
\begin{align*}
\phi(r^is^j) \phi(r^{i'}s^{j'})^{-1}
&= (a^ib^j)(a^{i'}b^{j'})^{-1}
&
\\
&
@nstep{= a^i b^jb^{-j'} a^{-i'}}
&
\\
&
@nstep{= a^i b^{j - j'} a^{-i'}}
&
\\
&
@nstep{= a^{i - i'}}
&
@nstep{\text{ since } \ord b = 2.}
\\
&
@nstep{ = e}
&
@nstep{\text{ since } \ord a = 3.}
\end{align*}

@endsteps
 This implies that
$\phi(r^is^j) = \phi(r^{i'}s^{j'})$.
We conclude that $\phi$ is well-defined.

@col
 We now show that $\phi$ is a group homomorphism:

@col
 Given $\mu, \mu' \in \{0, 1, 2\}$, $\nu, \nu' \in \{0, 1\}$, we have:
\[
\phi(r^\mu s^\nu \cdot r^{\mu'}s^{\nu'}) =
\begin{cases}
\phi(r^{\mu + \mu'}s^{\nu'}),&\text{if } \nu = 0;\\
\phi(r^{\mu - \mu'}s^{\nu + \nu'}),&\text{if } \nu = 1.
\end{cases}
\]
@col
 \[
=
\begin{cases}
a^{\mu + \mu'}b^{\nu'},&\text{if } \nu = 0;\\
a^{\mu - \mu'}b^{\nu + \nu'} = a^{\mu}b^{\nu}a^{\mu'}b^{\nu'},&\text{if } \nu = 1.
\end{cases}
\]
@col
 \[
=\phi(r^\mu s^\nu)\phi(r^{\mu'}s^{\nu'}).
\]
This shows that $\phi$ is a group homomorphism.

@col
 To show that $\phi$ is a group isomorphism,
it remains to show that it is surjective and one-to-one.

It is clear that $\phi$ is surjective.  We leave it as an exercise
to show that $\phi$ is one-to-one.
@qed
@endcol
@end

@slide
@eg
 The group:
\[
G = \left\{g \in \mathrm{GL}(2, \mathbb{R}) \,\left|\,
g = \left(
\begin{matrix}
\cos \theta & -\sin \theta\\
\sin \theta & \cos \theta
\end{matrix}
\right) \text{ for some } \theta \in \mathbb{R}
\right.
\right\}
\]
is isomorphic to
\[
G' = \{z \in \mathbb{C} : \abs{z} = 1\}.
\]
Here, the group operation on $G$ is matrix multiplication, and the group operation on $G'$ is the multiplication of complex numbers.
<hr/>
@newcol
 Each element in $G'$ is equal to $e^{i\theta}$ for some $\theta \in \mathbb{R}$.
Define a map $\phi : G \ra G'$ as follows:
\[
\phi\left(\left(
\begin{matrix}
\cos \theta & -\sin \theta\\
\sin \theta & \cos \theta
\end{matrix}
\right)\right) = e^{i\theta}.
\]
<strong>Exercise:</strong> Show that $\phi$ is a well-defined map.
Then, show that it is a bijective group homomorphism.
@endcol
@end
@subsection{WeBWorK}
@enumerate
@item @webwork{Library/UMass-Amherst/Abstract-Algebra/PS-GroupHomomorphisms/Homomorphisms1.pg}
@item @webwork{Library/UMass-Amherst/Abstract-Algebra/PS-GroupHomomorphisms/Homomorphisms4.pg}
@item @webwork{Library/UMass-Amherst/Abstract-Algebra/PS-GroupHomomorphisms/Homomorphisms3.pg}
@item @webwork{Library/UMass-Amherst/Abstract-Algebra/PS-GroupHomomorphisms/Homomorphisms6.pg}
@item @webwork{Library/UMass-Amherst/Abstract-Algebra/PS-GroupHomomorphisms/Homomorphisms2.pg}
@item @webwork{Library/UMass-Amherst/Abstract-Algebra/PS-GroupHomomorphisms/Homomorphisms8.pg}
@endenumerate
@section{Rings}
@subsection{Basic Results in Elementary Number Theory}
@thm
@title{Division Theorem}
@label{thm:divalg}
 Let $a, b \in \mathbb{Z}$, $a \neq 0$,
then there exist unique $q$ (called the quotient), and $r$ (@keyword{remainder}) in $\mathbb{Z}$, satisfying
$0 \leq r < \abs{a}$, such that $b = aq + r$.
@end
@proof
@newcol
 We will prove the case $a > 0$, $b \geq 0$.  The other cases are left as exercises.

@col
 Fix $a > 0$.
First, we prove the existence of the quotient $q$ and remainder $r$ for any $b \geq 0$,
using mathematical induction.

@col
<strong>The base step</strong>
 corresponds to the case $0 \leq b < a$.
In this case, if we let $q = 0$ and $r = b$, then indeed $b = qa + r$,
where $0 \leq r  = b < a$.  Hence, $q$ and $r$ exist.

@col
<strong>The inductive step</strong>
 of the proof of the existence of $q$ and $r$ is as follows:
Suppose the existence of the quotient and remainder holds for all non-negative $b' < b$,
we want to show that it must also hold for $b$.

@col
 First, we may assume that
$b \geq a$, since the case $b < a$ has already been proved.  Let $b' = b - a$.
Then, $0 \leq b' < b$,
so by the inductive hypothesis we have $b' = q'a + r'$
for some $q', r' \in \mathbb{Z}$ such that $0 \leq r' < a$.

@col
 This implies that $b = b' + a = (q' + 1)a + r'$.

@col
 So, if we let $q = q'+ 1$
and $r = r'$, then $b = qa + r$, where $0 \leq r < a$.
This establishes the existence of $q, r$ for $b$.
Hence, by mathematical induction, the existence of $q, r$ holds for all $b \geq 0$.

@col
 Now we prove the uniqueness of $q$ and $r$.
Suppose $b = qa + r = q'a + r'$, where $q, q', r, r' \in \mathbb{Z}$,
with $0 \leq r, r' < a$.

@col
 Then, $qa+ r = q'a+r'$ implies that $r - r' = (q' - q)a$.
Since $0 \leq r, r' < a$, we have:

@col
 \[
a > \abs{r - r'} = \abs{q' - q} a.
\]

@col
 Since $q' - q$ is an integer, the above inequality implies that $q'  - q = 0$,
i.e. $q' = q$, which then also implies that $r' = r$.
We have therefore established the uniqueness of $q$ and $r$.

The proof of the theorem, for the case $a > 0, b \geq 0$, is now complete.
@qed
@endcol
@end

<h5 class="notkw">Another Proof of the @ref{thm:divalg}.</h5>
@proof
@of{thm:divalg}
@newcol
We consider here the special case $b \geq 0$.
Consider the set:
\[
S = \{s \in \mathbb{Z}_{\geq 0 }\;:\; s = b - aq \text{ for some } q \in \mathbb{Z}.\}
\]
Since $b = b - a\cdot 0 \geq 0$, we have $b \in S$.
So, $S$ is a nonempty subset of $\mathbb{Z}$ bounded below by $0$.
By the Least Integer Axiom, there exists a minimum element $r \in S$.
We claim that $r < \abs{a}$:

@col
Suppose not, that is, $r \geq \abs{a}$.  By assumption:
$r = b - aq$
for some $q \in \mathbb{Z}$.

@col
Consider the element $r' = r - \abs{a}$.  Then, $0 \leq r'$ and moreover:
\[
r' = (b - aq) - \abs{a} = b - (q \pm 1)a,
\]
depending on whether $a > 0$ or $a < 0$.
So, $r' \in S$.  On the other hand, by construction we have $r' < r$,
which contradicts the minimality of $r$.  We conclude that $r < \abs{a}$.
This establishes the existence of the remainder $r$.

@col
The existence of $q$ in the theorem is now also clear.  We leave the proof of the uniqueness of $r$ and $q$ as an exercise.
@endcol
@end
@slide
@keyword*{cyclic}
@thm
Every subgroup of $\mathbb{Z}$ is cyclic.
@end
@proof
@newcol
First, we note that the group operation $\ast$ on $\mathbb{Z}$
is integer addition, with $e_{\mathbb{Z}} = 0$,
and $z^{\ast -1} = -z$ for any $z \in \mathbb{Z}$.

@col
Let $H$ be a nontrivial (i.e. contains more than one element)
subgroup of $\mathbb{Z}$.
Since for any $h \in H$ we also have $-h \in H$,
$H$ contains at least one positive element.

@col
Let $d$ be the least positive integer in $H$.
It exists because of the Least Integer Axiom.

We claim that $H = \langle d \rangle$:

@col
For any $h \in H$,
by the Division Theorem for Integers we have $h = dq + r$
for some $r, q \in \mathbb{Z}$, such that $0 \leq r < d$.  Then,
\[
r = h - dq = h - (\underbrace{d + d + \ldots + d}_{q \text{ times}})
\]
if $q \geq 0$, or
\[
r = h - dq = h - (\underbrace{(-d) + (-d) + \ldots + (-d)}_{q \text{ times}})
\]
if $q < 0$.

@col
In either case, since $H$ is a subgroup we have $r \in H$.  If $r > 0$, then we have
a positive element in $H$ which is strictly less than $d$, which contradicts
the minimality of $d$.  Hence, $r = 0$, from which it follows that any $h \in H$
is equal to $dq = d^{\ast q}$ for some $q \in \mathbb{Z}$.
This shows that $H = \langle d \rangle$.
@endcol
@end

@ex
@newcol
Let $n$ be a positive integer.
Every subgroup of $\mathbb{Z}_n$ is cyclic.
@endcol
@end

@cor
@newcol
Every subgroup of a cyclic group is cyclic.
@endcol
@end
@course{Math 2070}
@week{6}
@topic{Elementary Number Theory}
@topic{Euclid's Lemma}
@topic{Congruences}
@topic{Chinese Remainder Theorem}
@section{Further Results in Elementary Number Theory}
@defn
The @keyword{Greatest Common Divisor} $gcd(a, b)$ of $a, b \in \mathbb{Z}$ is the largest positive integer
$d$ which divides both $a$ and $b$ (Notation: $d | a$ and $d | b$).
@end

<strong>Note.</strong>
@newcol
If $a \neq 0$, then $gcd(a, 0) = \abs{a}$.
$gcd(0, 0)$ is undefined.
@endcol

@subsection{Euclidean Algorithm}
@label{sec:euclidalg}
@lemma
@newcol
If $b = aq + r$ $(a, b, q, r \in \mathbb{Z})$, then
$gcd(b, a) = gcd (a, r)$.
@endcol
@end
@proof
@newcol
If $d | a$ and $d | b$, then $d | r = b - aq$.
Conversely, if $d | a$ and $d | r$, then $d|a$ and $d|b = qa+r$.
So, the set of common divisors of $a, b$ is the same as the set of the common divisors of $a, r$.
If two finite sets of integers are the same, then their largest elements are clearly the same.
In other words:
\[
gcd(b, a) = gcd(a, r).
\]
@qed
@endcol
@end
@slide
Suppose $\abs{b} \geq \abs{a}$.  Let $b_0 = b$, $a_0 = a$.
Write $b_0 = a_0q_0 + r_0$, where $0 \leq r_0 < \abs{a_0}$.

@newcol
For $n > 0$, let $b_n = a_{n - 1}$ and $a_n = r_{n - 1}$, where
$r_n$ is the remainder of the division of $b_n$ by $a_n$.  That is,
\[
b_n = a_nq_n + r_n, \quad  0 \leq r_n < \abs{a_n}.
\]
@col
If $r_0 = 0$, then that means that $a | b$, and $gcd(a, b) = \abs{a}$.
Now, suppose $r_0 > 0$.
Since $r_n$ is a non-negative integer and  $0 \leq r_n < r_{n - 1}$,
eventually, $r_n = 0$ for some $n \in \mathbb{N}$.
@endcol

@claim
@newcol
$gcd(b, a) = \abs{a_n}$.
@endcol
@end
@proof
@newcol
By the previous lemma,
@steps
\[
\begin{split}
gcd(b, a) &= gcd(b_0, a_0)\\
&
@nstep{= gcd(a_0, r_0) = gcd(b_1, a_1)}
\\
&
@nstep{= gcd(a_1, r_1) = gcd(b_2, a_2)}
\\
&
@nstep{= \ldots}
\\
&
@nstep{= gcd(a_{n}, r_{n}) = gcd(a_n, 0) = \abs{a_n}.}
\end{split}
\]
@endsteps

@endcol
@end

@slide
@eg
Find $gcd(285,255)$.

@newcol
@steps
\[
\begin{split}
\underbrace{285}_{b_0} &= \underbrace{255}_{a_0} \underbrace{1}_{q_0} + \underbrace{30}_{r_0}
\\
@nstep{\underbrace{255}_{b_1 = a_0}}
&
@nstep{=\underbrace{30}_{a_1 = r_0} \underbrace{8}_{q_1} + \underbrace{15}_{r_1}}
\\
@nstep{\underbrace{30}_{b_2}}
&
@nstep{=\underbrace{15}_{a_2} \underbrace{2}_{q_2} + \underbrace{0}_{r_2}}
\end{split}
\]
@endsteps
@col
So, $gcd(285, 255) = r_1 = 15$.
@endcol
@end
@slide
@claim
@title{BÃ©zout's Lemma}
@label{bezoutslemma}
Let $a, b$ be nonzero integers.
There exist $x, y \in \mathbb{Z}$ such that $gcd(a, b) = ax + by$.
@end
@proof
@newcol
<strong>Sketch of Proof:</strong>
<hr/>
<strong>Approach 1.</strong>
@newcol
Recall the notation used in @ref{sec:euclidalg} .
We saw that if $r_n = 0$, then $gcd(a, b) = r_{n - 1}$. <br/> We may prove BÃ©zout's Lemma via mathematical induction as follows: <br/>
@col
First, for integers $0 \leq l < \min(n - 1, 2)$, show that there exist
$x_l, y_l \in \mathbb{Z}$ such that $r_l = a x_l + b y_l$.
This is the base step of the induction proof. <br/>
@col
We now carry out the inductive step.
Suppose $n - 1 \geq 2$. For any integer $2 \leq k \leq n - 1$,
suppose $r_l = a x_l + b y_l$ for some $x_l, y_l \in \mathbb{Z}$, for all
$0\leq l < k$. <br/>
Show that:
\[r_k = \underbrace{b_k}_{a_{k - 1} = r_{k - 2}} - q_{k} \underbrace{a_{k}}_{r_{k - 1}}\]
also has the form $r_k = a x_k + b y_k$
for some $x_k, y_k \in \mathbb{Z}$. <br/>
@col
The desired identity $gcd(a, b) = r_{n - 1} = ax_{n - 1} + by_{n - 1}$
then follows by mathemtical induction.
@endcol
<hr/>
<strong>Approach 2.</strong>
@newcol
Consider the set:
\[S = \{n \in \mathbb{Z}_{> 0} | n = ax + by \text{ for some } x, y \in \mathbb{Z}\}.\]
Show that the the minimum element $d \in S$ is the greatest common divisor of
$a$ and $b$.
@endcol
<hr/>
@endcol
@end
@ex
@newcol
Find $x, y \in \mathbb{Z}$ such that:
\[gcd(285, 255) = 285 x + 255 y.\]
@endcol
@end
@ex
@newcol
For any nonzero $a, b$ in  the group $G = (\mathbb{Z}, +)$,
we have:
\[
\langle a, b \rangle = \langle gcd(a, b) \rangle.
\]
@endcol
@end
@slide
@defn
Two integers $a, b \in \mathbb{Z}$ are @keyword{relatively prime} if $gcd(a, b) = 1$.
@end
@claim
@newcol
Two integers $a, b \in \mathbb{Z}$ are relatively prime if and only if there exist $x, y \in \mathbb{Z}$
such that $ax + by = 1$.
@endcol
@end
@keyword*{BÃ©zout's Lemma}
@proof
@newcol
If $a, b$ are relatively prime, then by definition $gcd(a, b) = 1$.
So, by @ref{bezoutslemma} there exist $x, y \in \mathbb{Z}$ such that:
\[ax + by = gcd(a, b) = 1.\]
Conversely,
suppose $ax + by = 1$ for some $x, y \in \mathbb{Z}$.
Then, any common divisor of $a$ and $b$ must also be a divisor of $1$.
Since $1$ is only divisible by $\pm 1$, we conclude that $gcd(a, b) = 1$.
@endcol
@end
@slide
@defn
An integer $p \geq 2$ is @keyword{prime} if its only proper divisors (i.e. divisors different from $\pm p$)
are $\pm 1$.
@end
@lemma
@title{Euclid's Lemma}
@newcol
Let $a, b$ be integers.
If $p$ is prime and $p | ab$, then $p$ divides at least one of $a$ and $b$.
@endcol
@end
@proof
@newcol
Suppose $p$ does not divide $b$ (Notation: $p\nmid b$), then $gcd(p, b) = 1$,
which implies that $1 = px + by$ for some $x, y \in \mathbb{Z}$.
Since $p | apx$ and $p | aby$, we have $p | a = a\underbrace{(px + by)}_{= 1}$.
@qed
@endcol
@end
@slide
More generally,
@claim
@label{euclidslemmageneral}
If $a, b$ are relatively prime and $a | bc$, then $a | c$.
@end
@proof
@keyword{Exercise.}
@end
@claim
@newcol
If $a, b$ are relatively prime and:
\[
a | c, \quad b | c,
\]
then:
\[
ab | c.
\]
@endcol
@end
@proof
@newcol
By assumption, there are $s, t \in \mathbb{Z}$ such that:
\[
c = as = bt.
\]
@col
So, $a | as = bt$,
which by @ref{euclidslemmageneral} implies that $a | t$, since $gcd(a, b) = 1$.

@col
Hence, $t = au$ for some $u \in \mathbb{Z}$, and we have $c = bt = ab u$.
It follows that $ab | c$.
@qed
@endcol
@end
@slide
@thm
@title{The Fundamental Theorem of Arithmetic}
@label{thm:fta}
Let $a$ be a positive integer $\geq 2$. Then,
@ol
@li
The integer $a$ is either a prime or a product of primes.
@li
@keyword{Unique Factorization} The integer $a$ may be written uniquely as
\[
a = p_1^{n_1}p_2^{n_2}\cdots p_l^{n_l},
\]
where $p_1, p_2, \cdots, p_l$ are distinct prime numbers, and $n_1, n_2, \ldots, n_l \in \mathbb{N}$.
@endol
@end
@proof
@newcol
We prove Part 1 of the theorem by contradiction.

@col
Suppose there exist positive integers $\geq 2$ which are neither primes
nor products of primes.

@col
Let $m$ be the smallest such integer. Since $m$ is not prime, there are
positive integers $a, b \neq 1$ such that $m = ab$.

@col
In particular, $a, b < m$.
So, $a$ and $b$ must be either primes or products of primes, which implies that $m$ is itself a product of primes, a contradiction.
<hr/>
@col
We now prove Part 2 ( @keyword{Unique Factorization} ) of the theorem by induction.

@col
The base step corresponds to the case $l = 1$.

@col
Suppose:
\[
a = p_1^{n_1} = q_1^{m_1}q_2^{m_2}\cdots q_k^{m_k},
\]
where $p_1$ is prime, and the $q_i$'s are distinct primes,
and $n_1, m_i \in \mathbb{N}$.

@col
Then, $p_1$ divides the right-hand side,
so by Euclid's Lemma $p_1$ divides one of the $q_i$'s.

@col
Since the $q_i$'s are prime, we may assume (reindexing if necessary) that $p_1 = q_1$.

@col
Suppose $k > 1$. If $n_1 > m_1$, then $p_1^{n_1 - m_1} = q_2^{m_2}\cdots q_k^{m_k}$,
which implies that $p_1 = q_1$ is one of $q_2,\ldots, q_k$, a contradiction, since the $q_i$'s are distinct.

@col
If $n_1 \leq m_1$, then $1 = p_1^{m_1 - n_1}q_2^{m_2}\cdots q_k^{m_k}$,
which is impossible.
We conclude that $k = 1$, and $p_1 = q_1$, $n_1 = m_1$.

@col
Now we establish the inductive step: Suppose unique factorization is true for all positive integers $a'$
which may be written as $a' = p_1^{n_1}p_2^{n_2}\cdots p_{l'}^{n_{l'}}$,
for any $l' < l$.
We want to show that it is also true for any integer $a$
which may be written as $a = p_1^{n_1}p_2^{n_2}\cdots p_{l}^{n_{l}}$.

@col
In other words, suppose
\[
a = p_1^{n_1}p_2^{n_2}\cdots p_{l}^{n_{l}} = q_1^{m_1}\cdots q_k^{m_k},
\]
where $p_i, q_i$ are prime and $n_i, m_i \in \mathbb{N}$. We want to show that $k = l$, and $p_i = q_i$,
$n_i = m_i$, for $i = 1, 2, \ldots, l$.

@col
If $k < l$, then by the inductive hypothesis applied to $l' = k < l$, we have $k = l$,
a contradiction.
So, we may assume that $k \geq l$.

@col
By Euclid's Lemma, $p_l$ divides, and hence must be equal to, one of the
$q_i$'s.

@col
Reindexing if necessary, we may assume that $p_l = q_k$. Cancelling $p_l$ and $q_{k}$
from both sides of the equation, it is also clear that $n_l = m_{k}$.
Hence, we have:
\[
p_1^{n_1}p_2^{n_2}\cdots p_{l-1}^{n_{l-1}} = q_1^{m_1}\cdots q_{k-1}^{m_{k -1}}.
\]
Since $l - 1 < l$, we may now apply the inductive hypothesis to the integer
which is equal to the left-hand side of the above equation,
and conclude that $l - 1 = k -1$, $p_i = q_i$, $n_i = m_i$, for $1\leq i \leq l - 1$.

@col
Since we already know that $p_l^{n_l}$ matches $q_{k}^{m_{k}}$,
we have $l = k$, and $p_i = q_i$, $n_i = m_i$, for $1 \leq i \leq l$.
This establishes the inductive step, and completes the proof.
@qed
@endcol
@end
@subsection{WeBWorK}
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Congruences/Congruences3.pg}
@item
@webwork{Library/NewHampshire/NECAP/grade11/gr11-2009/n11-2009-9s.pg}
@item
@webwork{Library/SUNYSB/gcd.pg}
@endenumerate
@section{Modular Arithmetic}
@keyword*{congruence}
@defn
Let $m$ be a positive integer, then $a, b \in \mathbb{Z}$ are said to be:

<center>
@keyword{congruent modulo $m$}</center>
\[
a \equiv b \mod m,
\]
if $m | (a - b)$.
@end
@claim
@newcol
The congruence relation $\equiv$ is an @keyword{equivalence relation} . In other words, it
is: <p/><ul>
<li>
@keyword{Reflexive}:<br/> $a \equiv a \mod m$;

</li>
<li> @keyword{Symmetric}:<br/> $a \equiv b \mod m$ implies that $b \equiv a \mod m$;

</li>
<li> @keyword{Transitive}:<br/> $a \equiv b \mod m$, $b \equiv c \mod m$, imply that $a \equiv c \mod m$.

</li></ul>
@endcol
@end
@proof
@newcol
<ul>
<li>
<div style="width:5.4em;display:inline-block">
<b class="notkw">Reflexivity</b></div>
@newcol
Since $m | 0 = (a - a)$, we have $a\equiv a \mod m$.
@endcol</li>
<li>
<div style="width:5.4em;display:inline-block">
<b class="notkw">Symmetry</b></div>
@newcol
If $a \equiv b \mod m$, then by definition $m$ divides $a - b$.
But if $m$ divides $a - b$,
it must also divide $-(a - b) = b - a$, which implies that $b \equiv a \mod m$.
@endcol</li>
<li>
<div style="width:5.4em;display:inline-block">
<b class="notkw">Transitivity</b></div>
@newcol
If $m | (a - b)$ and $m | (b - c)$, then $m | ((a - b) + (b - c)) = (a - c)$, which implies
that $a \equiv c \mod m$.
@endcol</li></ul>
@qed
@endcol
@end
<strong>Note.</strong>
@newcol
$a \equiv 0 \mod m$ if and only if $m | a$.
@endcol
@slide
@claim
@label{claim:congremainder}
<ol>
<li> If $a = qm + r$, then $a \equiv r \mod m$. </li>
<li> If $0 \leq r < r' < m$, then $r \not\equiv r' \mod m$. </li></ol>
@end
@proof
@keyword{Exercise.}
@end
@cor
@label{congremainder}
@newcol
Given integer $m \geq 2$, every $a \in \mathbb{Z}$ is congruent modulo $m$
to exactly one of $\{0, 1, 2, \ldots, m - 1\}$.
@endcol
@end
@proof
@newcol
By Part 1 of the claim, $a$ is congruent mod $m$ to the remainder $r$
of the division of $a$ by $m$. <br/>
@col
By definition, the remainder $r$ lies in $\{0, 1, 2, \ldots, m - 1\}$.
If $a \equiv r' \mod m$, for some $r' \in \{0, 1, 2, \ldots, m - 1\}$,
then by transitivity, we have $r' \equiv r \mod m$. <br/>
@col
By Part 2 of the claim, we have $r = r'$.
@qed
@endcol
@end
@slide
@thm
@label{congcompat}
Congruence is compatible with addition and multiplication in the following sense: <ul>
<li>
<div style="width:6.5em;display:inline-block">
<strong>Addition</strong></div>
@newcol
If $a \equiv a' \mod m$, and $b \equiv b' \mod m$, then $a + b \equiv a'+ b'\mod m$.
@endcol</li>
<li>
<div style="width:6.5em;display:inline-block">
<strong>Multiplication</strong></div>
@newcol
If $a \equiv a' \mod m$ and $b \equiv b' \mod m$, then
$ab \equiv a'b' \mod m$.
@endcol</li></ul>
@end
@proof
@newcol
<ul>
<li>
<div style="width:6.5em;display:inline-block">
<strong>Addition</strong></div>
@newcol
If $m | (a - a')$ and $m | (b - b')$, then:
\[
m | (a - a') + (b - b') = (a + b) - (a' + b').
\]
So, $a + b \equiv a' + b' \mod m$.
@endcol</li>
<li>
<div style="width:6.5em;display:inline-block">
<strong>Multiplication</strong></div>
@newcol
If $m | (a - a')$ and $m | (b - b')$, then:
\[
m | (a - a')b + a'(b - b') = (ab - a'b').
\]
So, $ab \equiv a'b' \mod m$.
@endcol</li></ul>
@qed
@endcol
@end
@slide
@eg
For $a \in \mathbb{Z}$, $a^2 \equiv 0, 1$, or $4 \mod 8$.
@end
@proof
@newcol
By @ref{congremainder} ,
any $a \in \mathbb{Z}$ is congruent modulo $8$ to exactly one
element in $\{0, 1, 2, \ldots, 7\}$.
So, by @ref{congcompat} ,
$a^2$ is congruent modulo 8 to one of:
\[
\{0^2, 1^2, 2^2, 3^2, 4^2, 5^2, 6^2, 7^2\} = \{0, 1, 4, 9, 16, 25, 36, 49\}.
\]
The numbers above a congruent modulo 8 to 0, 1, or 4. The claim follows.
@qed
@endcol
@end
@slide
@thm
@label{thm:inversemodm}
If $a$ and $m$ are relatively prime, then there exists $x \in \mathbb{Z}$ such that
$ax \equiv 1 \mod m$.
@end
@proof
@newcol
Since $a$ and $m$ are relatively prime, by @ref{bezoutslemma} there exist $x, y \in \mathbb{Z}$ such that:
\[
ax + my = 1.
\]
@col
This implies that $m$ divides $my = 1 - ax$. So, by definition,
we have $ax \equiv 1 \mod m$.
@endcol
@end
@slide
@thm
@title{Chinese Remainder Theorem}
If $m_1$ and $m_2$ are relatively prime, then the system of congruence relations:
\begin{equation*}
\begin{split}
x &\equiv r_1 \mod m_1\\
x &\equiv r_2 \mod m_2
\end{split}
\end{equation*}
has a solution $x_0 \in \mathbb{Z}$. Moreover, any two solutions are congruent modulo $m_1m_2$,
and any integer which is congruent to $x_0$ modulo $m_1m_2$ is also a solution.
@end
@remark
@newcol
In other words, the system of two congruence relations is equivalent to
a single congruence relation:
\[
x \equiv r \mod m_1 m_2
\]
for some $r \in \mathbb{Z}$.

@col
Applying this process repeatedly, a system of congruence relations of the form:
\begin{align*}
x &\equiv& r_1 &\mod m_1 \\
x &\equiv& r_2 &\mod m_2 \\
& &  \vdots &\\
x &\equiv&  r_l &\mod m_l
\end{align*}
where the $m_i$'s are pairwise coprime, is equivalent to a single relation of the
form:
\[
x \equiv r \mod m_1m_2\cdots m_l
\]
for some $r \in \mathbb{Z}$.
@endcol
@end
@proof
@newcol
Since $m_1$ and $m_2$ are relatively prime, by @ref{thm:inversemodm} there exists $n \in \mathbb{Z}$ such that $m_1n \equiv 1 \mod m_2$.
Let $x = m_1n(r_2 - r_1) + r_1$. <br/>
@col
Since:
\[
m_1 n (r_2 - r_1) \equiv 0 \mod m_1,
\]
we have:
\[
x \equiv r_1 \mod m_1.
\]
@col
Moreover, since $m_1n \equiv 1 \mod m_2$, we have:
\[
x = m_1n(r_2 - r_1) + r_1 \equiv r_2 - r_1 + r_1 \equiv r_2 \mod m_2.
\]
This shows that the system of congruence relations has at least one solution. <br/>
@col
If $x'$ is another solution to the system, then: <br/>
@col
\begin{eqnarray*}
x - x' &\equiv r_1 - r_1 &\equiv 0 \mod m_1,\\
x - x' &\equiv r_2 - r_2 &\equiv 0 \mod m_2.
\end{eqnarray*}
@col
So, $m_1 | (x - x')$ and $m_2 | (x - x')$. Since, $m_1, m_2$ are relatively prime,
by a previous result we conclude that $m_1m_2 | (x - x')$. In other words,
$x \equiv x' \mod m_1m_2$.

Conversely, for any integer $k$, it is clear $x' = x + m_1m_2k$  is also a solution provided that $x$ is a solution.

Hence, the solution set to the system of congruence relations may be described by:
\[
x \equiv x_0 \mod m_1m_2,
\]
where $x_0$ is any particular solution to the system.
@qed
@endcol
@end
@slide
<strong>Note.</strong> The proof of the Chinese Remainder Theorem as written above is complete.
However, it is worthwhile to explain
how we come up with the solution $x = m_1n(r_2 - r_1) + r_1$ in the first place. <br/>
@newcol
Heuristically, the solution may be arrived at as follows:
For any $q \in \mathbb{Z}$, $x = m_1 q + r_1$ is a solution to the first congruence relation.
We want to find $q$ such that $m_1 q + r_1$ is also a solution to the second congruence relation, that is:
\[
m_1 q + r_1 \equiv r_2 \mod m_2
\]
@col
or, equivalently,
\[
m_1 q \equiv r_2 - r_1 \mod m_2. \tag{$\ast$}
\]
@col
Noting that there exists an $n \in \mathbb{Z}$ such that $m_1 n \equiv 1 \mod m_2$,
the congruence relation $(\ast)$ is equivalent to:
\[
q \equiv n(r_2 - r_1) \mod m_2.
\]
@col
Hence, $x = m_1 q + r_1$ is a solution to the system of congruence relations
if and only if $q$ is of the form $m_2l + n(r_2 - r_1)$, where $l \in \mathbb{Z}$.
In particular, $l = 0$ gives $q = n(r_2 - r_1)$. Hence, $x = m_1n(r_2 - r_1) + r_1$
is a solution.
@endcol
@slide
@eg
Solve the following system of congruence relations:
\begin{align}
x &\equiv&  3  & \mod 34 \label{eq:crteg1}\\
x &\equiv&  -1 & \mod 27 \label{eq:crteg2}
\end{align}
@newcol
The relation \eqref{eq:crteg1} holds if and only if:
\[
x = 34s + 3
\]
for some $s \in \mathbb{Z}$.

@col
For any such $x$, the relation \eqref{eq:crteg2} holds if and only if:
\[
34s + 3 \equiv -1 \mod 27,
\]
or equivalently:
\begin{equation}
\label{eq:crteg3}
34s \equiv -4 \mod 27.
\end{equation}
@col
Since $gcd(34, 27) = 1$, by @ref{thm:inversemodm} there exists $a \in \mathbb{Z}$ such that $a\cdot 34 \equiv 1 \mod 27$.
To find $a$, we perform the Euclidean Algorithm on $34$ and $27$:
\[
\begin{split}
34 &= 27 \cdot 1 + 7\\
27 &= 7 \cdot 3 + 6\\
7 &= 6 \cdot 1 + 1\\
6 &= 1\cdot 6 + 0
\end{split}
\]
@col
Working backwards from the last equation, we see that:
\[
1 = 34(4) + 27(-5)
\]
Hence:
\[
27 | (1 - 34\cdot 4 )
\]
That is, $34 \cdot 4 \equiv 1 \mod 27$.
So, we may take $a = 4$.

@col
Multiplying both sides of \eqref{eq:crteg3} by $a = 4$, we see that \eqref{eq:crteg3} holds if and only if:
\[
s \equiv -16 \mod 27,
\]
which is equivalent to:
\[
s \equiv 11 \mod 27.
\]
Since the relation above holds if and only if $s = 27t + 11$
for some $t \in \mathbb{Z}$,
we conclude that $x \in \mathbb{Z}$ is a solution to our system of congruence relations if and only if:
\[
x = 34s + 3 = 34(27t + 11) + 3 = (34)(27)t + 377
\]
for some $t \in \mathbb{Z}$.
More concisely, the solution set to the system of congruence relations is represented by the single relation:
\[
x \equiv 377 \mod 34\cdot 27
\]
@endcol
@end
@slide
@ex
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Congruences/Congruences1.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Congruences/Congruences2.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Congruences/Congruences5.pg}
@item
@webwork{Library/Rochester/setDiscrete6Integers/ur_dis_6_9.pg}
@item
@webwork{Library/Rochester/setDiscrete7NumberTheory/ur_dis_7_1.pg}
@item
@webwork{Library/Rochester/setDiscrete7NumberTheory/ur_dis_7_2.pg}
@item
@webwork{Library/Rochester/setDiscrete7NumberTheory/ur_dis_7_3.pg}
@item
@webwork{Library/Rochester/setDiscrete7NumberTheory/ur_dis_7_4.pg}
@item
@webwork{Library/SDSU/Discrete/IntegersAndRationals/pL11.pg}
@item
@webwork{Library/Rochester/setDiscrete7NumberTheory/ur_dis_7_6.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Congruences/Congruences10.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Congruences/Congruences11.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Congruences/Congruences12.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Congruences/Congruences13.pg}
@endenumerate
@end@course{Math 2070}
@week{7}
@topic{Polynomials}
@topic{Rings}
@section{Polynomials with Rational Coefficients}
<strong>Notation:</strong> \[
\mathbb{Q} = \text{Set of rational numbers}
\]
\[
\begin{split}
\mathbb{Q}[x] &= \text{Set of polynomials with rational coefficients}\\
&= \left\{a_0 + a_1 x + \cdots + a_n x^n | n \in \mathbb{Z}_{\geq 0}, a_i \in \mathbb{Q}\right\}
\end{split}
\]
@slide
@thm
@title{Division Theorem for Polynomials with Rational Coefficients}
For all $f, g \in \mathbb{Q}[x]$, such that $f \neq 0$, there exist unique $q, r \in \mathbb{Q}[x]$,
satisfying $\deg r < \deg f$, such that $g = fq + r$.
@end
@proof
@newcol
We first prove the existence of $q$ and $r$, via induction on the degree of $g$.
The base step corresponds to the case $\deg g < \deg f$. In this case,
the choice $q = 0$, $r = g$ works, since $g = f\cdot 0 + g$,
and $\deg r = \deg g < \deg f$.

@col
Now, we establish the inductive step.
Let $f$ be fixed.
Given $g$, suppose for all $g'$ with $\deg g' < \deg g$,
there exist $q', r' \in \mathbb{Q}[x]$ such that $g' = fq' + r'$,
with $\deg r' < \deg f$.
We want to show that there exist $q, r$ such that $g = fq + r$, with $\deg r < \deg f$.

@col
Suppose $g = a_0 + a_1 x + \cdots + a_m x^m$ and $f = b_0 + b_1 x + \cdots + b_n x^n$,
where $a_m, b_n \neq 0$.
We may assume that $m \geq n$, since the case $m < n$ (i.e. $\deg g < \deg f$)
has already been proved.

@col
Consider the polynomial:
\[
g' = g - \frac{a_m}{b_n}x^{m - n}f.
\]
Then, $\deg g' < \deg g$,
and by the induction hypothesis we have:
\[
g' = fq' + r'
\]
for some $q', r' \in \mathbb{Q}[x]$ such that $\deg r' < \deg f$.

@col
Hence,
\[
g - \frac{a_m}{b_n}x^{m - n}f = g' = fq' + r',
\]
which implies that:

@col
\[
g = f\left(q' + \frac{a_m}{b_n}x^{m - n}\right) + r'
\]
This establishes the existence of the quotient $q = q' + \frac{a_m}{b_n}x^{m - n}$ and the remainder $r = r'$.

@col
Now, we prove the uniqueness of $q$ and $r$.
Suppose $g = fq + r = fq' + r'$, where $q, q', r, r' \in \mathbb{Q}[x]$,
with $\deg r, \deg r' < \deg f$. We have:
\[
fq + r = fq' + r',
\]
which implies that:

@col
\[
\deg f(q - q') = \deg (r' - r) < \deg f.
\]
The above inequality can hold only if $q = q'$, which in turn implies that $r' = r$.
It follows that the quotient $q$ and the remainder $r$ are unique.
@qed
@endcol
@end
@slide
@defn
Given $f, g \in \mathbb{Q}[x]$, a @keyword{Greatest Common Divisor} $d$ of $f$ and $g$
is a polynomial in $\mathbb{Q}[x]$ which satisfies the following two properties: <ol>
<li> $d$ divides both $f$ and $g$. </li>
<li> For any $e \in \mathbb{Q}[x]$ which divides both $f$ and $g$, we have $\deg e \leq \deg d$. </li></ol>
@end

@claim
@newcol
If $g = fq +r$, and $d$ is a GCD of $g$ and $f$, then $d$ is a GCD of $f$ and $r$.
@endcol
@end
@proof
@newcol
See the proof of @ref{887e4de79f26f195c5f15feb518dbea2} .
@endcol
@end
@slide
@cor
The Euclidean Algorithm applies to $\mathbb{Q}[x]$.

@newcol
Namely:  Suppose $\deg g \geq \deg f$.
let $g_0 = g$, $f_0 = f$, and let $r_0$ be the unique polynomial in $\mathbb{Q}[x]$
such that:
\[
g_0 = f_0q_0 + r_0,\quad \deg r_0 < \deg f_0,
\]
for some $q_0 \in \mathbb{Q}[x]$.

@col
For $k > 0$,
let:
\[
g_k = f_{k-1}, \quad f_k = r_{k - 1}.
\]
Let $r_k$ be the remainder such that:
\[
g_k = f_k q_k + r_k,
\]
for some $q_k \in \mathbb{Q}[x]$.

@col
Since $\deg r_k < \deg f_k = \deg r_{k - 1}$,
we have:
\[
\deg r_0 > \deg r_1 > \deg r_2 > \cdots \geq 0 \geq -\infty
\]
(where by convention we let $\deg 0 = -\infty$).

@col
Eventually, $r_n = 0$ for some $n$,
and it follows from the previous claim
and arguments similar to those used in the case of $\mathbb{Z}$
that $r_{n-1}$ is a GCD of $f$ and $g$.
@endcol
@end
@slide
@eg
@label{eg:euclidalgpoly}
@enumerate
@item
Find a GCD of $x^5 + 1$ and $x^3 + 1$ in $\mathbb{Q}[x]$.

@newcol
@steps
\begin{align*}
x^{5} + 1 &
@nstep{=\left(x^{3} + 1\right)\left(x^{2}\right) + \left(-x^{2} + 1\right)}
\\
@nstep{x^{3} + 1}
&
@nstep{= \left(-x^{2} + 1\right)\left(-x\right) + \left(x + 1\right)}
\\
@nstep{-x^{2} + 1}
&
@nstep{= \left(x + 1\right)\left(-x + 1\right) + \left(0\right)}
\end{align*}
@endsteps
@col
So, a GCD is $x + 1$.
@endcol
@item
Find a GCD of $x^3 - x^2 - x + 1$ and $x^3 + 4x^2 + x - 6$ in $\mathbb{Q}[x]$.

@newcol
@steps
\begin{align*}
x^{3} - x^{2} - x + 1
&
@nstep{= \left(x^{3} + 4 x^{2} + x - 6\right)\left(1\right) + \left(-5 x^{2} - 2 x + 7\right)}
\\
@nstep{x^{3} + 4 x^{2} + x - 6}
&
@nstep{= \left(-5 x^{2} - 2 x + 7\right)\left(-\frac{1}{5} x - \frac{18}{25}\right) + \left(\frac{24}{25} x - \frac{24}{25}\right)}
\\
@nstep{-5 x^{2} - 2 x + 7}
&
@nstep{= \left(\frac{24}{25} x - \frac{24}{25}\right)\left(-\frac{125}{24} x - \frac{175}{24}\right) + \left(0\right)}
\end{align*}
@endsteps
@col
So, a GCD is $\frac{24}{25}x - \frac{24}{25}$, and so is $x - 1$.
@endcol
@endenumerate
@end
@slide
@cor
@title{BÃ©zout's Identity for Polynomials}
@label{bezoutpolynomial}
For any $f, g \in \mathbb{Q}[x]$ which are not both zero,
and $d$ a GCD of $f$ and $g$,
there exist $u, v \in \mathbb{Q}[x]$ such that:
\[
d = fu + gv.
\]
@end

@eg
@newcol
In @ref{eg:euclidalgpoly}, we have:
@steps
\begin{align*}
(x + 1) &= \left(x^3 + 1\right) - \left(-x^{2} + 1\right)\left(-x\right)
\\&
@nstep{= \left(x^3 + 1\right) - \left(\left(x^{5} + 1\right) - \left(x^{3} + 1\right)\left(x^{2}\right)\right)\left(-x\right)}
\\&
@nstep{= \bigg(x\bigg)\bigg(x^{5} + 1\bigg) + \bigg(-x^{3} + 1\bigg)\bigg(x^{3} + 1\bigg)}
\end{align*}
@endsteps
@endcol
@end
@section{Factorization of Polynomials}
@defn
A polynomial $p$ in $\mathbb{Q}[x]$ is @keyword{irreducible} if it satisfies the following conditions: <ol>
<li> $\deg p > 0$, </li>
<li> if $p = ab$ for some $a, b \in \mathbb{Q}[x]$, then either $a$ or $b$
is a constant. </li></ol>
@end
<hr/>
@claim
@newcol
If $p \in \mathbb{Q}[x]$ is irreducible and $p | f_1f_2$, where $f_1, f_2 \in \mathbb{Q}[x]$,
then $p | f_1$ or $p | f_2$.
@endcol
@end
@proof
@newcol
Suppose $p$ does not divide $f_2$, then the only common divisors of $p$ and $f_2$ are
constant polynomials.
In particular, $1$ is a GCD of $p$ and $f_2$.  Then, by @ref{bezoutpolynomial} ,
there exist $u, v \in \mathbb{Q}[x]$ such that $1 = pu + f_2v$.  We have:
\[
f_1 = puf_1 + f_1f_2v.
\]
Since $p$ divides the right-hand side of the above equation, it must divide $f_1$.
@qed
@endcol
@end

@slide
@thm
A polynomial in $\mathbb{Q}[x]$ of degree greater than zero is either irreducible or a product of irreducibles.
@end
@proof
@newcol
Suppose there is a nonempty set of polynomials of degree $> 0$
which are neither irreducible nor products of irreducibles.  Let
$p$ be an element of this set which has the least degree.  Since $p$ is not irreducible,
there are $a, b \in \mathbb{Q}[x]$ of degrees $> 0$ such that $p = ab$. But, $a, b$, having degrees strictly
less than $\deg p$, must be either irreducible or products of irreducibles.  This implies that $p$ is a product
of irreducibles, a contradiction.
@qed
@endcol
@end
<strong>Remark:</strong> Compare this proof with that of Part 1 of the
Fundamental Theorem of Arithmetic (@ref{thm:fta}).
@slide
@thm
@title{Unique Factorization for Polynomials}
For any $p \in \mathbb{Q}[x]$ of degree $> 0$, if:
\[
p = f_1f_2\cdots f_n = g_1g_2\cdots g_m,
\]
where $f_i, g_j$ are irreducible polynomials in $\mathbb{Q}[x]$, then
$n = m$, and the $g_j$'s may be reindexed so that
$f_i = \lambda_i g_i$ for some $\lambda_i \in \mathbb{Q}$,
for $i = 1, 2, \ldots, n$.
@end
@proof
@newcol
<strong>Exercise</strong> . See the proof of Part 2 of @ref{thm:fta} ).
@endcol
@end

@section{Rings}
@subsection{Definition of a Ring}
@defn
A @keyword{ring} $R$ (or $(R, +, \times)$) is a set equipped with two operations:
\[
\times, + : R\times R \rightarrow R
\]
which satisfy the following properties: <ol>
<li> Properties of $+$:
@ol
@li
Commutativity: $a + b = b + a$, $\forall a, b \in R$.
@li
Associativity: $a + (b + c) = (a + b) + c$.
@li
There is an element $0 \in R$ (called the @keyword{additive identity element} ),
such that $a + 0 = a$ for all $a \in R$.
@li
Every element of $R$ has an additive inverse; namely:
For all $a \in R$, there exists an element of $R$, usually denoted $-a$,
such that $a + (-a) = 0$.
@endol</li>
<li> Properties of $\times$:
@ol
@li
Associativity: $a(bc) = (ab)c$.
@li
There is an element $1 \in R$ (called the @keyword{multiplicative identity element} ),
such that $1\times a = a\times 1 = a$ for all $a \in R$.
@endol</li>
<li> Distributativity:
@ol
@li
$a\times(b + c) = a\times b + a\times c$, for all $a, b, c \in R$.
@li
$(a + b) \times c = a \times c + b\times c$, for all $a, b, c \in R$.
@endol</li></ol>
@end

<strong>Note:</strong>
@newcol
@ol
@li
For convenience's sake, we often write $ab$ for $a\times b$.
@li
In the definition, commutativity is required of addition, but not of multiplication.
@li
Every element has an additive inverse, but <i> not necessarily</i> a multiplicative inverse.
That is, there may be an element $a \in R$ such that $ab \neq 1$ for all $b \in R$.
@endol
@endcol
@slide
@eg
The following sets, equipped with the usual operations of addition and multiplication,
are rings:
@ol
@li
$\mathbb{Z}$, $\mathbb{Q}$, $\mathbb{R}$
@li
$\mathbb{Z}[x]$, $\mathbb{Q}[x]$, $\mathbb{R}[x]$
(Polynomials with integer, rational, real coefficients, respectively.)
@li
\[
\begin{split}
\mathbb{Q}[\sqrt{2}] &=
\{\sum_{k = 0}^n a_k(\sqrt{2})^k\, |\, a_k \in \mathbb{Q}, n \in \mathbb{Z}_{\geq 0}\}\\
&= \{a + b\sqrt{2}\, |\, a, b \in \mathbb{Q}\}.
\end{split}
\]
@li
$M_n(\mathbb{R})$,
the set of $n \times n$ real matrices, $n \in \mathbb{N}$.
@li
For a fixed $n$, the set of $n\times n$ matrices with integer coefficients.
@li
$C[0, 1] = \{f : [0, 1]\rightarrow \mathbb{R}\; |\; f \text{ is continuous.}\}$
@endol

The following sets, under the usual operations of addition and multiplication, are not rings:
@ol
@li
$\mathbb{N}$, no additive identity element, i.e. no 0.
@li
$\mathbb{N}\cup\{0\}$, nonzero elements have no additive inverses.
@li
$\GL(n, \mathbb{R})$,
the set of $n \times n$ invertible real matrices, $n \in \mathbb{N}$.
@endol
@end
@slide
@claim
In a ring $R$, there is a unique additive identity element
and a unique multiplicative identity element.
@end
@proof
@newcol
Suppose there is an element $0' \in R$ such that $0' + r = r$ for all $r \in R$, then
in particular $0' + 0 = 0$.

@col
Since $0$ is an additive identity, we have $0' + 0 = 0'$.
So, $0' = 0$.

@col
Suppose there is an element $1' \in R$ such that $1'r = r$ or all $r \in R$,

@col
then in particular $1' \cdot 1 = 1$.

@col
But $1' \cdot 1 = 1'$ since $1$ is a multiplicative identity element, so $1' = 1$.
@qed
@endcol
@end

@ex
@newcol
Prove that:
For any $r$ in a ring $R$, its additive inverse $-r$ is unique.
That is, if $r + r' = r + r'' = 0$, then $r' = r''$.
@endcol
@end
@subsection{WeBWorK}
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition1.pg}
<br/><br/><br/><br/>
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition2.pg}
<br/><br/><br/><br/>
@endenumerate
@slide

@claim
For all elements $r$ in a ring $R$, we have $0r = r0 = 0$.
@end
@proof
@newcol
By distributativity,
\[
0r = (0 + 0)r = 0r + 0r.
\]
@col
Adding $-0r$ (additive inverse of $0r$) to both sides, we have:
\[
0 = (0r + 0r) + (-0r) = 0r + (0r + (-0r)) = 0r + 0 = 0r.
\]

@col
The proof of $r0 = 0$ is similar and we leave it as an <strong>exercise</strong> .
@qed
@endcol
@end

@claim
@newcol
For all elements $r$ in a ring, we have $(-1)(-r) = (-r)(-1)= r$.
@endcol
@end
@proof
@newcol
We have:
\[
0 = 0(-r) = (1 + (-1))(-r) = -r + (-1)(-r).
\]
@col
Adding $r$ to both sides, we obtain
\[
r = r + (-r + (-1)(-r)) = (r + -r) + (-1)(-r) = (-1)(-r).
\]
@col
We leave it as an <strong>exercise</strong> to show that $(-r)(-1) = r$.
@qed
@endcol
@end

@slide

@ex
Show that:
For all $r$ in a ring $R$, we have:
\[
(-1) r = r(-1) = -r.
\]
@end

@ex
@newcol
Show that:
If $R$ is a ring in which $1 = 0$, then $R = \{0\}$.  That is, it has only one element.

(We call such an $R$ the @keyword{zero ring} .)
@endcol
@end@course{Math 2070}
@week{8}
@topic{Commutative Rings}
@topic{Integral Domains}
@topic{Fields}
@section{Commutative Rings}
@defn
A ring $R$ is said to be @keyword{commutative} if $ab = ba$ for all $a, b \in R$.
@end

@eg
@newcol
For a fixed natural number $n > 1$,
the ring of $n\times n$ matrices with integer coefficients,
under the usual operations of addition and multiplication, is not commutative.
@endcol
@end

@slide
@eg
Let $m$ be a natural number greater than 1.  Let $\mathbb{Z}_m = \{0, 1, 2, \ldots, m - 1\}$.
Recall that for any integer $n \in \mathbb{Z}$, there exists a unique $\ol{n} \in \mathbb{Z}_m$,
such that $n \equiv \ol{n} \mod m$.  More precisely, $\ol{n}$ is the remainder of the division of of $n$ by $m$:
$n = mq + r$.
We equip $\mathbb{Z}_m$ with addition $+_m$ and multiplication $\times_m$ defined as follows:
For $a, b \in \mathbb{Z}_m$, let:
\[
\begin{split}
a +_m b &= \overline{a + b},\\
a \times_m b &= \overline{a\cdot b},
\end{split}
\]
where the addition and multiplication on the right are the usual addition and multiplication for integers.
@end
@slide
@claim
With addition and multiplication thus defined, $\mathbb{Z}_m$ is a commutative ring.
@end
@proof
@newcol
@ol
@li
For $a, b \in \mathbb{Z}_m$, we have $a +_m b = \overline{a + b} = \overline{b + a} = b +_m a$,
since addition for integers is commutative.  So, $+_m$ is commutative.
@li
For any $r_1, r_2 \in \mathbb{Z}$,
by @ref{claim:congremainder} and @ref{congcompat} ,
we have
\[
r_1 \equiv \overline{r_1} \mod m, \quad r_2 \equiv \overline{r_2} \mod m,
\]
and:
\[
\overline{r_1 + r_2} \equiv r_1 + r_2 \equiv \overline{r_1} + \overline{r_2} \equiv \overline{\overline{r_1} + \overline{r_2}} \mod m.
\]
@newcol
For $a, b, c \in \mathbb{Z}_m$, we have:
@steps
\[
\begin{split}
a +_m (b +_m c) &= a +_m \overline{b + c}
\\&
@nstep{= \overline{a + \overline{b + c}}}
\\&
@nstep{= \overline{\overline{a} + \overline{b + c}}}
\\&
@nstep{= \overline{a + (b + c)}}
\end{split}
\]
@endsteps
@col
But $a + (b + c)$ is equal to $(a + b) + c$, since addition for integers is associative.  Hence, the above expression
is equal to:
@steps
\[
\begin{split}
\overline{(a + b) + c} &= \overline{\overline{(a + b)} + \overline{c}}
\\&
@nstep{= \overline{\overline{a + b} + {c}}}
\\&
@nstep{= \overline{(a +_m b) + c}}
\\&
@nstep{= (a +_m b) +_m c.}
\end{split}
\]
@endsteps
@col
We conclude that $+_m$ is associative.
@endcol
<hr/>
@li
<strong>Exercise:</strong> We can take 0 to be the additive identity element.
@li
For each nonzero element $a \in \mathbb{Z}_m$, we can take the additive inverse of $a$ to be $m - a$.
Indeed, $a +_m (-a)  = \overline{a + (m - a)} = \overline{m} = 0$.
@li
By the same reasoning used in the case of addition,
for $r_1, r_2 \in \mathbb{Z}$, we have
\[
\ol{r_1 r_2} \equiv r_1r_2 \equiv \ol{r_1}\cdot\ol{r_2}
\equiv \ol{\ol{r_1}\cdot\ol{r_2}} \mod m.
\]

For $a, b, c \in \mathbb{Z}_m$, we have:
\[
a\times_m(b\times_mc) = a\times_m\overline{bc} = \ol{\ol{a}\cdot\ol{bc}} = \ol{a(bc)},
\]
which by the associativity of multiplication for integers is equal to:
\[
\ol{(ab) c} = \ol{\ol{ab}\cdot\ol{c}} = \ol{ab}\times_m c = (a\times_m b)\times_m c.
\]
So, $\times_m$ is associative.
@li
<strong>Exercise:</strong> We can take $1$ to be the multiplicative identity.
@li
For $a, b \in \mathbb{Z}_m$, $a\times_m b =\ol{a\cdot b} = \ol{b\cdot a} = b\times_ma$.  So $\times_m$ is commutative.
@li
Lastly, we need to prove distributativity.
For $a, b, c \in \mathbb{Z}_m$, we have:
@steps
\[
\begin{split}
a \times_m (b +_m c) &= \ol{\ol{a} \cdot \ol{b + c}}
\\&
@nstep{= \ol{a \cdot (b + c)}}
\\&
@nstep{= \ol{ab + ac}}
\\&
@nstep{= \ol{\ol{ab} + \ol{ac}}}
\\&
@nstep{= a\times_m b +_m a\times_m c.}
\end{split}
\]
@endsteps
@newcol
It now follows from the distributativity from the left, proven above,
and the commutativity of $\times_m$,
that distributativity from the right also holds:
\[
(a +_m b) \times_m c = a\times_m c + b\times_m c.
\]
@endcol
@endol
@qed
@endcol
@end
@section{Integral Domains, Units}
@defn
A nonzero commutative ring $R$ is an @keyword{integral domain} if
the product of two nonzero elements is always nonzero.
@end

@defn
@newcol
A nonzero element $r$ in a ring $R$ is called a @keyword{zero divisor} if
there exists nonzero $s \in R$ such that $rs = 0$ or $sr = 0$.
@endcol
@end

<strong>Note.</strong>
@newcol
A nonzero commutative ring $R$ is an integral domain if and only if
it has no zero divisors.
@endcol

@eg
@newcol
Since $2, 3 \neq 0$ in $\mathbb{Z}_6$, but
$2 \times_6 3 = \bar{6} = 0$,
the ring $\mathbb{Z}_6$ is not an integral domain.
@endcol
@end

@slide

@claim
A commutative ring $R$ is an integral domain if and only if
the @keyword{cancellation law} holds for multiplication.  That is:
Whenever $ca = cb$ and $c\neq 0$, we have $a = b$.
@end
@proof
@newcol
Suppose $R$ is an integral domain.

@col
If $ca = cb$, then by distributativity $c(a - b) = c(a + -b) = 0$.

@col
Since $R$ is an integral domain,
we have either $c = 0$ or $a - b = 0$.

@col
So, if $c \neq 0$, we must have
$a = b$.

@col
Conversely, suppose cancellation law holds.
It suffices to show that whenever we have $a, b \in R$ such that $ab = 0$ and $a \neq 0$,
then we must have $b = 0$.

@col
By a previous result we know that $0 = a0$.
So, $ab = a0$, which by the cancellation law implies that $b = 0$.
@qed
@endcol
@end

<strong>Note.</strong>
@newcol
If every nonzero element of a commutative ring has a multiplicative inverse,
then that ring is an integral domain:
\[
ca = cb \implies c^{-1} ca = c^{-1}cb\implies a = b.
\]
However, a nonzero element of an integral domain does not
necessarily have a multiplicative inverse.
@endcol
@slide
@eg
The ring $\mathbb{Z}$ is an integral domain, for the product of two nonzero integers is nonzero.
So, the cancellation law holds for $\mathbb{Z}$, but the only nonzero elements in $\mathbb{Z}$
which have multiplicative inverses are $\pm 1$.
@end

@eg
@newcol
The ring $\mathbb{Q}[x]$ is an integral domain.
@endcol
@end

@ex
@label{ex:zmintdom}
@newcol
Show that:
For $m > 1$,
$\mathbb{Z}_m$ is an integral domain if and only if $m$ is a prime.
@endcol
@end
@slide
@eg
Consider $R = C[-1, 1]$, the ring of all continuous functions on $[-1, 1]$, equipped with
the usual operations of addition and multiplication for functions.

@newcol
Let:
\[
f(x) = \begin{cases}
-x, & -1 \leq x \leq 0,\\
0, & 0 < x \leq 1.
\end{cases}
\quad,\quad
g(x) = \begin{cases}
0, & -1 \leq x \leq 0,\\
x, & 0 < x \leq 1.
\end{cases}
\]
@col
Then $f$ and $g$ are nonzero elements of $R$, but $fg = 0$.

@col
So $R$ is not an integral domain.
@endcol
@end

@slide
@defn
We say that an element $r \in R$ is a @keyword{unit} if it has a multiplicative inverse; i.e.
there is an element $r^{-1} \in R$ such that $rr^{-1} = r^{-1} r = 1$.
@end

@eg
@newcol
Consider $4 \in \mathbb{Z}_{25}$.  Since $4\cdot 19 = 76 \equiv 1 \mod 25$,
we have $4^{-1} = 19$ in $\mathbb{Z}_{25}$.  So, $4$ is a unit in $\mathbb{Z}_{25}$.

@col
On the other hand, consider $10 \in \mathbb{Z}_{25}$.  Since $10 \cdot 5 = 50 \equiv 0 \mod 25$,
we have $10 \cdot 5 = 0$ in $\mathbb{Z}_{25}$.  If $10^{-1}$ exists, then by the associativity
of multiplication, we would have:
\[
5 = (10^{-1}\cdot 10)\cdot 5 = 10^{-1} \cdot (10 \cdot 5) = 10^{-1} \cdot 0 = 0,
\]
a contradiction.  So, $10$ is not a unit in $\mathbb{Z}_{25}$.
@endcol
@end

@slide
@claim
Let $m \in \mathbb{N}$ be greater than one.  Then, $r \in \mathbb{Z}_m$ is a unit
if and only if $r$ and $m$ are relatively prime; i.e. $gcd(r, m) = 1$.
@end
@proof
@newcol
Suppose $r \in \{0, 1, 2,\ldots, m - 1\}$ is a unit in $\mathbb{Z}_m$, then
there exists $r^{-1} \in \mathbb{Z}_m$ such that $r\cdot r^{-1} \equiv 1 \mod m$.

@col
In other words,
there exists $x \in \mathbb{Z}$ such that $r\cdot r^{-1} - 1 = mx$, or $r\cdot r^{-1} - mx = 1$.
This implies that if there is an integer $d$ such that  $d | r$ and $d | m$,
then $d$ must also divide $1$.  Hence, the GCD of $r$ and $m$ is $1$.

@col
Conversely, if $gcd(r, m) = 1$, then there exists $x, y \in \mathbb{Z}$ such that $rx + my = 1$.

@col
It follows that $r^{-1} = \ol{x}$ is a multiplicative inverse of $r$.
Here, $\ol{x} \in \mathbb{Z}_m$ is the remainder of the division of $x$ by $m$.
@qed
@endcol
@end

@cor
@label{cor:zpfield}
@newcol
For $p$ prime, every nonzero element of $\mathbb{Z}_p$ is a unit.
@endcol
@end

@slide
@eg
The only units of $\mathbb{Z}$ are $\pm 1$.
@end

@eg
@newcol
Let $R$ be the ring of all real-valued functions on $\mathbb{R}$.
Then, any function $f \in R$  satisfying $f(x) \neq 0$, $\forall x$, is a unit.
@endcol
@end

<!-- @eg
@newcol
Let $R$ be the ring of all continuous real-valued functions on $\mathbb{R}$,
then $f \in R$ is a unit if and only if it is either strictly positive or strictly negative.
@endcol
@end -->

@slide
@claim
The only units of $\mathbb{Q}[x]$ are nonzero constants.
@end
@proof
@newcol
Given any $f \in \mathbb{Q}[x]$ such that $\deg f > 0$, for all nonzero $g \in \mathbb{Q}[x]$ we have
\[
\deg fg \geq \deg f > 0 = \deg 1;
\]
hence, $fg \neq 1$.  If $g = 0$, then $fg = 0 \neq 1$.
So, $f$ has no multiplicative inverse.

@col
If $f$ is a nonzero constant, then $f^{-1} = \frac{1}{f}$ is a constant polynomial in $\mathbb{Q}[x]$, and
$f\cdot \frac{1}{f} = \frac{1}{f}\cdot f = 1$.  So, $f$ is a unit.

@col
Finally, if $f = 0$, then $fg = 0 \neq 1$ for all $g \in \mathbb{Q}[x]$, so the zero polynomial
has no multiplicative inverse.
@qed
@endcol
@end
@subsection{WeBWorK}
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition10.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition3.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition7.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition9.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition8.pg}
@endenumerate
@section{Fields}
@defn
A @keyword{field} is a commutative ring, with $1 \neq 0$, in which every nonzero element is a unit.
@end
@newcol
In other words, a nonzero commutative ring $F$ is a field if and only if every nonzero element $r \in F$
has a multiplicative inverse $r^{-1}$, i.e. $r r^{-1} = r^{-1} r = 1$.

@col
Since every nonzero element of a field is a unit, a field is necessarily an integral domain,
but an integral domain is not necessarily a field.  For example $\mathbb{Z}$ is an integral domain
which is not a field.

@endcol
@slide
@eg
@ol
@li
$\mathbb{Q}$, $\mathbb{R}$ are fields.
@li
For $m \in \mathbb{N}$,
it follows from a previous result that $\mathbb{Z}_m$ is a field if and only if $m$ is prime. <br/><strong>Notation</strong>
@newcol
For $p$ prime, we often denote the field $\mathbb{Z}_p$ by $\mathbb{F}_p$.
@endcol
@endol
@end

@slide
@claim
Equipped with the usual operations of addition and multiplications for real numbers,
$F = \mathbb{Q}[\sqrt{2}] := \{a + b\sqrt{2}|a, b \in \mathbb{Q}\}$ is a field.
@end
@proof
@newcol
Observe that:
$(a + b\sqrt{2}) + (c + d\sqrt{2}) = (a + c) + (b + d)\sqrt{2}$ lies in $F$,
and $(a + b\sqrt{2})(c + d\sqrt{2}) = (ac + 2bd) + (ad + bc)\sqrt{2} \in F$.
Hence, addition and multiplication for real numbers are well-defined operations on
$F$.
As operations on $\mathbb{R}$,
they are commutative, associative, and satisfy distributativity;
therefore, as $F$ is a subset of $\mathbb{R}$,
they also satisfy these properties as operations on $F$.

@col
It is clear that $0$ and $1$
are the additive and multiplicative identities of $F$.
Given $a + b\sqrt{2} \in F$, where $a, b \in \mathbb{Q}$, it is clear that
its additive inverse $-a - b\sqrt{2}$ also lies in $F$.
Hence, $F$ is a commutative ring.

@col
To show that $F$ is a field, for every nonzero $a + b \sqrt{2}$ in $F$, we need to find its multiplicative inverse.  As an element of the field $\mathbb{R}$, the multiplicative inverse of $a + b\sqrt{2}$ is:
\[
(a + b\sqrt{2})^{-1} = \frac{1}{a + b\sqrt{2}}.
\]
@col
It remains to show that this number lies in $F$.
Observe that:
\[
(a + b\sqrt{2})(a - b\sqrt{2}) = a^2 - 2b^2.
\]
We claim that $a^2 - 2b^2 \neq 0$.

@col
Suppose $a^2 - 2b^2 = 0$, then either (i) $a = b = 0$, or (ii) $b\neq 0$, $\sqrt{2} = \abs{a/b}$.

@col
Since we have assumed that $a + b\sqrt{2}$ is nonzero, case (i) cannot hold.

@col
But case (ii) also cannot hold because $\sqrt{2}$ is known to be irrational.
Hence $a^2 - 2b^2 \neq 0$, and:
\[
\frac{1}{a + b\sqrt{2}} = \frac{a}{a^2 - 2b^2} - \frac{b}{a^2 - 2b^2}\sqrt{2},
\]
which lies in $F$.
@qed
@endcol
@end

@slide
@claim
All finite integral domains are fields.
@end
@proof
@newcol
Let $R$ be an integral domain with $n$ elements, where $n$ is finite.
Write $R = \{a_1, a_2, \ldots, a_{n}\}$.

@col
We want to show that for any nonzero element $a \neq 0$ in $R$,
there exists $i$, $1 \leq i \leq n$,
such that $a_i$ is the multiplicative inverse of $a$.

@col
Consider the set $S = \{aa_1, aa_2,\ldots, aa_{n}\}$.
Since $R$ is an integral domain, the cancellation law holds.
In particular, since $a \neq 0$, we have $aa_i = aa_j$ if and only if $i = j$.

@col
The set $S$ is therefore a subset of $R$ with $n$ distinct elements, which implies that $S = R$.

@col
In particular, $1 = aa_i$ for some $i$.  This $a_i$ is the multiplicative inverse of $a$.
@qed
@endcol
@end
@subsection{Field of Fractions}
An integral domain fails to be a field precisely when there is a nonzero element
with no multiplicative inverse.
The ring $\mathbb{Z}$ is such an example, for $2 \in \mathbb{Z}$ has no
multiplicative inverse.

@newcol
But any nonzero $n \in \mathbb{Z}$
has a multiplicative inverse $\frac{1}{n}$ in $\mathbb{Q}$, which is a field.

@col
So, a question one could ask is, can we "enlarge" a given integral domain to a field,
by formally adding multiplicative inverses to the ring?
@endcol
@subsubsection{An Equivalence Relation}
<br/>
Given an integral domain $R$ (commutative, with $1 \neq 0$).  We consider the set:
$R \times R_{\neq 0} := \{(a, b) : a, b \in R, b\neq 0\}$.
We define a relation $\equiv$ on $R \times R_{\neq 0}$ as follows:
\[
(a, b) \equiv (c, d) \text{ if } ad = bc.
\]
@lemma
@newcol
The relation $\equiv$ is an equivalence relation.

@col
In other words, the relation $\equiv$ is: <ol>
<li>
<strong>Reflexive:</strong> $(a, b) \equiv (a, b)$ for all $(a, b) \in R\times R_{\neq 0}$ </li>
<li>
<strong>Symmetric:</strong> If $(a, b) \equiv (c, d)$, then $(c, d) \equiv (a, b)$. </li>
<li>
<strong>Transitive:</strong> If $(a, b) \equiv (c, d)$ and $(c, d) \equiv (e, f)$,
then $(a, b) \equiv (e, f)$. </li></ol>
@endcol
@end
@proof
@newcol
<strong>Exercise.</strong>
@endcol
@end

@slide
Due to the properties (reflexive, symmetric, transitive),
of an equivalence relation, the equivalent classes form a @keyword{partition} of
$S$.  Namely, equivalent classes of non-equivalent elements are disjoint:
\[
[s] \cap [t] = \varnothing
\]
if $s \not\sim t$;
and the union of all equivalent classes is equal to $S$:
\[
\bigcup_{s \in S} [s] = S.
\]

@defn
@newcol
Given an equivalence relation $\sim$ on a set $S$,
the @keyword{quotient set} $S/\sim$ is the set of all equivalence classes
of $S$, with respect to $\sim$.
@endcol
@end

@slide
We now return to our specific situation of $R \times R_{\neq 0}$, with $\equiv$ defined as above.
We define addition $+$ and multiplication $\cdot$ on $R\times R_{\neq 0}$ as follows:
\[
\begin{split}
(a, b) + (c, d) &:= (ad + bc, bd)\\
(a, b)\cdot(c, d) &:= (ac, bd)
\end{split}
\]
@claim
Suppose $(a, b) \equiv (a', b')$ and $(c, d) \equiv (c', d')$, then:
@ol
@li
$(a, b) + (c, d) \equiv (a', b') + (c', d')$.
@li
$(a, b)\cdot(c, d) \equiv (a', b') \cdot (c', d')$.
@endol
@end
@proof
@newcol
By definition, $(a, b) + (c, d) = (ad + bc, bd)$,
and $(a', b') + (c', d') = (a'd' + b'c', b'd')$.
Since by assumption $ab' = a'b$ and $cd' = c'd$,

@col
we have:
\[
(ad + bc)b'd' = adb'd' + bcb'd' = a'b dd' + c'd bb' = (a'd' + b'c')bd;
\]
hence, $(a, b) + (c, d) \equiv (a', b') + (c', d')$.

@col
For multiplication, by definition we have $(a, b)\cdot(c, d) = (ac, bd)$
and $(a', b')\cdot(c', d') = (a'c', b'd')$.

@col
Since
\[
acb'd' = ab'cd' = a'bc'd = a'c'bd,
\]
we have $(a, b)\cdot(c, d) \equiv (a', b')\cdot(c', d')$.
@qed
@endcol
@end
@slide
Let:
\[
\mathrm{Frac}(R) := (R \times R_{\neq 0})/\equiv,
\]
and define $+$ and $\cdot$ on $\mathrm{Frac}(R)$ as follows:
\[
\begin{split}
[(a, b)] + [(c, d)] &= [(ad + bc, bd)]\\
[(a, b)]\cdot[(c, d)] &= [(ac, bd)]
\end{split}
\]
@cor
@newcol
$+$ and $\cdot$ thus defined are well-defined binary operations on $\mathrm{Frac}(R)$.

@col
In other words, we get the same output in $\mathrm{Frac}(R)$
regardless of the choice of representatives of the equivalence classes.
@endcol
@end

@claim
@newcol
The set $\mathrm{Frac}(R)$, equipped with $+$ and $\cdot$ defined as above,
forms a field, with additive identity $0 = [(0, 1)]$
and multiplicative identity $1 = [(1, 1)]$.
The multiplicative inverse of a nonzero element
$[(a, b)] \in \mathrm{Frac}(R)$ is $[(b, a)]$.
@endcol
@end
@proof
@newcol
<strong>Exercise.</strong>
@endcol
@end

@slide
@defn
$\mathrm{Frac}(R)$ is called the @keyword{Fraction Field} of $R$.
@end

<strong>Note.</strong>
@newcol
$\mathrm{Frac}(\mathbb{Z}) = \mathbb{Q}$,
if we identify $a/b \in \mathbb{Q}$, $a, b \in \mathbb{Z}$,
with $[(a, b)] \in \mathrm{Frac}(\mathbb{Z})$.
@endcol
@subsection{WeBWorK}
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition9.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition8.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition5.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition6.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition2.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsIdealsHomomorphisms/RingsIdealsHomomorphisms1.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition7.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition1.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition10.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsDefinition/RingsDefinition12.pg}
@endenumerate@course{Math 2070}
@week{9}
@topic{Ring Homomorphisms}
@section{Homomorphisms}
@defn
Let $(A, +_A, \cdot_A)$, $(B, +_B, \cdot_B)$ be rings.  A @keyword{ring homomorphism} from $A$ to $B$
is a map $\phi: A \rightarrow B$ with the following properties:
@ol
@li
$\phi(1_A) = 1_B$.
@li
$\phi(a_1 +_A a_2) = \phi(a_1) +_B \phi(a_2)$, for all $a_1, a_2 \in A$.
@li
$\phi(a_1\cdot_A a_2) = \phi(a_1)\cdot_B \phi(a_2)$, for all $a_1, a_2 \in A$.
@endol
@end

Note that if $\phi : A \rightarrow B$ is a homomorphism, then:
@ol
@li
\[
\phi(0_A) + \phi(0_A) = \phi(0_A + 0_A) = \phi(0_A).
\]
Adding $-\phi(0_A)$ to both sides, we have:
\[
\phi(0_A) = 0_B.
\]
<!--
\[
1 = \phi(1) = \phi(1 + 0) = \phi(1) + \phi(0) = 1 + \phi(0),
\]
-->
@li
For all $a \in A$, $0 = \phi(0) = \phi(-a + a) = \phi(-a) + \phi(a)$,
which implies that $\phi(-a) = -\phi(a)$.
@li
If $u$ is a unit in $A$, then $1 = \phi(u\cdot u^{-1}) = \phi(u)\phi(u^{-1})$,
and $1 = \phi(u^{-1}\cdot u) = \phi(u^{-1})\phi(u)$;
which implies that $\phi(u)$ is a unit, with $\phi(u)^{-1} = \phi(u^{-1})$.
@endol

@slide
@eg
The map $\phi : \mathbb{Z}\rightarrow \mathbb{Q}$ defined by:
\[
\phi(n) = \frac{n}{1}, \quad n \in \mathbb{Z},
\]
is a homomorphism, since:
@ol
@li
$\phi(1) = \frac{1}{1} = 1_{\mathbb{Q}}$,
@li
$\phi(n +_\mathbb{Z} m)  = \frac{n + m}{1}
= \frac{n}{1} +_{\mathbb{Q}} \frac{m}{1}
= \phi(n) +_{\mathbb{Q}} \phi(m)$.
@li
$\phi(n \cdot_\mathbb{Z} m)
= \frac{nm}{1} = \frac{n}{1} \cdot_{\mathbb{Q}} \frac{m}{1}
= \phi(n)\cdot_{\mathbb{Q}} \phi(m).
$
@endol
@end

@slide
@eg
Fix an integer $m$ which is larger than $1$.  For $n \in \mathbb{Z}$, let $\ol{n}$ denote the remainder of the division
of $n$ by $m$.  That is:
\[
n = mq + \bar{n}, \quad 0 \leq \bar{n} < m
\]
Recall that $\mathbb{Z}_m = \{0, 1, 2, \ldots, m - 1\}$ is a ring,
with the addition law defined by:
\[
s +_m t = \ol{s + t},
\]
and the multiplication law defined by:
\[
s\times_m t = \ol{s\cdot t},
\]
for all $s, t \in \mathbb{Z}_m$.  Here, $+$ and $\cdot$ are the usual
addition and multiplication for integers.

@newcol
Define a map $\phi : \mathbb{Z} \rightarrow \mathbb{Z}_m $ as follows:
\[
\phi(n) = \ol{n}, \quad \forall n \in \mathbb{Z}.
\]
@col
Then, $\phi$ is a homomorphism.
@endcol
@end
@proof
@newcol
@ol
@li
$\phi(1) = \ol{1} = 1$,
@li
$\phi(s + t) = \ol{s + t} = \ol{\ol{s} + \ol{t}} = \ol{s} +_m \ol{t} = \phi(s) +_m \phi(t)$.
@li
$\phi(s \cdot t) = \ol{s\cdot t} = \ol{\ol{s}\cdot\ol{t}} = \ol{s}\times_m\ol{t} = \phi(s)\times_m\phi(t)$.
@endol
@qed
@endcol
@end

@slide
@eg
For any ring $R$, define a map $\phi : \mathbb{Z} \rightarrow R$ as follows:
\[
\phi(0) = 0;
\]
@newcol
For $n \in \mathbb{N}$,
\[
\phi(n) =  n\cdot 1_R := \underbrace{1_R + 1_R + \cdots + 1_R}_{n\text{ times }};
\]
@col
\[
\phi(-n) =  -n\cdot 1_R := n\cdot(-1_R) =  \underbrace{(-1_R) + (-1_R) + \cdots + (-1_R)}_{n\text{ times}}.
\]
@col
The map $\phi$ is a homomorphism.
@endcol
@end
@proof
@newcol
@keyword{Exercise.}
@endcol
@end

@slide
@keyword*{evaluation homomorphism}
@eg
@label{eg:evalhomom}
Let $R$ be a commutative ring.  For each element $r \in R$,
we may define the <strong>evaluation map</strong> $\phi_r : R[x] \rightarrow R$ as follows:
\[
\phi_r\left(\sum_{k = 0}^n a_k x^k\right) = \sum_{k = 0}^n a_k r^k
\]
The map $\phi_r$ is a ring homomorphism.
@end
@proof
<em>Discussed in class.</em>
@end

@slide
@defn
If a ring homomorphism $\phi: A \rightarrow B$ is a bijective map, we say that $\phi$ is an @keyword{isomorphism},
and that $A$ and $B$ are @keyword{isomorphic} as rings.
@end

<strong>Notation</strong>
@newcol
If $A$ and $B$ are isomorphic, we write $A \cong B$.
@endcol

@slide
@claim
If $\phi:A \rightarrow B$ is an isomorphism, then $\phi^{-1} : B \rightarrow A$ is an isomorphism.
@end
@proof
@newcol
Since $\phi$ is bijective, $\phi^{-1}$ is clearly bijective.  It remains to show that $\phi^{-1}$ is a homomorphism:
<ol>
<li> Since $\phi(1_A) = 1_B$, we have $\phi^{-1}(1_B) = \phi^{-1}(\phi(1_A)) = 1_A$. </li>
<li> For all $b_1, b_2 \in B$, we have
\begin{multline*}
\phi^{-1}(b_1 + b_2) = \phi^{-1}(\phi(\phi^{-1}(b_1)) + \phi(\phi^{-1}(b_2)))
\\= \phi^{-1}(\phi(\phi^{-1}(b_1) + \phi^{-1}(b_2))) = \phi^{-1}(b_1) + \phi^{-1}(b_2)
\end{multline*} </li>
<li> For all $b_1, b_2 \in B$, we have
\begin{multline*}
\phi^{-1}(b_1 \cdot b_2) = \phi^{-1}(\phi(\phi^{-1}(b_1)) \cdot \phi(\phi^{-1}(b_2)))
\\= \phi^{-1}(\phi(\phi^{-1}(b_1) \cdot \phi^{-1}(b_2))) = \phi^{-1}(b_1) \cdot \phi^{-1}(b_2)
\end{multline*} </li></ol>
This shows that $\phi^{-1}$ is a bijective homomorphism.
@qed
@endcol
@end
@course{Math 2070}
@week{10}
@topic{Ideals}
@topic{Principal Ideal Domains}
@topic{Quotient Rings}
@section{Ring Homomorphisms - continued}
An isomorphism is more than simply a bijective map,
for it must preserve algebraic structure.

@newcol
For example, there is a bijective map
$f : \mathbb{Z} \rightarrow \mathbb{Q}$
,
but the two are clearly not isomorphic as rings:

@col
Suppose $\phi : \mathbb{Z}\rightarrow \mathbb{Q}$
is an isomorphism.
Then, both $\phi$ and $\phi^{-1}$ must send units to units.

@col
Consider $2 \in \mathbb{Q}$.
Since $\mathbb{Q}$ is a field, the nonzero element $2$ is a unit.
So $\phi^{-1}(2)$ must be a unit of $\mathbb{Z}$.

@col
But the only units of $\mathbb{Z}$ are $\pm 1$.
Since $\phi$ is an homomorphism, we have $\phi(1) = 1 \neq 2$.

@col
So, we are left with the case $\phi(-1) = 2$.  This cannot hold either,
since:

@col
\[
1 = \phi((-1)(-1)) = \phi(-1)\phi(-1)
\]
implies that $\phi(-1)$ could only be $\pm 1 \neq 2$.

@col
So, $\mathbb{Z}$ and $\mathbb{Q}$ cannot be isomorphic.
@endcol

@slide
@thm
The fields $\mathbb{Q}$ and $\mathrm{Frac}(\mathbb{Z})$ are isomorphic.
@end
@proof
@newcol
Define a map $\phi: \mathbb{Q} \rightarrow \mathrm{Frac}(\mathbb{Z})$ as follows:
\[
\phi(a/b) = [(a, b)],\quad \forall\, a/b \in \mathbb{Q}, a, b \in \mathbb{Z}, b \neq 0.
\]
@col
We first need to show that $\phi$ is well-defined.
Namely, suppose $a/b = c/d$ in $\mathbb{Q}$,
we need to show that $\phi(a/b) = [(a, b)]$ is equal to $\phi(c/d) = [(c, d)]$.

@col
This is clear, since $a/b = c/d$ implies that $ad = bc$,
which by definition of $\Frac(\mathbb{Z})$ implies that $[(a, b)] = [(c, d)]$.

@col
We now show that $\phi$ is a homomorphism:

@col
@ol
@li
$\phi(1) = \phi(1/1) = [(1, 1)]$, which is indeed the multiplicative identity of $\Frac(\mathbb{Z})$.
@li
For $a, b, c, d \in \mathbb{Z}$, $b, d \neq 0$, we have:
\begin{multline*}
\phi(a/b + c/d) = \phi((ad + bc)/(bd)) = [(ad + bc, bd)]\\
= [(a, b)] + [(c, d)] = \phi(a/b) + \phi(c/d)
\end{multline*}
@li
For $a, b, c, d \in \mathbb{Z}$, $b, d \neq 0$, we have:
\begin{multline*}
\phi((a/b)(c/d)) = \phi((ac)/(bd)) = [(ac, bd)]\\
= [(a, b)]\cdot[(c, d)] = \phi(a/b)\phi(c/d)
\end{multline*}
@endol
@col
Finally, we need to show that $\phi$ is one-to-one and onto.

@col
Suppose there are $a, b, c, d \in \mathbb{Z}$ such that $\phi(a/b) = \phi(c/d)$.
Then, by definition of $\phi$ we have $[(a, b)] = [(c, d)]$,
which implies that $ad = bc$,
from which it follows that $a/b = c/d$ as elements of $\mathbb{Q}$.
So, $\phi$ is one-to-one.

@col
Given $[(a, b)] \in \Frac(\mathbb{Z})$, $a, b\in \mathbb{Z}$, $b \neq 0$,
it is clear that
$a/b$ belongs to $\mathbb{Q}$, and $\phi(a/b) = [(a, b)]$.
So $\phi$ is onto.

@col
Hence, $\phi$ is a bijective homomorphism.  In other words, it is an isomorphism.
@qed
@endcol
@end

@slide
@thm
If $F$ is a field, then $\Frac(F) \cong F$.
@end
@proof
@newcol
Define a map $\phi : F \rightarrow \Frac(F)$ as follows:
\[
\phi(s) = [(s, 1)],\quad \forall s \in F.
\] @keyword{Exercise:}

<ol>
<li> Show that $\phi$ is a homomorphism. </li>
<li> Show that $\phi$ is bijective. </li></ol>
@qed
@endcol
@end

@slide
@defn
The @keyword{kernel} of a ring homomorphism $\phi : A \rightarrow B$
is the set:
\[
\ker \phi := \{a \in A : \phi(a) = 0\}
\]
The @keyword{image} of $\phi$ is the set:
\[
\im \phi := \{b \in B : b = \phi(a) \text{ for some } a \in A\}.
\]
@end
@slide
@claim
@label{claim:onetooneker}
A ring homomorphism $\phi : A \rightarrow B$ is one-to-one if and only if $\ker \phi = \{0\}$.
@end
@proof
@newcol
Suppose $\phi$ is one-to-one.
For any $a \in \ker \phi$, we have $\phi(0) = \phi(a) = 0$,
which implies that $a = 0$ since $\phi$ is one-to-one.  Hence, $\ker \phi = \{0\}$.

Suppose $\ker \phi = \{0\}$.  If $\phi(a) = \phi(a')$,
then:
\[
0 = \phi(a) + \left(-\phi(a')\right)
= \phi(a) + \left(\phi(-a')\right) 
= \phi(a + (-a')),
\]
which implies that $a + (-a') \in \ker \phi = \{0\}$.
So, $a + (-a') = 0$, which implies that $a = a'$.  Hence, $\phi$ is one-to-one.
@qed
@endcol
@end
@slide
@defn
An @keyword{ideal} $I$ in a commutative ring $R$ is a subset of $R$ which satisfies
the following properties:
@ol
@li
$0 \in I$;
@li
If $a, b \in I$, then $a + b \in I$.
@li
For all $a \in I$, we have $ar \in I$ for all $r \in R$.
@endol
@newcol
If an ideal $I$ is a proper subset of $R$, we say it is a @keyword{proper ideal} .
@endcol
@end

<strong>Note.</strong>
@newcol
If an ideal $I$ contains $1$, then $r = 1 \cdot r \in I$ for all $r \in R$,
which implies that $I = R$.
@endcol

<strong>Remark.</strong>
@newcol
There is a definition of an @keyword{ideal} in the more general case where the ring is not necessarily commutative.
It is similar to the definition above, except for one extra condition:
$ra$ belongs to $I$ for all $a \in I$, $r\in R$.

Clearly,
this general definition coincides with the one above in the special case that
the ring is commutative. <p/> In this introductory course, unless otherwise noted,
we will always discuss ideals in the context of commutative rings.
@endcol
@slide
@eg
For any commutative ring $R$, the set $\{0\}$ is an ideal,
since $0 + 0 = 0$, and $0\cdot r = 0$ for all $r \in R$.
@end

@eg
@newcol
For all $m \in \mathbb{Z}$, the set $I = m\mathbb{Z}:=\{mn : n \in \mathbb{Z}\}$ is an ideal:
@ol
@li
$0 = m\cdot 0 \in I$;
@li
$mn_1 + mn_2 = m(n_1 + n_2) \in I$.
@li
Given $mn \in I$, for all $l \in \mathbb{Z}$, we have $mn\cdot l = m \cdot nl \in I$.
@endol
@endcol
@end

@slide
@eg
Recall the homomorphism $\phi : \mathbb{Z}\rightarrow \mathbb{Z}_m$ defined by $\phi(n) = \ol{n}$.
We claim that the kernel of $\phi$ is:
\[
\ker \phi = m\mathbb{Z}.
\]
@end
@proof
@newcol
If $\phi(n) = \ol{n} = 0$, then $n = mq + 0 = mq$ for some $q \in \mathbb{Z}$.  So, $n \in m\mathbb{Z}$.
Hence, $\ker \phi \subseteq m\mathbb{Z}$.

Given $mn \in m\mathbb{Z}$, where $n \in \mathbb{Z}$, the remainder $\ol{mn}$ of the division of $mn$ by $m$
is clearly $0$, so $\phi(mn) = 0$, which implies that $m \mathbb{Z}\subseteq \ker \phi$.

Hence, $\ker \phi = m\mathbb{Z}$.
@endcol
@end

@slide
@claim
Let $A$ be a commutative ring.
If $\phi : A \rightarrow B$ is a ring homomorphism, then $\ker \phi$ is an ideal of $A$.
@end
@proof
@newcol
@ol
@li
Since $\phi$ is a homomorphism, we have $\phi(0) = 0$.
Hence, $0 \in \ker \phi$.
@li
If $a, b \in \ker \phi$, then $\phi(a + b) = \phi(a) + \phi(b) = 0 + 0 = 0$.
Hence, $a + b \in \ker \phi$.
@li
Given any $a \in \ker \phi$, for all $r \in R$
we have $\phi(ar) = \phi(a)\phi(r) = 0\cdot \phi(r) = 0$.
Hence, $ar \in \ker \phi$ for all $r \in R$.
@endol
@endcol
@end

<h5>Remark.</h5>
The claim still holds if we remove the requirement that $A$ be commutative,
and "ideal" is defined using the more general definition mentioned earlier.

@subsection{WeBWorK}
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsIdealsHomomorphisms/RingsIdealsHomomorphisms5.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsIdealsHomomorphisms/RingsIdealsHomomorphisms7.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsIdealsHomomorphisms/RingsIdealsHomomorphisms6.pg}
@endenumerate
@section{Principal Ideals}
For a fixed finite set of elements $a_1, a_2,\ldots, a_n$ in a commutative ring $R$,
let $(a_1, a_2,\ldots, a_n)$ denote the subset:
\[
\{r_1 a_1 + r_2 a_2 + \cdots + r_n a_n : r_i \in R\}.
\]
@claim
@newcol
The set $I = (a_1, a_2, \ldots, a_n)$ is an ideal of $R$.
@endcol
@end
@proof
@newcol
@ol
@li
$0 = 0\cdot a_1 + 0 \cdot a_2 + \cdots + 0\cdot a_n \in I$.
@li
For $\sum_{i} r_i a_i$ and $\sum_i r_i'a_i$ in $I$, we have
$\sum_i r_i a_i + \sum_i r_i'a_i = \sum_i (r_i + r_i')a_i \in I$.
@li
Given any $\sum_i r_ia_i \in I$, for any $r \in R$ we have
$r \sum_i r_i a_i = \sum_i (rr_i) a_i \in I$.
@qed
@endol
@endcol
@end
@newcol
We call $(a_1, a_2,\ldots, a_n)$ the ideal @keyword{generated} by $a_1, a_2, \ldots, a_n$.
An ideal $(a) = \{ar : r \in R\}$ generated by one element $a \in R$ is called a @keyword{principal ideal} .

@col
Note that $R = (1)$ and $\{0\} = (0)$ are both principal ideals.
@endcol
@slide
@claim
A nonzero commutative ring $R$ is a field if and only if its only ideals are
$\{0\}$ and $R$.
@end
@proof
@newcol
Suppose a nonzero commutative ring $R$ is a field.
If an ideal $I$ of $R$ is nonzero, it contains at least one
nonzero element $a$ of $R$.

@col
Since $R$ is a field, $a$ has a multiplicative inverse $a^{-1}$ in $R$.
Since $I$ is an ideal, and $a \in I$, we have $1 = a^{-1} a \in I$.

@col
So, $I$ is an ideal which contains $1$,
hence it must be the whole field $R$.

@col
Conversely, let $R$ be a nonzero commutative ring whose only ideals are $\{0\}$ and $R$.

@col
Given any nonzero element $a \in R$,
the principal ideal $(a) := \{ar : r \in R\}$ generated by $a$ is nonzero because it contains $a \neq 0$.

@col
Hence, by hypothesis the ideal $(a)$ is necessarily the whole ring $R$.
In particular, the element $1$ lies in $(a)$, which means that there is an $r \in R$
such that $ar = 1$.
This shows that any nonzero element of $R$ is a unit.  Hence, $R$ is a field.
@qed
@endcol
@end
@slide
@claim
Let $k$ be a field, and $R$ a nonzero ring.  Any ring homomorphism $\phi : k \rightarrow R$ is necessarily one-to-one.
@end
@proof
@newcol
Since $R$ is not a zero ring, it contains $1 \neq 0$.  So, $\phi(1) = 1 \neq 0$, which implies that $\ker \phi$
is a proper ideal of $k$.  Since $k$ is a field, we have $\ker \phi = \{0\}$.  It now follows from a previous claim that $\phi$ is one-to-one.
@qed
@endcol
@end
@eg
@newcol
For any natural number $m  > 1$,
there can be no ring homomorphisms from $\mathbb{Q}$ to $\mathbb{Z}_m$.

The reason is as follows:

@col
By the previous claim, any ring homomorphism from the field $\mathbb{Q}$
to $\mathbb{Z}_m$ must be one-to-one, but there can be no one-to-one
map from the infinite set $\mathbb{Q}$ to the finite set $\mathbb{Z}_m$.
@endcol
@end
@slide
@claim
Given $a, b$ in a commutative ring $R$.  If $b = au$ for some unit $u \in R$,
then $(a) = (b)$.

If $R$ is an integral domain and $(a) = (b)$, then $b = au$ for some unit $u \in R$.
@end
@proof
@newcol
We leave the first part of the claim as an exercise.

@col
We now prove the second part.  Suppose $(a) = (b)$.  If $b = 0$,
then $a$ is necessarily zero.  So, $b = 0 = 0\cdot 1 = a \cdot 1$, and we are done.

@col
Now suppose $b \neq 0$.  The condition $(a) = (b)$
implies that there exist $u, v \in R$ such that $b = au$ and $a = bv$.

@col
Putting the two together, we have:
\[
b = buv,
\]
@col
which implies that $b(1 - uv) = 0$.

@col
Since $R$ is by assumption an integral domain,
and $b \neq 0$, we have $1 - uv = 0$, which implies that $uv = 1$.
This shows that $u$ is unit.
@qed
@endcol
@end

@slide
@defn
@label{def:pid}
If $R$ is an integral domain in which every ideal is principal,
we say that $R$ is a @keyword{Principal Ideal Domain} (<i>abbrev.</i> @keyword{PID}).
@end

@thm
@newcol
The ring $\mathbb{Z}$ is a principal ideal domain.
@endcol
@end
@proof
@newcol
Let $I$ be an ideal of $\mathbb{Z}$.
We already know that the zero ideal $\{0\} = (0)$ is principal.

@col
So, we may assume that $I$ contains a nonzero element $a$.  Since $-1 \in \mathbb{Z}$ and $I$ is an ideal,
we have $-a = (-1)\cdot a \in I$.  Hence, if $I$ is nonzero, it contains at least one positive integer.

@col
By the Least Integer Axiom, the ideal $I$ contains a positive integer $d$ which is smaller than all other
positive elements of $I$.  We claim that $I = (d)$.

@col
By the division theorem, for every $a \in I$, we have $a = dq + r$ for some $q, r \in \mathbb{Z}$
such that $0 \leq r < d$.  But this implies that $r = a - dq$ lies in $I$,
since $I$ is an ideal.

@col
Since $0 \leq r < d$ and $d$ is the minimal positive integer in $I$,
$r$ must necessarily be zero.
This implies that $a = dq$.  Hence, $I \subseteq (d)$.

@col
Conversely, since $d \in I$ and $I$ is an ideal, we have $dr \in I$
for all $r \in \mathbb{Z}$, which implies that $(d) \subseteq I$.

@col
Hence, $I = (d)$.  In other words, $I$ is a principal ideal generated by $d$.
@qed
@endcol
@end

@slide
We claim that for any field $k$, the ring of polynomials
$k[x]$ is also a PID.

To prove this we first establish the following theorem:

@thm
@title{Division Theorem for Polynomials with Unit Leading Coefficients}
@label{thm:divalgpoly}
Let $R$ be a commutative ring.  For all $d, f \in R[x]$, such that the leading coefficient of $d$ is a unit in $R$,
there exist $q , r \in R[x]$ such that:
\[
f = qd + r,
\]
with $\deg r < \deg d$.
@end
@proof
@newcol
The proof is essentially the same as that of the division theorem for $\mathbb{Q}[x]$.  We prove by induction:

@col
The base case corresponds to the case where $\deg f < \deg d$; and the inductive step
corresponds to showing that, for any fixed $d$, the claim holds for $f$ if it holds for all
$f'$ with $\deg f' < \deg f$.

@col
Base case: If $\deg f < \deg d$, we take $r = f$.  Then, indeed $f = 0\cdot d + r$, with $\deg r < \deg d$.

@col
Inductive step:
Let $d =\sum_{i = 0}^n a_i x^i\in R[x]$ be fixed, where $a_n$ is a unit in $R$.
For any given $f = \sum_{i = 0}^m b_ix^i \in R[x]$, $m \geq n$,
suppose the claim holds for all $f'$ with $\deg f' < \deg f$.

@col
Let:
\[
f' = f - a_n^{-1}b_m x^{m - n} d.
\]
@col
Then, $\deg f' < \deg f$, hence by hypothesis there exist $q', r' \in R[x]$, with $\deg r' < \deg d$,
such that:
\[
f - a_n^{-1}b_m x^{m - n} d = f' = q' d + r',
\]
@col
which implies that:
\[
f = (q' + a_n^{-1}b_m x^{m - n}) d + r'.
\]
@col
So, $f = qd + r'$, where $q = q' + a_n^{-1}b_m x^{m - n} \in R[x]$, and $\deg r' < \deg d$.
@qed
@endcol
@end

@slide
@thm
@label{thm:pidpoly}
Let $k$ be a field.  Then, $k[x]$ is a PID.
@end
@proof
@newcol
Since $k$ is a field, the previous claim holds for all $d, f \in k[x]$ such that $d \neq 0$.

@col
Let $I$ be an ideal of $k[x]$.

If $I = \{0\}$ then, it is principal, since $\{0\} = (0)$.

Suppose $I$ is nonzero.
Let $d$ be the polynomial in $I$ with the least degree among all nonzero polynomials
in $I$.
Since the degree of any nonzero polynomial is a nonnegative integer,
such an element $d$ exists by the Least Integer Axiom.
It is clear that $(d) \subseteq I$.  It remains to show that $I \subseteq (d)$.

@col
For all $f \in I$, by the previous claim we have:
\[
f = qd + r,
\]
for some $q, r \in k[x]$ such that $\deg r < \deg d$.

@col
Observe that $r = f - qd = f + (-1)qd$ lies in $I$.
Since $d$ is a nonzero element of $I$ with the least degree, the element $r$ must necessarily be zero.

@col
In order words $f = qd$, which implies that $f \in (d)$.
Hence, $I \subseteq (d)$, and we may now conclude that $I = (d)$.
@qed
@endcol
@end
@section{Quotient Rings}
Let $R$ be a commutative ring.  Let $I$ be an ideal of $R$.
We define a relation $\sim$ on $R$ as follows:
\[
a \sim b, \quad \text{ if } a - b \in I.
\]

<strong>Notation/Terminology:</strong> If $a \sim b$, we say that $a$ is @keyword{congruent modulo $I$} to $b$,
and write:
\[
a \equiv b \mod I.
\]

@claim
@newcol
Congruence modulo $I$ is an @keyword{equivalence relation} .
@endcol
@end
@proof
@newcol
<ul>
<li>
@keyword{Reflexivity}
@newcol
$a - a = 0 \in I$, since $I$ is an ideal; hence, $a \equiv a \mod I$.
@endcol</li>
<li>
@keyword{Symmetry}
@newcol
If $a - b \in I$, then $b - a = -1(a  - b) \in I$, since $I$
is an ideal and $-1 \in R$.  Hence, $a \equiv b \mod I$ implies that $b \equiv a \mod I$.
@endcol</li>
<li>
@keyword{Transitivity}
@newcol
If $a - b \in I$ and $b - c \in I$, then
$a - c = a + (- b + b) - c = (a - b) + (b - c) \in I$,
since $I$, being an ideal, is closed under addition.
Hence, $a \equiv b, b \equiv c \mod I$ implies that $a \equiv c \mod I$.
@qed
@endcol</li></ul>
@endcol
@end

@slide
Let $R/ I$ be the set of equivalence classes of $R$ with respect to the relation $\sim$.
Each element of $R/ I$ has the form:
\[
\ol{r} = r + I = \{r + a : a \in I\}, \quad r \in R.
\]

<h5>Terminology.</h5>
We call $\ol{r}$ the @keyword{residue} of $r$ in $R/I$.

Note that if $r \in I$, then $\bar{r} = \bar{0}$, since $r - 0 = r \in I$.

@newcol
Observe that: for all $r, r' \in R$, and $a, a' \in I$,
\[
(r + a) + (r' + a') = (r + r') + (a + a') \in (r + r') + I = \ol{r + r'},
\]
\[
(r + a)\cdot(r'+ a') = rr' + ra' + r'a + aa' \in rr' + I = \ol{rr'}.
\]
@col
Hence, we may define binary operations $+, \cdot$ on $R/I$ as follows:
\[
\begin{split}
\ol{r} + \ol{r'}  &= \ol{r + r'},\\
\ol{r}\cdot\ol{r'} &= \ol{rr'},
\end{split}
\]
for all $\ol{r},\ol{r'} \in R/ I$.
@endcol

@slide
@claim
The set $R/I$, equipped with the addition $+$ and multiplication $\cdot$ defined above,
is a commutative ring.
@end
@proof
@newcol
We note here only that the additive identity element of $R/I$ is $\ol{0} = 0 + I$,
the multiplicative identity element of $R/I$ is $\ol{1} = 1 + I$,
and that $-\ol{r} = \ol{-r}$ for all $r \in R$.

We leave the rest of the proof (additive and multiplicative associativity, commutativity, distributativity)
as an <strong>Exercise.</strong>
@endcol
@end

@claim
@newcol
The map $\pi : R \rightarrow R/I$, defined by
\[
\pi(r) = \ol{r},\quad \forall r \in R.
\]
is a surjective ring homomorphism with kernel $\ker \pi = I$.
@endcol
@end
@proof
@newcol
<strong>Exercise.</strong>
@endcol
@end

@slide
Let $m$ be a natural number.  The set:
\[
m\mathbb{Z} = \{mn : n \in \mathbb{Z}\}
\]
is an ideal of $\mathbb{Z}$.
@claim
@newcol
The quotient ring $\mathbb{Z}/m\mathbb{Z}$ is isomorphic to $\mathbb{Z}_m$.
@endcol
@end
@proof
@newcol
For $r \in \mathbb{Z}$, let $r_m$ denote the remainder of the division of $r$ by $m$.

@col
<strong>Exercise:</strong> We have $\ol{r} = \ol{r_m}$ in $\ZZ/m\ZZ$,
where $\bar{r}$ is the residue of $r$ in $\ZZ/m\ZZ$.

@col
Define a map $\phi : \mathbb{Z}_m \ra \ZZ/m\ZZ$ as follows:
\[
\phi(r) = \bar{r},\quad \forall\, r \in \ZZ_m.
\]
@col
We claim that $\phi$ is a homomorphism:
@ul
@li
$\phi(1) = \bar{1} = 1_{\ZZ/m\ZZ}$.
@li
\begin{multline*}
\phi(r +_{\ZZ_m} r') = \ol{r +_{\ZZ_m} r'} = \ol{(r +_{\ZZ} r')_m} \\
= \ol{r +_{\ZZ} r'} = \ol{r} + \ol{r'} = \phi(r) + \phi(r')
\end{multline*}
@li
\begin{multline*}
\phi(r \cdot_{\ZZ_m} r') = \ol{r \cdot_{\ZZ_m} r'} = \ol{(r \cdot_{\ZZ} r')_m}\\
= \ol{r \cdot_{\ZZ} r'} = \ol{r} \cdot \ol{r'} = \phi(r) \cdot \phi(r')
\end{multline*}
@endul
@col
Hence, $\phi$ is a homomorphism.

@col
Next, we show that $\phi$ is bijective:

@col
For all $\bar{r} \in \ZZ/m\ZZ$, we have $\phi(r_m) = \ol{r_m} = \ol{r}$.
Hence, $\phi$ is onto.

@col
Suppose $r$ is an element in $\ZZ_m$
such that $\phi(r) = \ol{r} = 0$ in $\ZZ/m\ZZ$.  By definition, this means that $r \in m\ZZ$,
or equivalently, that $m | r$.  Since $0 \leq r < m$, we must have $r = 0$.
Hence, $\ker \phi = \{0\}$.
It now follows from @ref{claim:onetooneker} that $\phi$ is one-to one.

@col
We conclude that $\phi : \ZZ_m \ra \ZZ/m\ZZ$ is an isomorphism.
@qed
@endcol
@end

@slide
@claim
Let $\phi : R \longrightarrow R'$ be a ring homomorphism.  Then, the image of $\phi$:
\[
\im \phi = \{r' \in R' : r' = \phi(r) \text{ for some } r \in R\}
\]
is a ring under the addition and multiplication operations of $R'$.
(In fact, it is a subring of $R'$.)
@end
@proof
<strong>Exercise.</strong>
@end

@slide
@thm
@title{First Isomorphism Theorem}
Let $R$ be a commutative ring.
Let $\phi : R \ra R'$ be a ring homomorphism.
Then:
\[
R/\ker\phi \cong \im \phi,
\]
(i.e. $R/\ker \phi$ is isomorphic to $\im \phi$.)
@end
@proof
@newcol
We define a map $\ol{\phi} : R/\ker\phi \ra \im \phi$ as follows:
\[
\ol{\phi}(\ol{r}) = \phi(r), \quad \forall\, r \in R,
\]
where $\ol{r}$ is the residue of $r$ in $R/\ker \phi$.

@col
We first need to check that $\phi$ is well-defined.
Suppose $\ol{r} = \ol{r'}$, then $r' - r \in \ker\phi$.
We have:
\[
\phi(r') - \phi(r) = \phi(r' - r) = 0.
\]
@col
Hence, $\phi(r') = \phi(r)$.
So, $\phib$ is well-defined.

@col
Next, we show that $\phib$ is a homomorphism:
@ul
@li
$\phib(\ol{1}) = \phi(1) = 1$;
@li
$
\phib(\ol{a} + \ol{b}) = \phib(\ol{a + b}) = \phi(a + b) = \phi(a) + \phi(b)
= \phib(\ol{a}) + \phib(\ol{b});
$
@li
$
\phib(\ol{a} \cdot \ol{b})
= \phib(\ol{ab}) = \phi(ab) = \phi(a)\phi(b) = \phib(\ol{a})\phib(\ol{b}).
$
@endul

@col
Finally, we show that $\phib$ is a bijection, i.e. one-to-one and onto.

@col
For any $r' \in\im \phi$, there exists $r \in R$ such that $\phi(r) = r'$.
Since $\phib(\ol{r}) = \phi(r) = r'$, the mapÂ $\phib$ is onto.

@col
Let $r$ be an element in $R$ such that
$\phib(\ol{r}) = \phi(r) = 0$.
We have $r \in \ker \phi$, which implies that $\ol{r} = 0$ in $R/\ker\phi$.
Hence, $\ker \phib = \{0\}$, and it follows from @ref{claim:onetooneker} that $\phib$ is one-to-one.
@qed
@endcol
@end

@slide
@cor
If a ring homomorphism $\phi : R \ra R'$ is surjective, then:
\[
R' \cong R/\ker \phi
\]
@end

@course{Math 2070}
@week{11}
@topic{Quotient Rings}
@topic{Polynomials over a Field}
@section{Quotient Rings - continued}
@eg
Let $m$ be a natural number.
Consider the map $\phi : \mathbb{Z} \ra \ZZ_m$ defined by:
\[
\phi(n) = {n}_m, \quad \forall\, n \in \mathbb{Z},
\]
where ${n}_m$ is the remainder of the division of $n$ by $m$.

<strong>Exercise:</strong> $\phi$ is a homomorphism.

It is clear that $\phi$ is surjective, and that $\ker \phi = m\ZZ$.
So, it follows from the First Isomorphism Theorem that:
\[
\ZZ_m \cong \ZZ/m\ZZ.
\]
@end
@slide
@defn
@title{Gaussian Integers}
Let:
\[
\mathbb{Z}[i] = \{z \in \mathbb{C}: z = a + bi \text{ for some } a, b \in \mathbb{Z}\},
\]
where $i = \sqrt{-1}$.
@end
@ex
@newcol
Show that the set $\mathbb{Z}[i]$ is a ring under the usual addition $+$
and multiplication $\times$ operations on $\mathbb{C}$.

Moreover, we have $0_{\mathbb{Z}[i]} = 0$, $1_{\mathbb{Z}[i]} = 1$,
and:
\[
-(a + bi) = (-a) + (-b) i
\]
for any $a, b \in \mathbb{Z}$.
@endcol
@end

@slide
@skip
@eg
The ring $\mathbb{Z}[i]/(1 + 3i)$ is isomorphic to $\mathbb{Z}/10\ZZ$.
@end
@proof
@newcol
Define a map $\phi: \ZZ \ra \ZZ[i]/(1 + 3i)$ as follows:
\[
\phi(n) = \ol{n},\quad \forall\, n \in \ZZ,
\]
where $\ol{n}$ is the residue of $n \in \ZZ[i]$ modulo $(1 + 3i)$.

@col
It is clear that $\phi$ is a homomorphism ( <strong>Exercise</strong> ).

Observe that in $\mathbb{Z}[i]$, we have:
\[
1 + 3i \equiv 0 \mod (1 + 3i),
\]
@col
which implies that:
@steps
\begin{align*}
@nstep{1} & @nstep{\equiv -3i \mod (1 + 3i)}
\\
@nstep{i\cdot 1} & @nstep{\equiv i \cdot (-3i) \mod (1 + 3i)}
\\
@nstep{i} & @nstep{\equiv 3 \mod (1 + 3i).}
\end{align*}
@endsteps
@col
Hence, for all $a, b \in \ZZ$,
\[
\ol{a + bi} = \ol{a + 3b} = \phi(a + 3b)
\]
in $\ZZ[i]/(1 + 3i)$.  Hence, $\phi$ is surjective.

@col
Suppose $n$ is an element of $\ZZ$ such that $\phi(n) = \ol{n} = 0$.
Then, by the definition of the quotient ring we have:
\[
n \in (1 + 3i).
\]
@col
This means that there exist $a, b \in \ZZ$ such that:
\[
n = (a + bi)(1 + 3i) = (a - 3b) + (3a + b)i,
\]
@col
which implies that $3a + b = 0$, or equivalently, $b = -3a$.  Hence:
\[
n = a - 3b = a - 3(-3a) = 10 a,
\]
@col
which implies that $\ker \phi \subseteq 10\ZZ$.  Conversely, for all $m \in \ZZ$,
we have:
\[
\phi(10 m) = \ol{10 m} = \ol{(1 + 3i)(1 - 3i)m} = 0
\]
in $\ZZ[i]/(1 + 3i)$.

@col
This shows that $10\ZZ \subseteq \ker \phi$.  Hence, $\ker \phi = 10\ZZ$.

@col
It now follows from the First Isomorphism Theorem that:
\[
\ZZ/10\ZZ \cong \ZZ[i]/(1 + 3i).
\]
@qed
@endcol
@end

@section{Polynomials over a Field}
Let $k$ be a field.
For $f \in k[x]$ and $a \in k$, let:
\[
f(a) = \phi_a(f),
\]
where $\phi_a$ is the @keyword{evaluation homomorphism} defined in @ref{eg:evalhomom}.
That is:
\[
\phi_a\left(\sum_{i = 0}^nc_ix^i \right) = \sum_{i = 0}^nc_ia^i .
\]

@defn
Let $f = \sum_{i = 0}^nc_ix^i$ be a polynomial in $k[x]$.
An element $a \in k$ is a @keyword{root} of $f$ if:
\[
f(a) = 0
\]
in $k$.
@end

@slide

@lemma
For all $f \in k[x]$, $a \in k$, there exists $q \in k[x]$ such that:
\[
f = q(x - a) + f(a)
\]
@end
@proof
By the @ref{thm:divalgpoly},
there exist $q, r \in k[x]$ such that:
\[
f = q(x - a) + r,\quad \deg r < \deg (x - a) = 1.
\]
This implies that $r$ is a constant polynomial.

@newcol
Applying the evaluation homomorphism $\phi_a$ to both sides of the above equation,
we have:
@steps
\[
\begin{split}
f(a) &= \phi_a(q(x - a) + r)
\\&
@nstep{= \phi_a(q)\cdot\phi_a(x - a) + \phi_a(r)}
\\&
@nstep{= q(a)(a - a) + r}
\\&
@nstep{= r.}
\end{split}
\]
@endsteps
@endcol
@end
@slide

@claim
@title{Root Theorem}
Let $k$ be a field, $f$ a polynomial in $k[x]$.  Then, $a \in k$
is a root of $f$ if and only if $(x - a)$ divides $f$ in $k[x]$.
@end
@proof
If $a \in k$ is a root of $f$, then by the previous lemma there exists $q \in k[x]$
such that:
\[
f = q(x - a) + \underbrace{f(a)}_{= 0} = q(x - a),
\]
so $(x - a)$ divides $f$ in $k[x]$.

@newcol
Conversely, if $f = q(x - a)$ for some $q \in k[x]$, then $f(a) = q(a)(a - a) = 0$.
Hence, $a$ is a root of $f$.
@endcol
@end

@slide
@thm
Let $k$ be a field, $f$ a nonzero polynomial in $k[x]$. <ol>
<li> If $f$ has degree $n$, then it has at most $n$ roots in $k$. </li>
<li> If $f$ has degree $n > 0$ and $a_1, a_2,\ldots, a_n \in k$ are distinct
roots of $f$, then:
\[
f = c\cdot \Pi_{i = 1}^n(x - a_i) := c(x - a_1)(x - a_2)\cdots (x - a_n)
\]
for some $c \in k$. </li></ol>
@end
@proof
@newcol
<ol>
<li>
@newcol
We prove Part 1 of the claim by induction.
If $f$ has degree 0, then $f$ is a nonzero constant, which implies that it has no roots.
So, in this case the claim holds. <br/>
@col
Let $f$ be a polynomial with degree $n > 0$.
Suppose the claim holds for all nonzero polynomials with degrees strictly less than $n$.
We want to show that the claim also holds for $f$.
If $f$ has no roots in $k$, then the claim holds for $f$ since $0 < n$.
If $f$ has a root $a \in k$, then by the previous claim there exists $q \in k[x]$
such that:
\[
f  = q(x - a).
\]
@col
For any other root $b \in k$ of $f$ which is different from $a$, we have:
\[
0 = f(b) = q(b)(b - a).
\]
@col
Since $k$ is a field, it has no zero divisors; so, it follows from $b - a \neq 0$ that $q(b) = 0$.
In other words, $b$ is a root of $q$.  Since $\deg q < n$,
by the induction hypothesis $q$ has at most $n - 1$ roots.
So, $f$ has at most $n - 1$ roots different from $a$.  This shows that $f$ has at most $n$ roots.
@endcol
<hr/></li>
<li>
@newcol
Let $f$ be a polynomial in $k[x]$ which has $n = \deg f$ distinct roots $a_1, a_2, \ldots, a_n \in k$.

@col
If $n = 1$, then $f = c_0 + c_1 x$ for some $c_i \in k$, with $c_1 \neq 0$.
We have:
\[
0 = f(a_1) = c_0 + c_1a_1,
\]
@col
which implies that: $c_0 = - c_1a_1$.  Hence,
\[
f = -c_1a_1 + c_1 x = c_1(x - a_1).
\]
@col
Suppose $n > 1$.
Suppose for all $n' \in \mathbb{N}$, such that $1 \leq n' < n$,
the claim holds for any polynomial of degree $n'$ which has $n'$ distinct roots in $k$.
By the previous claim, there exists $q \in k[x]$ such that:
\[
f = q(x - a_n).
\]
Note that $\deg q = n - 1$.

@col
For $1 \leq i < n$, we have
\[
0 = f(a_i) = q(a_i)\underbrace{(a_i - a_n)}_{\neq 0}.
\]
@col
Since $k$ is a field, this implies that $q(a_i) = 0$ for $1 \leq i < n$.
So, $a_1, a_2,\ldots, a_{n - 1}$ are $n - 1$ distinct roots of $q$.
By the induction hypothesis there exists $c \in k$ such that:
\[
q = c(x - a_1)(x - a_2)\cdots(x - a_{n - 1}).
\]
Hence, $f = q(x - a_n) = c(x - a_1)(x - a_2)\cdots(x - a_{n - 1})(x - a_n)$.
@qed
@endcol</li></ol>
@endcol

@end
@slide
@cor
Let $k$ be a field.  Let $f, g$ be nonzero polynomials in $k[x]$.
Let $n = {\rm max}\{\deg f, \deg g\}$.
If $f(a) = g(a)$ for $n + 1$ distinct $a \in k$.  Then, $f = g$.
@end
@proof
@newcol
Let $h = f - g$, then $\deg h \leq n$.  By hypothesis, there are $n + 1$ distinct elements $a \in k$
such that $h(a) = f(a) - g(a) = 0$.  If $h \neq 0$,
then it is a nonzero polynomial with degree $\leq n$ which has $n + 1$ distinct roots,
which contradicts the previous theorem.
Hence, $h$ must necessarily be the zero polynomial, which implies that $f = g$.
@qed
@endcol
@end

@slide

@defn
A polynomial in $k[x]$ is called a @keyword{monic polynomial} if its leading coefficient is $1$.
@end

@slide

@cor
@label{bezoutsforpolynomials}
Let $k$ be a field.  Let $f, g$ be nonzero polynomials in $k[x]$.  There exists a unique monic polynomial
$d \in k[x]$ with the following property: <ol>
<li> $(f, g) = (d)$ <br/> Moreover, this $d$ also satisfies the following properties: </li>
<li>
@newcol
$d$ divides both $f$ and $g$, i.e., there exists $a, b \in k[x]$ such that $f = ad$, $g = bd$.
@endcol</li>
<li>
@newcol
There are polynomials $p, q \in k[x]$ such that $d = pf + qg$.
@endcol</li>
<li>
@newcol
If $h \in k[x]$ is a divisor of $f$ and $g$, then $h$ divides $d$.
@endcol</li></ol>
@end

<strong>Terminology.</strong>
@newcol
<ul>
<li> The unique monic $d \in k[x]$ which satisfies property 1
is called the @keyword{Greatest Common Divisor} (<i>abbrev.</i> @keyword{GCD}) of $f$ and $g$. </li>
<li> We say that $f$ and $g$ are @keyword{relatively prime} if their GCD is $1$. </li></ul>
@endcol

<br/>
@proof
@newcol
@ol
@li
By @ref{thm:pidpoly} , there exists $d = \sum_{i = 0}^n a_i x^i \in k[x]$ such that
$(d) = (f, g)$.  Replacing $d$ by $a_n^{-1} d$ if necessary, we may assume that $d$ is a monic polynomial.
It remains to show that $d$ is unique.

@newcol
Suppose $(d) = (d')$, where both $d$ and $d'$ are monic polynomials.
Then, there exist nonzero $p, q \in k[x]$
such that:
\[
d' = pd,\quad d= qd'.
\]
@col
Examining the degrees of the polynomials, we have:
\[
\deg d' = \deg d + \deg p,
\]
and:
\[
\deg d = \deg q + \deg d' = \deg p + \deg q + \deg d.
\]
@col
This implies that $\deg p + \deg q = 0$.  Hence, $p$ and $q$ must both have degree $0$; in other words, they are
constant polynomials.  Moreover, we have $\deg d = \deg d'$.
Comparing the leading coefficients of $d'$ and $pd$, we have $p = 1$.
Hence, $d = d'$.
@endcol
@li
Clear.
@li
Clear.
@li
By Part 3 of the corollary, there are $p, q \in k[x]$ such that $d = pf + qg$.
It is then clear that if $h$ divides both $f$ and $g$, then $h$ must divide $d$.
@qed
@endol
@endcol
@end

@slide

@defn
Let $R$ be a commutative ring.
A nonzero element $p \in R$ which is not a unit is said to be @keyword{irreducible} if $p = ab$ implies that either $a$ or $b$ is a unit.
@end

@eg
The set of irreducible elements in the ring $\mathbb{Z}$ is $\{\pm p : p \text{ a prime number}\}$.
@end

@slide

Let $k$ be a field.
@lemma
A polynomial $f \in k[x]$ is a unit if and only if it is a
nonzero constant polynomial.
@end
@proof
<strong>Exercise.</strong>
@end

@slide

@claim
A nonzero nonconstant polynomial $p \in k[x]$ is irreducible if and only if there is no $f, g \in k[x]$,
with $\deg f, \deg g < \deg p$, such that $fg = p$.
@end
@proof
@newcol
Suppose $p$ is irreducible, and $p = fg$ for some $f, g \in k[x]$ such that $\deg f, \deg g < \deg p$.  Then $p = fg$ implies that $\deg f$ and $\deg g$ are both positive.
By the previous lemma, both $f$ and $g$ are non-units, which is a contradiction,
since the irreducibility of $p$ implies that either $f$ or $g$ must be a unit.

@col
Conversely, suppose $p$ is a nonzero non-unit in $k[x]$,
which is not equal to $fg$ for any $f, g \in k[x]$ with $\deg f, \deg g < \deg p$.
Then, $p = ab$, $a$, $b \in k[x]$,
implies that either $a$ or $b$ must have the same degree as $p$,
and the other factor must be a nonzero constant, in other words a unit in $k[x]$.
Hence, $p$ is irreducible.
@qed
@endcol
@end
@slide
@lemma
@title{Euclid's Lemma}
Let $k$ be a field.
Let $f, g$ be polynomials in $k[x]$.
Let $p$ be an irreducible polynomial in $k[x]$.
If $p | fg$ in $k[x]$, then $p | f$ or $p | g$.
@end
@proof
@newcol
Suppose $p \nmid f$.
Then, any common divisor of $p$ and $f$ must have degree strictly less than $\deg p$.
Since $p$ is irreducible, this implies that any common divisor of $p$ and $f$ is a nonzero constant.
Hence, the GCD of $p$ and $f$ is $1$.
By @ref{bezoutsforpolynomials} , there exist $a, b \in k[x]$ such that:
\[
ap + bf = 1.
\]
@col
Multiplying both sides of the above equation by $g$, we have:
\[
apg + bfg = g.
\]
Since $p$ divides the left-hand side of the above equation, it must
also divide the right-hand side, which is the polynomial $g$.
@qed
@endcol
@end
@claim
@newcol
If $f, g \in k[x]$ are relatively prime, and both divide $h \in k[x]$,
then $fg | h$.
@endcol
@end
@proof
@newcol
@keyword{Exercise.}
@endcol
@end
@slide
@thm
@title{Unique Factorization}
Let $k$ be a field.
Every nonconstant polynomial $f \in k[x]$ may be written as:
\[
f = c p_1\cdots p_n,
\]
where $c$ is a nonzero constant,
and each $p_i$ is a monic irreducible polynomial in $k[x]$.
The factorization is unique up to the ordering of the factors.
@end
@proof
@newcol
@keyword{Exercise.} One possible approach is very similar to the proof of unique factorization
for $\mathbb{Z}$. See: @ref{thm:fta} .
@endcol
@end

@slide
@ex
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-RingsQuotientsPolynomials/RingsQuotientsPolynomials3.pg}
@endenumerate
@end

@slide
@thm
@label{thm:pirredfield}
Let $k$ be a field.  Let $p$ be a polynomial in $k[x]$.
The following statements are equivalent:
@ol
@li
$k[x]/(p)$ is a field.
@li
$k[x]/(p)$ is an integral domain.
@li
$p$ is irreducible in $k[x]$.
@endol
@end
@remark
@newcol
Compare this result with @ref{ex:zmintdom} and @ref{cor:zpfield} .
@endcol
@end
@proof
@newcol
@ol
@li
$1 \Rightarrow 2$: Clear, since every field is an integral domain.
@li
$2 \Rightarrow 3$: If $p$ is not irreducible, there exist $f, g \in k[x]$,
with degrees strictly less than that of $p$, such that $p = fg$.
Since $\deg f, \deg g < \deg p$, the polynomial $p$ does not divide $f$ or $g$
in $k[x]$.  Consequently, the congruence classes $\ol{f}$ and $\ol{g}$
of $f$ and $g$, respectively, modulo $(p)$ is not equal to zero in $k[x]/(p)$.
On the other hand, $\ol{f}\cdot \ol{g} = \ol{fg} = \ol{p} = 0$ in $k[x]/(p)$.
This implies that $k[x]/(p)$ is not an integral domain, a contradiction.
Hence, $p$ is irreducible if $k[x]/(p)$ is an integral domain.
@li
$3 \Rightarrow 1$:
By definition, the multiplicative identity element $1$ of a field is different from the
additive identity element $0$.  So we need to check that the congruence class of $1 \in k[x]$
in $k[x]/(p)$ is not $0$.  Since $p$ is irreducible, by definition we have $\deg p > 0$.
Hence, $1 \notin (p)$, for a polynomial of degree $> 0$ cannot divide a polynomial of degree $0$
in $k[x]$.  We conclude that $1 + (p)\neq 0 + (p)$ in $k[x]/(p)$.

@newcol
Next, we need to prove the existence of the multiplicative inverse of any nonzero element in
$k[x]/(p)$.
Given any $f \in k[x]$ whose congruence class $\ol{f}$ modulo $(p)$ is nonzero in $k[x]/(p)$,
we want to find its multiplicative inverse $\ol{f}^{-1}$.
If $\ol{f} \neq 0$ in $k[x]/(p)$, then by definition $f - 0 \notin (p)$, which means
that $p$ does not divide $f$.  Since $p$ is irreducible, this implies that
$GCD(p, f) = 1$.  By @ref{bezoutsforpolynomials} there exist
$g, h \in k[x]$ such that $fg + hp = 1$.  It is then clear that $\ol{g} = \ol{f}^{-1}$,
since $fg - 1 = -hp$ implies that $fg - 1 \in (p)$,
which by definition means that $\ol{f}\cdot\ol{g} = \ol{fg} = 1$ in $k[x]/(p)$.
@endcol
@qed
@endol
@endcol
@end

@slide
@eg
The rings $\mathbb{R}[x]/(x^2 + 1)$ and $\mathbb{C}$ are isomorphic.
@end
@proof
@newcol
Define a map $\phi : \mathbb{R}[x] \ra \mathbb{C}$ as follows:
\[
\phi(\sum_{k = 0}^na_kx^k) = \sum_{k = 0}^n a_k i^k.
\]

@keyword{Exercise:} $\phi$ is a homomorphism.

@col
For all $a + bi$ ($a, b \in \mathbb{R}$) in $\mathbb{C}$, we have:
\[
\phi(a + bx) = a + bi.
\]
Hence, $\phi$ is surjective.

@col
We now find $\ker \phi$.
Since $\mathbb{R}[x]$ is a PID (see @ref{def:pid}).  There exists $p \in \mathbb{R}[x]$
such that $\ker \phi = (p)$.

@col
Observe that $\phi(x^2 + 1) = 0$.  So, $x^2 + 1 \in \ker \phi$,
which implies that there exists $q \in \mathbb{R}[x]$ such that $x^2 + 1 = pq$.
Since $x^2 + 1$ has no real roots, neither $p$ or $q$ can be of degree $1$.

@col
So, one of $p$ or $q$ must be a nonzero constant polynomial.
$p$ cannot be a nonzero constant polynomial, for that would imply that
$\ker \phi = \mathbb{R}[x]$.  So, $q$ is a constant,
which implies that $p = q^{-1} (x^2 + 1)$.  We conclude that $\ker \phi = (x^2 + 1)$.

@col
It now follows from the First Isomorphism Theorem that
$\mathbb{R}[x]/(x^2 + 1)\cong \mathbb{C}$.
@qed
@endcol
@end@course{Math 2070}
@week{12}
@topic{Rational Root Theorem}
@topic{Gauss's Theorem}
@topic{Eisenstein's Criterion}
@section{Polynomials over $\mathbb{Z}$ and $\mathbb{Q}$}
@thm
@title{Rational Root Theorem}
Let $f = a_0 + a_1x + \cdots + a_nx^n$, be a polynomial
in $\mathbb{Q}[x]$, with $a_i \in \mathbb{Z}$, $a_n \neq 0$.
Every rational root $r$ of $f$ in $\mathbb{Q}$ has the form
$r = b/c$ $(b, c \in \mathbb{Z})$ where $b | a_0$ and $c | a_n$. 
@end

@proof
@newcol
Let $r = b/c$ be a rational root of $f$, where $b, c$ are relatively prime integers.
We have:
\[
0 = \sum_{i = 0}^n a_i (b/c)^i
\] 
@col
Multiplying both sides of the above equation by $c^n$, we have:
\[
0 = a_0c^n + a_1c^{n - 1} b + a_2c^{n - 2}b^2 + \cdots + a_n b^n,
\]
or equivalently:
\[
a_0 c^n = -(a_1c^{n - 1} b + a_2c^{n - 2}b^2 + \cdots + a_n b^n).
\] 
@col
Since $b$ divides the right-hand side, and $b$ and $c$ are relatively prime,
$b$ must divide $a_0$.

@col
Similarly, we have:
\[
a_n b^n = - (a_0c^n + a_1c^{n - 1} b + a_2c^{n - 2}b^2 + \cdots + a_{n - 1}cb^{n - 1}).
\] 
@col
Since $c$ divides the right-hand side, and $b$ and $c$ are relatively prime, $c$ must divide $a_n$. 
@qed
@endcol
@end

@slide
@defn
A polynomial $f \in \mathbb{Z}[x]$ is said to be @keyword{primitive} if the gcd of its coefficients is $1$. 
@end
@remark
@newcol
Note that if $f$ is monic, i.e. its leading coefficient is $1$,
then it is primitive.

If $d$ is the gcd of the coefficients of $f$, then $\frac{1}{d}f$ is a primitive polynomial
in $\mathbb{Z}[x]$. 
@endcol
@end

@slide

@lemma
@title{Gauss's Lemma}
If $f, g \in \mathbb{Z}[x]$ are both primitive, then $fg$ is primitive. 
@end

@proof
@newcol
Write $f = \sum_{k = 0}^m a_k x^k$, $g = \sum_{k = 0}^n b_k x^k$.
Then, $fg = \sum_{k = 0}^{m+n}c_kx^k$, where:
\[
c_k = \sum_{i + j = k}a_ib_j.
\] 
@col
Suppose $fg$ is not primitive.  Then, there exists a prime $p$ such that $p$ divides $c_k$
for $k = 0, 1, 2,\ldots, m + n$.

@col
Since $f$ is primitive, there exists a least
$u \in \{0, 1, 2, \ldots, m\}$ such that $a_u$ is not divisible by $p$.

@col
Similarly, since $g$ is primitive, there is a least $v \in \{0, 1, 2, \ldots, n\}$
such that $b_v$ is not divisible by $p$.
We have:
\[
c_{u + v} = \sum_{\substack{i + j = u+v\\(i, j)\neq (u, v)}}a_ib_j + a_ub_v,
\] 
@col
hence:
\[
a_ub_v %% = c_{u + v} - \sum_{\substack{i + j = k\\(i, j)\neq (u, v)}}a_ib_j
= c_{u + v} - \sum_{\substack{i + j = u + v\\i < u}}a_ib_j
- \sum_{\substack{i + j = u + v\\j < v}}a_ib_j.
\] 
@col
By the minimality conditions on $u$ and $v$, each term on the right-hand side of the above equation
is divisible by $p$.

@col
Hence, $p$ divides $a_ub_v$, which by Euclid's Lemma implies that
$p$ divides either $a_u$ or $b_v$, a contradiction. 
@qed
@endcol
@end
@slide
@lemma
Every nonzero $f \in \mathbb{Q}[x]$ has a unique factorization:
\[
f = c(f) f_0,
\]
where $c(f)$ is a positive rational number, and $f_0$ is a primitive polynomial in $\mathbb{Z}[x]$. 
@end
@defn
@newcol
The rational number $c(f)$ is called the 
@keyword{content}
of $f$. 
@endcol
@end
@proof
@newcol
<b class="notkw">Existence:</b>

Write $f = \sum_{k = 0}^n (a_k/b_k)x^k$,
where $a_k, b_k \in \mathbb{Z}$.
Let $B = b_0b_1\cdots b_n$.
Then, $g := Bf$ is a polynomial in $\mathbb{Z}[x]$.
Let $d$ be the gcd of the coefficients of $g$.
Let $D = \pm d$, with the sign chosen such that $D/B > 0$.
Observe that $f = c(f)f_0$, where
\[
c(f) = D/B,
\]
and
\[
f_0 := \frac{B}{D} f = \frac{1}{D}g
\]
is a primitive polynomial in $\mathbb{Z}[x]$.

@col
<b class="notkw">Uniqueness:</b>

Suppose $f = ef_1$ for some positive $e \in \mathbb{Q}$ and primitive $f_1 \in \mathbb{Z}[x]$.
We have:
\[
ef_1 = c(f) f_0.
\]
Writing $e/c(f) = u/v$ where $u, v$ are relatively prime positive integers, we have:
\[
uf_1 = vf_0.
\]
Since $gcd(u, v) = 1$, by Euclid's Lemma the above equation implies that $v$ divides each
coefficient of $f_1$, and $u$ divides each coefficient of $f_0$.
Since $f_0$ and $f_1$ are primitive, we conclude that $u = v = 1$.
Hence, $e = c(f)$, and $f_1 = f_0$. 
@qed
@endcol
@end

@slide

@cor
For $f \in \mathbb{Z}[x] \subseteq \mathbb{Q}[x]$, we have $c(f) \in \mathbb{Z}$. 
@end
@proof
@newcol
Let $d$ be the gcd of the coefficients of $f$.  Then, $(1/d)f$
is a primitive polynomial, and
\[
f = d\left(\frac{1}{d} f \right)
\]
is a factorization of $f$ into a product of a positive rational number and a primitive polynomial
in $\mathbb{Z}[x]$.
Hence, by uniqueness of $c(f)$ and $f_0$, we have $c(f) = d \in \mathbb{Z}$. 
@qed
@endcol
@end

@slide

@cor
Let $f, g, h$ be nonzero polynomials in $\mathbb{Q}[x]$ such that $f = gh$.
Then, $f_0 = g_0h_0$ and $c(f) = c(g)c(h)$. 
@end
@proof
@newcol
The condition $f = gh$ implies that:
\[
c(f)f_0 = {c(g)}{c(h)} g_0h_0,
\]
where $f_0, g_0, h_0$ are primitive polynomials and $c(f), c(g), c(h)$ are positive rational numbers.
By a previous result $g_0h_0$ is primitive.  It now follows from the uniqueness of $c(f)$ and $f_0$
that $f_0 = g_0h_0$ and $c(f) = c(g)c(h)$. 
@qed
@endcol
@end

@slide

@thm
@title{Gauss's Theorem}
Let $f$ be a nonzero polynomial in $\mathbb{Z}[x]$.
If $f = GH$ for some $G, H \in \mathbb{Q}[x]$, then
$f = gh$ for some $g, h \in \mathbb{Z}[x]$, where
$\deg g = \deg G$, $\deg h = \deg H$.

Consequently, if $f$ cannot be factored into a product of polynomials of smaller degrees in $\mathbb{Z}[x]$,
then it is irreducible as a polynomial in $\mathbb{Q}[x]$. 
@end
@proof
@newcol
Suppose $f = GH$ for some $G, H$ in $\mathbb{Q}[x]$.
Then $f = c(f) f_0 = c(G)c(H) G_0 H_0$,
where $G_0$, $H_0$ are primitive polynomials in $\mathbb{Z}[x]$,
and $c(G)c(H) = c(f)$ by the uniqueness of the content of a polynomial.

@col
Moreover, since $f \in \mathbb{Z}[x]$, its content $c(f)$ lies in $\mathbb{Z}$.
Hence, $g = c(f) G_0$ and $h = H_0$ are polynomials in $\mathbb{Z}[x]$,
with $\deg g = \deg G$, $\deg h = \deg H$, such that $f = gh$. 
@qed
@endcol
@end

@slide

Let $p$ be a prime.
Let $\mathbb{F}_p = \mathbb{Z}/p\mathbb{Z} \cong \mathbb{Z}_p$.  It is a field, since $p$ is prime.
For $a \in \mathbb{Z}$, let $\ol{a}$ denote the residue of $a$ in $\mathbb{F}_p$.

<br/>@keyword{Exercise:} We have $\ol{a} = \ol{a_p}$, where $a_p$ is the remainder of the division of $a$ by $p$.

@thm
Let $f = \sum_{k = 0}^na_k x^k$ be a polynomial in $\mathbb{Z}[x]$
such that $p \nmid a_n$ (in particular, $a_n \neq 0$).
If $\ol{f} := \sum_{k = 0}^n \ol{a_k}x^k$ is irreducible in $\mathbb{F}_p[x]$,
then $f$ is irreducible in $\mathbb{Q}[x]$. 
@end
@proof
@newcol
Suppose $\ol{f}$ is irreducible in $\mathbb{F}_p[x]$,
but $f$ is not irreducible in $\mathbb{Q}[x]$.
By Gauss's theorem, there exist $g, h \in \mathbb{Z}[x]$ such that
$\deg g, \deg h  < \deg f$ and $f = gh$.

@col
Since by assumption $p \nmid a_n$, we have $\deg \ol{f} = \deg f$.

@col
Moreover, $\ol{gh} = \ol{g}\cdot\ol{h}$ (
<strong>Exercise</strong>
).

@col
Hence, $\ol{f} = \ol{gh} = \ol{g}\cdot \ol{h}$, where $\deg \ol{g}, \deg\ol{h} < \deg \ol{f}$.
This contradicts the irreducibility of $\ol{f}$ in $\mathbb{F}_p[x]$.

@col
Hence, $f$ is irreducible in $\mathbb{Q}[x]$ if $\ol{f}$ is irreducible in $\mathbb{F}_p[x]$. 
@qed
@endcol
@end

@slide

@eg
The polynomial $f(x) = x^4 - 5x^3 + 2x + 3 \in \mathbb{Q}[x]$ is irreducible. 
@end
@proof
@newcol
Consider $\ol{f} = x^4 -\ol{5}x^3 + \ol{2}x + \ol{3} = x^4 + x^3 + 1$ in $\mathbb{F}_2[x]$.
If we can show that $\ol{f}$ is irreducible, then by the previous theorem we can
conclude that $f$ is irreducible.

@col
Since $\mathbb{F}_2 = \{0, 1\}$ and
$\ol{f}(0) = \ol{f}(1) = 1 \neq 0$, we know right away that $\ol{f}$
has no linear factors.  So, if $\ol{f}$ is not irreducible, it must be a product of two quadratic factors:
\[
\ol{f} = (ax^2 + bx + c)(dx^2 + ex + g),\quad a, b, c, d, e, g \in \mathbb{F}_2.
\] 
@col
Note that by assumption $a, d$ are nonzero elements of $\mathbb{F}_2$, so $a = d = 1$.
This implies that, in particular:
\[
\begin{split}
1 &= \ol{f}(0) = cg\\
1 &= \ol{f}(1) = (1 + b + c)(1 + e + g)
\end{split}
\] 
@col
The first equation implies that $c = g = 1$.
The second equation then implies that $1 = (2 + b)(2 + e) = be$.
Hence, $b = e = 1$.

@col
We have:
\begin{multline*}
x^4 + x^3 +  1 = (x^2 + x + 1)(x^2 + x + 1)\\
= x^4 + 2x^3 + 3x^2 + 2x + 1 = x^4 + x^2 + 1,
\end{multline*}
a contradiction.

@col
Hence, $\ol{f}$ is irreducible in $\mathbb{F}_2[x]$, which implies
that $f$ is irreducible in $\mathbb{Q}[x]$. 
@qed
@endcol
@end

@slide

@thm
@title{Eisenstein's Criterion}
Let $f = a_0 + a_1 x + \cdots + a_n x^n$ be a polynomial in $\mathbb{Z}[x]$.
If there exists a prime $p$ such that $p | a_i$ for $0 \leq i < n$, but $p \nmid a_n$ and
$p^2 \nmid a_0$, then $f$ is irreducible in $\mathbb{Q}[x]$. 
@end
@proof
@newcol
We prove by contradiction.  Suppose $f$ is not irreducible in $\mathbb{Q}[x]$.
Then, by Gauss's Theorem, there exists $g = \sum_{k = 0}^l b_kx^k$,
$h = \sum_{k = 0}^{n - l} c_k x^k \in \mathbb{Z}[x]$, with $\deg g, \deg h < \deg f$,
such that $f = gh$.

@col
Consider the image of these polynomials in $\mathbb{F}_p[x]$.
By assumption, we have:
\[
\ol{a_n}x^n = \ol{f} = \ol{g}\ol{h}.
\] 
@col
This implies that $\ol{g}$ and $\ol{h}$ are divisors of $\ol{a_n}x^n$.
Since $\mathbb{F}_p$ is a field, unique factorization holds for $\mathbb{F}_p[x]$.
Hence, we must have:
\[
\ol{g} = \ol{b_u}x^u,\quad
\ol{h} = \ol{c_{n - u}}x^{n - u},
\]
for some $u \in \{0, 1, 2,\ldots, l\}$.

@col
If $u < l$, then $n - u > n - l \geq \deg \ol{h}$, which cannot hold.

@col
So, we conclude that $\ol{g} = \ol{b_l}x^l$, $\ol{h} = \ol{c_{n - l}} x^{n - l}$.

@col
In particular, $\ol{b_0} = \ol{c_0} = 0$ in $\mathbb{F}_p$, which implies
that $p$ divides both $b_0$ and $c_0$.  Since $a_0 = b_0c_0$, we have $p^2 | a_0$,
a contradiction. 
@qed
@endcol
@end

@slide
@eg
The polynomial $x^5 + 3x^4 - 6x^3 +12x + 3$ is irreducible in $\mathbb{Q}[x]$. 
@end
@course{Math 2070}
@week{13}
@topic{Field Extensions}
@topic{Finite Fields}
@section{Field Extensions}
@defn
Let $R$ be a ring.
A subset $S$ of $R$ is said to be a @keyword{subring} of $R$ if it is a ring under the addition $+_R$ and multiplication $\times_R$ associated with $R$,
and its additive and multiplicative identity elements $0$, $1$ are those of $R$.
@end
@remark
@newcol
To show that a subset $S$ of a ring $R$ is a subring,
it suffices to show that: <ul>
<li> $S$ contains the additive and multiplicative identity elements of $R$. </li>
<li> $S$ is "closed under addition": $a +_R b \in S$ for all $a,b \in S$. </li>
<li> $S$ is "closed under multiplication": $a \times_R b \in S$ for all $a, b\in S$. </li>
<li> $S$ is closed under additive inverse: For all $a \in S$, the additive inverse $-a$ of $a$
in $R$ belongs to $S$. </li></ul>
@endcol
@end
@defn
@newcol
A @keyword{subfield} $k$ of a field $K$ is a subring of $K$ which is a field.
@endcol
@end
@newcol
In particular, for each nonzero element $r \in k \subseteq K$.  The multiplicative inverse of $r$ in $K$
lies $k$.
@endcol
@defn
@newcol
Let $K$ be a field and $k$ a subfield.  Let $\alpha$ be an element of $K$.
We define $k(\alpha)$ to be the smallest subfield of $K$ containing $k$ and $\alpha$.
In other words, if $F$ is a subfield of $K$ which contains $k$ and $\alpha$, then $F \supseteq k(\alpha)$. <p/>
We say that $k(\alpha)$ is obtained from $k$ by <b class="notkw">adjoining</b><b style="display:none">adjoin</b> $\alpha$.
@endcol
@end

@slide
@thm
@label{thm:simpleextthm}
Let $k$ be a subfield of a field $K$.  Let $\alpha$ be an element of $K$.
@ol
@li
If $\alpha$ is a root of a nonzero polynomial $f \in k[x]$
(viewed as a polynomial in $K[x]$ with coefficients in $k$),
then $\alpha$ is a root of an irreducible polynomial $p \in k[x]$,
such that $p | f$ in $k[x]$.
@li
Let $p$ be an irreducible polynomial in $k[x]$ of which $\alpha$ is a root.
Then, the map $\phi : k[x]/(p) \ra K$,
defined by:
\[
\phi\left(\sum_{j = 0}^nc_jx^j + (p)\right) = \sum_{j = 0}^n c_j\alpha^j,
\]
is a well-defined one-to-one ring homomorphism with $\im \phi = k(\alpha)$.
(Here, $\sum_{j = 0}^nc_jx^j + (p)$ is the congruence class of $\sum_{j = 0}^nc_jx^j \in k[x]$
modulo $(p)$.) <br/>
Hence,
\[
k[x]/(p) \cong k(\alpha).
\]
@li
If $\alpha, \beta \in K$ are both roots of an irreducible polynomial $p$ in $k[x]$,
then there exists a ring isomorphism $\sigma : k(\alpha) \ra k(\beta)$,
with $\sigma(\alpha) = \beta$ and $\sigma(s) = s$, for all $s \in k$.
@li
Let $p$ be an irreducible polynomial in $k[x]$ of which $\alpha$ is a root.
Then, each element in $k(\alpha)$ has a unique expression of the form:
\[
c_0 + c_1\alpha + \cdots + c_{n - 1}\alpha^{n - 1},
\]
where $c_i \in k$, and $n = \deg p$.
@endol
@end

@remark
@newcol
Suppose $p$ is an irreducible polynomial in $k[x]$ of which $\alpha \in K$ is a root.
Part 4 of the theorem essentially says that $k(\alpha)$ is a vectors space of dimension $\deg p$
over $k$, with basis:
\[
\{1, \alpha, \alpha^2,\ldots, \alpha^{n - 1}\}.
\]
@endcol
@end

@slide

@eg
Consider $k = \mathbb{Q}$ as a subfield of $K = \mathbb{R}$.
The element $\alpha \in \sqrt[3]{2} \in \mathbb{R}$
is a root of the the polynomial $p = x^3 - 2 \in \mathbb{Q}[x]$,
which is irreducible in $\mathbb{Q}[x]$ by the Eisenstein's Criterion for the prime $2$.

@newcol
The theorem applied to this case says that $\mathbb{Q}(\alpha)$,
i.e. the smallest subfield of $\mathbb{R}$ containing $\mathbb{Q}$ and $\alpha$,
is equal to the set:
\[
\{c_0 + c_1 \alpha + c_2 \alpha^2 : c_i \in \mathbb{Q}\}
\]
@col
The addition and multiplication operations in $\mathbb{Q}(\alpha)$
are those associated with $\mathbb{R}$, in other words:
\begin{multline*}
(c_0 + c_1 \alpha + c_2 \alpha^2) + (b_0 + b_1 \alpha + b_2 \alpha^2)\\
= (c_0 + b_0) + (c_1 + b_1)\alpha + (c_2 + b_2)\alpha^2,
\end{multline*}
@col
\begin{multline*}
(c_0 + c_1 \alpha + c_2 \alpha^2) \cdot (b_0 + b_1 \alpha + b_2 \alpha^2)\\
= c_0b_0 + c_0b_1\alpha + c_0 b_2\alpha^2 + c_1 b_0\alpha + c_1b_1 \alpha^2\\ +
c_1b_2\alpha^3 + c_2b_0\alpha^2 + c_2b_1\alpha^3 + c_2b_2\alpha^4\\
= (c_0 b_0 + 2c_1b_2 + 2c_2b_1) + (c_0b_1 + c_1 b_0 + 2c_2b_2)\alpha \\
+ (c_0 b_2 + c_1 b_1 + c_2 b_0)\alpha^2
\end{multline*}
@endcol
@end

@ex
@newcol
Given  a nonzero $\gamma = c_0 + c_1\alpha + c_2 \alpha^2 \in \mathbb{Q}(\alpha)$,
$c_i \in \mathbb{Q}$, find $b_0, b_1, b_2 \in \mathbb{Q}$ such that
$b_0 + b_1 \alpha + b_2\alpha^2$ is the multiplicative inverse of $\gamma$ in $\mathbb{Q}(\alpha)$.
@endcol
@end
@slide

@proof
(<span style="color:SteelBLue">of @ref{thm:simpleextthm}</span>
)
@ol
@li
Define a map $\psi : k[x] \ra K$ as follows:
\[
\psi\left(\sum c_j x^j\right) = \sum c_j\alpha^j.
\]

@keyword{Exercise:} $\psi$ is a ring homomorphism.

@newcol
By assumption, $f$ lies in $\ker \psi$.
Since $k$ is a field, the ring $k[x]$ is a PID.
So, there exists $p \in k[x]$ such that $\ker \psi = (p)$.
Hence, $p | f$ in $k[x]$.

@col
By the First Isomorphism Theorem, $\im \psi$ is a subring of $K$
which is isomorphic to $k[x]/(p)$.  In particular, $\im \psi$ is an integral domain
because $K$ has no zero divisors.
Hence, by @ref{thm:pirredfield} , the polynomial $p$ is an irreducible in $k[x]$.

@col
Since $p \in (p) = \ker \psi$, we have $0 = \psi(p) = p(\alpha)$.  Hence,
$\alpha$ is a root of $p$.
@endcol
@li
If $f + (p) = g + (p)$ in $k[x]/(p)$, then $g - f \in (p)$, or equivalently:
$g =  f + pq$ for some $q \in k[x]$.

@newcol
Hence, $\phi(g + (p)) = f(\alpha) + p(\alpha)q(\alpha) = f(\alpha) = \phi(f + (p))$.

@col
This shows that $\phi$ is a well-defined map.  We leave it as an exercise to show
that $\phi$ is a one-to-one ring homomorphism.

@col
We now show that $\im \phi = k(\alpha)$.
By the First Isomorphism Theorem, $\im \phi$ is isomorphic to $k[x]/(p)$,
which is a field since $p$ is irreducible.
Moreover, $\alpha = \phi(x + (p))$ lies in $\im \phi$.  Hence, $\im \phi$ is a subfield
of $K$ containing $\alpha$.

@col
Since each element in $\im \phi$ has the form
$\sum_{j = 0}^n c_j \alpha^j$, where $c_j \in k$, and fields are closed under addition and multiplication,
any subfield of $K$ which contains $k$ and $\alpha$ must contain $\im \phi$.
This shows that $\im \phi$ is the smallest subfield of $K$ containing $k$ and $\alpha$.
Hence, $k[x]/(p) \cong \im \phi = k(\alpha)$.
@endcol
@li
Define $\phi' : k[x]/(p) \ra k(\beta)$ as follows:
\[
\phi'\left(\sum c_j x^j + (p)\right) = \sum c_j \beta^j.
\]
@newcol
By the same reasoning applied to $\phi$ before, the map $\phi'$
is a well-defined ring isomorphism, with:
\[
\phi'(x + (p)) = \beta,\quad \phi'(s + (p)) = s \text{ for all } s \in k.
\]
It is then easy to see that the map
$\sigma := \phi'\circ\phi^{-1} : k(\alpha) \ra k(\beta)$
is the desired isomorphism between $k(\alpha)$ and $k(\beta)$.
@endcol
@li
Since $\phi$ in Part 2 is an isomorphism onto $\im \phi = k(\alpha)$,
we know that each element $\gamma \in k(\alpha)$
is equal to $\phi(f + (p)) = f(\alpha) := \sum c_j \alpha^j$
for some $f = \sum c_j x^j \in k[x]$.

@newcol
By the division theorem for $k[x]$.  There exist $m, r \in k[x]$ such that $f = mp + r$,
with $\deg r < \deg p = n$.  In particular, $f + (p) = r + (p)$ in $k[x]/(p)$.

@col
Write $r = \sum_{j = 0}^{n - 1} b_j x^j$, with $b_j = 0$ if $j > \deg r$.

@col
We have:
\[
\gamma = \phi(f + (p)) = \phi(r + (p)) = \sum_{j = 0}^{n -1} b_j \alpha^j.
\]
@col
It remains to show that this expression for $\gamma$ is unique.
Suppose $\gamma = g(\alpha) = \sum_{j = 0}^{n - 1} b_j' \alpha^j$ for some
$g = \sum_{j = 0}^{n - 1}b_j'x^j \in k[x]$.

@col
Then, $g(\alpha) = r(\alpha) = \gamma$ implies that $\phi(g + (p)) = \phi(r + (p))$,
hence:
\[
(g - r) + (p) \in \ker \phi.
\]
Since $\phi$ is one-to-one, we have $(g - r) \equiv 0$ modulo $(p)$,
which implies that $p | (g - r)$ in $k[x]$.

@col
Since $\deg g, \deg r < \deg p$, this implies that $g - r = 0$.
So, the expression $\gamma = b_0 + b_1\alpha + \cdots + b_{n - 1}\alpha^{n - 1}$
is unique.
@qed
@endcol
@endol
@end

@slide
<h5>Terminology:</h5><ul>
<li> If $k$ is a subfield of $K$, we say that $K$ is a @keyword{field extension} of $k$. </li>
<li> Let $\alpha$ be an element in a field extension $K$ of a field $k$.
If there exists a polynomial $p \in k[x]$ of which $\alpha$
is a root, then $\alpha$ is said to be @keyword{algebraic} <b class="notkw">over $k$</b>. </li>
<li> If $\alpha \in K$ is algebraic over $k$, then there exists a unique <em>monic irreducible</em> polynomial $p \in k[x]$ of which $\alpha$ is a root (@keyword{Exercise}).
This polynomial $p$ is called the @keyword{minimal polynomial} of $\alpha$ over $k$. </li></ul>
@newcol
For example, $\sqrt[3]{2} \in \mathbb{R}$ is algebraic over $\mathbb{Q}$.
Its minimal polynomial over $\mathbb{Q}$ is $x^3 - 2$.
@endcol

@ex
@newcol
Find the minimal polynomial of $2 - \sqrt[3]{6} \in \mathbb{R}$ over $\mathbb{Q}$, if it exists.
@endcol
@end

@slide
@ex
Find the minimal polynomial of $\sqrt[3]{5}$ over $\mathbb{Q}$.
@end
@ex
@newcol
Express the multiplicative inverse of $\gamma = 2 + \sqrt[3]{5}$
in $\mathbb{Q}(\sqrt[3]{5})$ in the form:
\[
\gamma^{-1} = c_0 + c_1\sqrt[3]{5} + c_2\left(\sqrt[3]{5}\right)^2,
\]
where $c_i \in \mathbb{Q}$, if possible.
@endcol
@end
@section{WeBWorK}
@enumerate
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Fields/Fields3.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Fields/Fields4.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Fields/Fields5.pg}
@item
@webwork{Library/UMass-Amherst/Abstract-Algebra/PS-Fields/Fields6.pg}
@endenumerate
<!--
@section{Splitting Field}
<b style="display:none">splitting field</b>
<hr/>
@eg
Since $\sqrt[3]{2} \in \mathbb{Q}(\sqrt[3]{2})$ is a root of $x^3 - 2$,
the polynomial $p = x^3 - 2$ has a linear factor in
$\mathbb{Q}(\sqrt[3]{2})[x]$.  More precisely,
\[
x^3 - 2 = (x - \sqrt[3]{2})(x^2 + \sqrt[3]{2}x + (\sqrt[3]{2})^2)
\]
in $\mathbb{Q}(\sqrt[3]{2})[x]$. <p/>@keyword{Exercise}: Is $x^2 + \sqrt[3]{2}x + (\sqrt[3]{2})^2$
irreducible in $\mathbb{Q}(\sqrt[3]{2})[x]$?
@end
@newcol
We could repeat this process and adjoin roots of
$x^2 + \sqrt[3]{2}x + (\sqrt[3]{2})^2$ to $\mathbb{Q}(\sqrt[3]{2})$
to further "split" the polynomial $x^3 - 2$ into a product of linear factors.
That is the main idea behind the following theorem:
@endcol
@thm
@newcol
If $k$ is a field, and $f$ is a nonconstant polynomial in $k[x]$,
then there exists a field extension $K$ of $k$, such that $f \in k[x] \subseteq K[x]$
is a product of linear factors in $K[x]$.

@col
In other words, there exists a field extension $K$ of $k$, such that:
\[
f = c(x - \alpha_1)\cdots (x - \alpha_n),
\]
for some $c, \alpha_i \in K$.
@endcol
@end
@proof
@newcol
We prove by induction on $\deg f$.

@col
If $\deg f = 1$, we are done.

@col
<b class="notkw">Inductive Step:</b> Suppose $\deg f > 1$.  Suppose, for any field extension $k'$ of $k$,
and any polynomial $g \in k'[x]$ with $\deg g < \deg f$,
there exists a field extension $K$ of $k'$ such that $g$ splits into a product
of linear factors in $K[x]$.

@col
Suppose $f$ is irreducible.  Let $f(t)$ be the polynomial in $k[t]$
obtained from $f$ by replacing the variable $x$ with the variable $t$.
Consider $k' := k[t]/(f(t))$.
Then, $k'$ is a field extension of $k$ if we identify $k$ with the subset
$\{c + (f(t)) : c \in k\} \subseteq k'$,
where $c$ is considered as a constant polynomial in $k[t]$.

@col
Observe that $k'$ contains a root $\alpha$ of $f$,
namely $\alpha = t + (f(t)) \in k[t]/(f(t))$.
Hence, $f = (x - \alpha)q$ in $k'[x]$ for some polynomial $q \in k'[x]$ with $\deg q < \deg f$.

@col
Now, by the induction hypothesis,
there is an extension field $K$ of $k'$ such that $q$ splits into a product of linear factors in $K[x]$.
Consequently, $f$ splits into a product of linear factors in $K[x]$.

@col
If $f$ is not irreducible, then $f = gh$ for some $g, h \in k[x]$,
with $\deg g, \deg h < \deg f$.
So, by the induction hypothesis, there is a field extension $k'$ of $k$
such that $g$ is a product of linear factors in $k'[x]$.

@col
Hence,
$f = (x - \alpha_1)\cdots(x - \alpha_n) h$ in $k'[x]$.  Since $\deg h < \deg f$,
by the inductive hypothesis there exists a field extension $K$ of $k'$ such that $h$
splits into linear factors in $K[x]$.

@col
Hence, $f$ is a product of linear factors in $K[x]$.
@qed
@endcol
@end
-->
<!--@thm
If $k$ is a field, and $f$ is a nonconstant polynomial in $k[x]$,
then there exists a field extension $K$ of $k$, such that $f \in k[x] \subseteq K[x]$
is a product of linear factors in $K[x]$.
@newcol
In other words, there exists a field extension $K$ of $k$, such that:
\[
f = c(x - \alpha_1)\cdots (x - \alpha_n),
\]
for some $c, \alpha_i \in K$.
@endcol@end@proof@newcol
We prove by induction on $\deg f$.
@col
If $\deg f = 1$, we are done.
@col
<b class="notkw">Inductive Step:</b>
Suppose $\deg f > 1$.  Suppose, for any field extension $k'$ of $k$,
and any polynomial $g \in k'[x]$ with $\deg g < \deg f$,
there exists a field extension $K$ of $k'$ such that $g$ splits into a product
of linear factors in $K[x]$.
@col
Suppose $f$ is irreducible.  Let $f(t)$ be the polynomial in $k[t]$
obtained from $f$ by replacing the variable $x$ with the variable $t$.
Consider $k' := k[t]/(f(t))$.
Then, $k'$ is a field extension of $k$ if we identify $k$ with the subset
$\{c + (f(t)) : c \in k\} \subseteq k'$,
where $c$ is considered as a constant polynomial in $k[t]$.
@col
Observe that $k'$ contains a root $\alpha$ of $f$,
namely $\alpha = t + (f(t)) \in k[t]/(f(t))$.
Hence, $f = (x - \alpha)q$ in $k'[x]$ for some polynomial $q \in k'[x]$ with $\deg q < \deg f$.
@col
Now, by the induction hypothesis,
there is an extension field $K$ of $k'$ such that $q$ splits into a product of linear factors in $K[x]$.
Consequently, $f$ splits into a product of linear factors in $K[x]$.
@col
If $f$ is not irreducible, then $f = gh$ for some $g, h \in k[x]$,
with $\deg g, \deg h < \deg f$.
So, by the induction hypothesis, there is a field extension $k'$ of $k$
such that $g$ is a product of linear factors in $k'[x]$.
@col
Hence,
$f = (x - \alpha_1)\cdots(x - \alpha_n) h$ in $k'[x]$.  Since $\deg h < \deg f$,
by the inductive hypothesis there exists a field extension $K$ of $k'$ such that $h$
splits into linear factors in $K[x]$.
@col
Hence, $f$ is a product of linear factors in $K[x]$.
@qed@endcol@end-->
<!--
@section{Finite Fields}
Recall:
@defn
Let $R$ be a ring with additive and multiplicative identity elements $0$, $1$,
respectively.
The @keyword{characteristic} ${\rm char}\, R$ of $R$ is the smallest positive integer $n$
such that:
\[
\underbrace{1 + 1 + \cdots + 1}_{n \text{ times}} = 0.
\]
If such an integer does not exist, we say that the ring has @keyword{characteristic zero}.
@end

@slide

@eg
<ul>
<li> The ring $\mathbb{Q}$ has characteristic zero. </li>
<li> ${\rm char}\, \mathbb{Z}_6 = 6$. </li></ul>
@end

@ex
@newcol
If a ring $R$ as finitely many elements, then it has positive (i.e. nonzero) characteristic.
@endcol
@end

@claim
@newcol
If a field $F$ has positive characteristic ${\rm char}\, F$,
then ${\rm char}\, F$ is a prime number.
@endcol
@end

@eg
@newcol
${\rm char}\,\mathbb{F}_5 = 5$,
which is prime.
@endcol
@end

@remark
@newcol
Note that all finite rings have positive characteristics,
but there are rings with positive characteristics which have infinitely many elements,
e.g. the polynomial ring $\mathbb{F}_5[x]$.
@endcol
@end

@slide

@claim
Let $F$ be a finite field.  Then, the number of elements of $F$ is equal to $p^n$
for some prime $p$ and $n \in \mathbb{N}$.
@end
@proof
@newcol
Since $F$ is finite, it has finite characteristic.  Since it is a field,
$\mathrm{char}\, F$ is a prime $p$.

@col
@keyword{Exercise:} $\mathbb{F}_p$ is isomorphic to a subfield of $F$.

@col
Viewing $\mathbb{F}_p$ as a subfield of $F$,
we see that $F$ is a vector space over $\mathbb{F}_p$.
Since the cardinality of $F$ is finite, the dimension $n$ of $F$ over $\mathbb{F}_p$
must necessarily be finite.

@col
Hence, there exist $n$ basis elements
$\alpha_1, \alpha_2,\ldots, \alpha_{n }$ in $F$,
such that each element of $F$ may be expressed uniquely as:
\[
c_1\alpha_1  + c_2\alpha_2 + \cdots + c_{n}\alpha_{n},
\]
where $c_i \in \mathbb{F}_p$.

@col
Since $\mathbb{F}_p$ has $p$ elements,
it follows that $F$ has $p^n$ elements.
@qed
@endcol
@end

@slide

@claim
Let $k$ be a field, $f$ a nonzero irreducible polynomial in $k[x]$,
then $k[x]/(f)$ is a vector space of dimension $\deg f$ over $k$.
@end
@proof
@newcol
Let $K = k[t]/(f(t))$,
then $K$ is a field extension of $k$ which contains a root $\alpha$ of $f$,
namely, $\alpha = t + (f(t))$.

@col
It is clear that $K = k(\alpha)$, since any element in $K = k[t]/(f(t))$ has the form $\sum b_i\alpha^i$, where $b_i \in k$.

On the other hand, by @ref{thm:simpleextthm}, every element in $k(\alpha)$ may be expressed uniquely in the form:
\[
c_0 + c_1 \alpha + c_2\alpha^2 + \cdots + c_{n - 1}\alpha^{n - 1},\quad c_i \in k,\; n = \deg f,
\]
which shows that $K = k(\alpha)$ is a vector space of dimension $\deg f$ over $k$.

Since $K$ is simply $k[x]/(f)$ with the variable $x$ replaced with $t$,
we conclude that $k[x]/(f)$ is a vector space of dimension $\deg f$ over $k$.
@qed
@endcol
@end

@cor
@newcol
If $k$ is a finite field with $\abs{k}$ elements,
and $f$ is an irreducible polynomial of degree $n$ in $k[x]$,
then the field $k[x]/(f)$ has $\abs{k}^n$ elements.
@endcol
@end

@slide
@eg
Let $p = 2$, $n = 2$.  To construct a finite field with $p^n = 4$ elements.
We first start with the finite field $\mathbb{F}_2$,
then try to find an irreducible polynomial $f \in \mathbb{F}_2[x]$ such that
$\mathbb{F}_2[x]/(f)$ has 4 elements.

@newcol
Based on our discussion so far,
the degree of $f$ should be equal to $n = 2$,
since $n$ is precisely the dimension of the desired finite field over $\mathbb{F}_2$.

@col
Consider $f = x^2 + x + 1$.
Since $p$ is of degree $2$ and has no root in $\mathbb{F}_2$,
it is irreducible in $\mathbb{F}_2[x]$.  Hence, $\mathbb{F}_2[x]/(x^2 + x + 1)$
is a field with $4$ elements.
@endcol
@end

@slide

@thm
(<b class="notkw">Galois</b>)
Given any prime $p$ and $n \in \mathbb{N}$,
there exists a finite field $F$ with $p^n$ elements.
@end
@proof
(Not within the scope of the course.)

@newcol
Consider the polynomial:
\[
f = x^{p^n} - x \in \mathbb{F}_p[x]
\]
By Kronecker's theorem, there exists a field extension $K$ of $\mathbb{F}_p$
such that $f$ splits into a product of linear factors in $K[x]$.
Let:
\[
F = \{\alpha \in K : f(\alpha) = 0\}.
\]

@ex
Let $g = (x - a_1)(x - a_2)\cdots(x - a_n)$ be a polynomial in $k[x]$,
where $k$ is a field.  Show that the roots $a_1, a_2, \ldots, a_n$ are distinct
if and only if $gcd(g, g') = 1$, where $g'$ is the derivative of $g$.
@end

In this case, we have $f' = p^n x^{p^n - 1} - 1 = -1$ in $\mathbb{F}_p[x]$.
Hence, $gcd(f, f') = 1$, which implies by the exercise that the roots of $f$
are all distinct.  So, $f$ has $p^n$ distinct roots in $K$, hence $F$ has exactly $p^n$ elements.

It remains to show that $F$ is a field.
Let $q = p^n$.  By definition, an element $a \in K$ belongs to $F$ if and only if
$f(a) = a^q - a = 0$, which holds if and only if $a^q = a$.
For $a, b \in F$, we have:
\[
(ab)^q = a^qb^a = ab,
\]
which implies that $F$ is closed under multiplication.
Since $K$, being a extension of $\mathbb{F}_p$, has characteristic $p$.
we have $(a + b)^p = a^p + b^p$.  Hence,
\begin{multline*}
(a + b)^q = (a + b)^{p^n} = ((a + b)^p)^{p^{n - 1}} = (a^p  + b^p)^{p^{n - 1}}\\
= (a^p + b^p)^p)^{p^{n - 2}} = (a^{p^2} + b^{p^2})^{p^{n - 2}}\\
= \cdots = a^{p^n} + b^{p^n} = a + b,
\end{multline*}
which implies that  $F$ is closed under addition.

Let $0, 1$ be the additive and multiplicative identity elements, respectively, of $K$.
Since $0^q = 0$ and $1^q = 1$, they are also the additive and multiplicative identity elements of $F$.

For nonzero $a \in F$, we need to prove the existence of
the additive and multiplicative inverses of $a$ in $F$.

Let $-a$ be the additive inverse of $a$ in $K$.
Since $(-1)^q = -1$ (even if $p = 2$, since $1 = -1$ in $\mathbb{F}_2$),
we have:
\[
(-a)^q = (-1)^q a^q = -a,
\]
so $-a \in F$.  Hence, $a \in F$ has an additive inverse in $F$. <p/>
Since $a^q = a$ in $K$, we have:
\[
a^{q - 2} a = a^{q - 1} = 1
\]
in $K$.  Since $a \in F$ and $F$ is closed under multiplication,
$a^{q - 2} = \underbrace{a\cdots a}_{q-2 \text{ times}}$ lies in $F$.
So, $a^{q -2}$ is a multiplicative inverse of $a$ in $F$.
@qed
@endcol
@end
-->